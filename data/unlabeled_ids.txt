run heidel time english
run heidel time spanish
default_heideltime_location
text
ann
date
heideltime env
default props
props
pipeline
outputs
heidel time itest
test working
inputs
time expression
sutime simple parser itest
set up
normalized date
test british style date recognition
doc
british document one
british document two
american document one
american document two
sutime british itest
test heidel time kbpannotator itest
working_dir
gold_results
test file contents
test document
output results
heidel time kbpannotator itest
get default properties
get time annotator
test sutime durations
test sutime durations2
test sutime durations3
test sutime iso
test suiso with timezone
test sutime2
test sutime date
test sutime time
test sutime resolve time
test sutime range without range
test sutime range with range
test sutime range conversion
test sutime empty sentence
test sutime inexact time
test sutime set
test sutime date time
test sutime date time2
test sutime iso2
test sutime date2
test sutime holidays
test sutime12am pm
test inner capture group access
test overlaps
test resolve1
test resolve2
test resolve3
test set
test set2
test seasons
check timex
create document
time_annotator_name
test text
expected timexes
expected timexes resolved
document
sutime
timex ann
expected timex
document with ref time
expected timexes resolved1
expected timexes resolved2
expected timexes resolved3
timexes
ref times
expected timex strs resolved
ref time
expected timex str
ref modifiers
ref exprs
expected values prev
expected values this
expected values next
expected values next imme
expected values prev imme
expected values all
ref mod
expected values
expr
tod exprs
expected tod values
tod
expected values every
expected multiples
matcher
update v
ref exprs1
ref exprs2
expected1
expected2
ref modifier
document text
expected text
actual text
begin
end
actual timex
annotation
sutime itest
test gradient check
test binary no recursion
test unary no recursion
test unary recursion bottom
test unary recursion top
test unary recursion both
test binary recursion bottom
test binary unary
test unary binary unary
parser
correct
hypothesis
expected binary
expected unary
dv model
correct tree
training batch
hypothesis tree
hypotheses
top parses
all trees
gc func
dvparser cost and gradient itest
test positions
check tree
main
tree
leaves
leaf
index
tlp
gsf
deps
nodes
dep
args
dependency index itest
start lpserver
run
test start server
test get tree
test get tokenized test
test get lemmas
test get text tree
test get binarized text tree
test get collapsed tree stanford dependencies
test get collapsed tree universal dependencies
test quit
test get shift reduce text
lexparser
srparser
lexmodel
srmodel
tagger
test string
result string
binarized result string
collapsed tree stanford dependencies string
collapsed tree universal dependencies string
tokenized string
lemma test string
lemma expected string
port
daemon
use stanford dependencies
server
thread
client
tokenized
result
server thread
lexicalized parser server itest
load conll file original
original con lllines
test reading co nllxfile
example co nllxpath
example co nllupath
in file
sents
trees
unlabeled
c pos
reader
sentence tokens
line
splits
sentence
word
pos
dep type
head
token
file path
original lines
original sentences
original trees
current sentences
current trees
co nllreading itest
run depparse test
test english on wsjdev
test english on wsjtest
test ccprocess
test serialization annotation
uas threshold
las threshold
scores
uas
las
enhanced plus plus
dependencies
expected
tempfile
read sentences
dependency parser itest
test simple parse
test basic constraint
english parser
english tagger
constraint
constraints
shift reduce parser itest
build one treebank test case
build two treebank test case
build and test
test build english parser
test build chinese parser
test build german parser
test build french parser
test build arabic parser
english command lines
english two treebanks
chinese command lines
german command lines
french command lines
arabic command lines
base test ser command line
base test text command line
english one tree
english second tree
english three trees
chinese one tree
chinese three trees
german one tree
german three trees
french one tree
french three trees
arabic one tree
arabic three trees
train command line
test path
parser file
text file
base command line
train path
command line formatter
test
secondary path
original out
original err
saved output
tee out
tee out ps
tee err
tee err ps
output lines
perf line
test command line
english command line
chinese command line
german command line
french command line
arabic command line
build lexicalized parser itest
parser test case
compare single output
compare output
sample sausage
test parse string
test parser query
test parse multiple
test constraints
test chinese dependencies
test chinese dependencies semantic head
test already tagged
test tag regex
test char offsets
tag print
penn print
typ dep print
typ dep col print
chinese parser
chinese penn print
chinese typ dep print
t lp
english path
chinese path
results
printer
expected output
actual output
expected tags
expected penn
expected dep
expected dep col
words
sentences
results1
results2
chinese test
expected chinese tree
expected chinese deps
chinese test2
expected chinese tree2
expected chinese deps2
expected chinese deps2sd
params tree print
tokens
begins
ends
yield
lexicalized parser itest
test api
test dp
temp
out
parser demo itest
read trees
process file
compare results
setup expected results
run four tests
run two tests
test english
test german
test chinese
run test
filename
encoding
trf
next
input
output
expected results
parser filename
english trees
english encoding
english pcfg
german trees
german encoding
german pcfg
french trees
french encoding
arabic trees
arabic encoding
chinese trees
chinese encoding
chinese pcfg
input trees
pcfg
factored
pcfg input
factored input
pcfg results
factored results
parser path
threads
threaded parser slow itest
parser thread
test char encoding utf8
test char encoding iso8859
test char encoding gb18030
try char encoding
utf8bytes
iso8859bytes
gb18030bytes
contents
tmp input
tmp file
offset
num read
length
lexicalized parser character encoding itest
get sequence pattern expr
get or pattern expr
get node pattern expr
test token sequence matcher value
test token sequence matcher begin end
test token sequence matcher1
test token sequence matcher2
test token sequence matcher3
test token sequence matcher conj
test token sequence matcher conj2
test token sequence matcher conj all
test token sequence matcher all
test token sequence matcher all2
test token sequence matcher non overlapping
test token sequence matcher4
test token sequence matcher5
test token sequence matcher6
test token sequence matcher7
test token sequence matcher8
test token sequence matcher9
test token sequence matcher10
test token sequence optimize or string
test multiple patterns
test token sequence matcher pos nnp
test token sequence matcher number
test token sequence matcher nested
test token sequence matcher aas
test token sequence finds wildcard
test token sequence matches wildcard
test token sequence matcher abs
test token sequence matcher multi node pattern
test token sequence matcher multi node pattern2
test token sequence matcher back ref
test multi pattern matcher
test string pattern match case insensitive
test string match case insensitive
test compile
test binding compile
test case insensitive1
test case insensitive2
text regex
patterns
match
test text1
content
greedy pattern
seq pattern
entire match
reluctant pattern
seq pattern2
matcher2
timing
doc no match
multi pattern matcher
expected iter
matches
nnp pattern
env
node pattern
res
matched
token sequence matcher itest
test rebuilding mwttext
test rebuilding text
french properties
french pipeline
french text
french doc
rebuilt french text
basic properties
rebuilt text
sentence utils itest
test coref
coref chains
document itest
test postag
test lemma
test ner
test mentions
test parse
test natlog operators
test natlog polarities
test dependency parse
test dependency parse with parse annotator
test to core labels
test write read
operators
polarities
sent
tmp
orig
loaded
sentence itest
test keyphrases
test keyphrases pp
test keyphrases regressions
test keyphrases as string
test head of span
test all spans
test all spans limited
test dependency path between
test loopy dependency path between
test dependency path between regressions
iter
start
sentence algorithms itest
test regularization gradient check
train_path
training trees
model
sentiment training itest
parse sentence
can initialize
check
check formatted
check empty
parse what is
parse what are
parse what was
parse what is there
parse what noun is
parse what noun has
parse what noun has np
parse what do vp
parse what has
parse where did
parse where does
parse where is
parse who is
parse who is in
parse who was
parse who did
parse what did
parse when did
parse what nndo
parse what nnis
parse how
parse how much
parse how can
formatting start upper case
formatting correct tense
what nnwill i
instance
fields
got
question to statement translator itest
annotate
assert extracted
assert entailed
test annotator runs
test basic entailments
test basic extractions
test paper examples
test other examples
test extractions george boyd
test extractions obama wiki one
test extractions obama wiki two
test extractions obama wiki three
test extractions obama wiki four
test extractions obama wiki five
test extractions obama wiki six
test there is no doubt
test chess is not aphysical sport
test sara
test tom jerry
dummy test
found
extractions
extraction
expected set
actual
open ieitest
test play
test choose
test be
test use
test license
verb tense itest
get
mock word
mk segment
test load weights doesnt crash
test some sanity checks
weights
root
out edges
root vertex
edges
pair
spec
natural logic weights itest
check scope
annotator runs
negation mid sentence
all_x_verb_y
all_x_want_y
all_x_verb_prep_y
all_x_be_y
all_x_can_y
all_x_relclause_verb_y
all_of_x_verb_y
per_predicate
per_has_predicate
per_predicate_prep
per_has_predicate_prep
per_is_nn
per_is_jj
few_x_verb_y
a_few_x_verb_y
binary_no
unary_not
num_x_verb_y
at_least_num_x_verb_y
everyone_pp_verb_y
there_are_np
there_are_np_pp
one_of_the_x_y
regression strange comma
unary some
fracas sentences with all
fracas sentences with each
fracas sentences with every
fracas sentences with everyone
fracas sentences with few
fracas sentences with a
fracas sentences with afew
fracas sentences with at least afew
fracas sentences with either
fracas sentences with one of the
fracas sentences with several
fracas sentences with some
fracas sentences with the
fracas sentences with there are
fracas sentences with proper nouns
fracas sentences with at most at least
fracas sentences with pure numbers
fracas sentences with both
fracas sentences with many
fracas sentences with most
fracas sentences with neither
fracas sentences with binary no
fracas sentences with binary no one
temporal regressions
implicit negations but
implicit negations except
double negatives
binary negation out of order
scopes
subj begin
subj end
obj begin
obj end
guess
terms
quant end
seen subj
token index
clean sentence
term
quantifiers
operator scope itest
all cats have tails
there is no doubt that cats have tails
some cats dont have tails
complex proper nouns
temporal test cases
expected str
actual str
polarity itest
natural logic annotator itest
test slurp file
ioutils itest
to string
load expected results
save results
save key
compare chain
sent num
mention span
pieces
mention lines
mentions
mention line
chains
fout
bout
keys
key
chain
mention
expected chain
expected mention
map entry
integer coref chain entry
dcoref exact output itest
expected mention
make props file
test dcoref co nllresult v4
test dcoref co nllresult v801
run dcoref
run coref system
get final score
path
work dir
scorer
final score
work_dir_file
work_dir
props_path
coref system
return msg
conll output mention gold file
conll output mention coref predicted file
writer gold
writer predicted coref
mention extractor
summary
f1matcher
f1s
dcoref slow itest
run coref test
get coref results
test dcoref
delete on exit
base log file
current
current dir
coref args
log file
actual results
mention_tp
mention_f1
muc_tp
muc_f1
bcubed_tp
bcubed_f1
ceafm_tp
ceafm_f1
ceafe_tp
ceafe_f1
blanc_f1
conll_score
mention_pattern
muc_pattern
bcubed_pattern
ceafm_pattern
ceafe_pattern
blanc_pattern
conll_pattern
results string
low results
high results
dcoref benchmark slow itest
statistical coref fast benchmark slow itest
neural chinese coref co nllbenchmark slow itest
neural english coref co nllbenchmark slow itest
fast neural english coref benchmark slow itest
neural english coref benchmark slow itest
neural chinese coref benchmark slow itest
statistical coref co nllbenchmark slow itest
set low high expected
test chinese dcoref
print results tsv
low res
high res
exp res
low val
high val
exp val
where
chinese coref benchmark slow itest
logger
expected_f1_score
properties_path
work_dir_name
test name
final conll score
coref benchmark
deterministic chinese coref co nllbenchmark slow itest
deterministic chinese coref benchmark slow itest
run and test cdc
test no arg classify
gold file name
old out
old err
out stream
err stream
out print
err print
gold file
lines
gold line
result line
column data classifier itest
new datum
test str binary datums
label
features
counts
counter
d1f1
d1f2
d2f1
d2f2
train data
prior
lfc
shift params logistic classifier itest
test str multi class datums
datums
datum
td1
linear classifier itest
test xml
test plain text
test tagged
single tagger
multi tagger
tagged text
plain text
xml text
sout
single output
multi output
bin
multicore maxent tagger itest
test one tagger
test two taggers
tagger1
tagger2
test file
threaded tagger itest
test choose tokenizer
test tokenize test
run run tagger test
test run tagger stdin
test run tagger not stdin
test run tagger xml
test run tagger xml2tags
test run tagger many tags
run tag from xmltest
test tag from xmlsimple
test tag from xmltwo tags
test tag from xmlnested
test tag from xmlsingle tag
test tag from xmlescaping
test tag string
test tag core labels
test tagger wrapper
tokenizer
output strings
emulate stdin
xml tag
output line
tags
output writer
test words
config
wrapper
query
expected result
maxent tagger itest
get coref chain string
test statistical english slow
test statistical english fast
test neural english
test hybrid chinese
test neural chinese
english doc
english coref result
chinese doc
chinese coref result
return string
representative
output heading
coref result string
coref annotator sanity itest
test coref example
sample text
sample doc
pronominal mention
pronominal mention itest
test basic embedded same unicode
test basic allow embedded same unicode
test basic ascii quotes
test max length
test tis
test dashes
test basic internal punc
test basic latex quotes
test latex quotes with directed apostrophes
test embedded latex quotes
test embedded latex quotes no embedded
test embedded single latex quotes
test embedded latex quotes all end same place
test embedded latex quotes all end same place no embedded
test triple embedded latex quotes
test triple embedded latex quotes no embedded
test triple embedded unicode quotes
test basic ignore single quotes
test basic unicode quotes
test unicode quotes with bad unicode quotes
test unicode quotes with apostrophes
test basic double quotes
test unclosed initial quotes
test unclosed last double quotes
test double enclosed in single
test single enclosed in double
test embedded quotes
test embedded quotes two
test embedded mixed complicated
test quotes follow eachother
test basic single quotes
test unclosed last single quotes
test multi paragraph quote double
test multi paragraph quote single
test multi line quote double
test multi line quote single
test word beginning with apostrophe at quote beginning single quotes
test words with apostrophe terminals in one double quote
test words with apostrophe terminals in double quotes
test unclosed last double quotes unclosed annotation
run quotes
assert inner annotation values
assert embedded
assert embedded helper
run unclosed quotes
pipeline no single quotes
pipeline max five
pipeline ascii quotes
pipeline allow embedded same
pipeline unclosed quotes
quotes
embedded
second
unclosed quotes
num quotes
quote
quote index
sentence begin
sentence end
token begin
token end
quote tokens
bed
eqs
b embed
recurse
quote annotator itest
add language specific properties
set up paths
build pipeline
load sentences from co nllfile
tag co nllfile with pipeline
run eval script
parse results
get f1score
test dev
test test
ner_eval_script
fb1_pattern
language
pipeline properties
working dir
dev gold file
test gold file
dev predicted file
test predicted file
expected dev score
expected test score
return list
conll lines
curr sentence
curr nertags
conll line
conll fields
final co nlloutput
loaded sentences
annotated sentence
predicted co nllfile
eval cmd
input line
conll eval script results
result lines
found f1score
eval script results
gold file path
predicted file path
expected score
annotated co nll
nerbenchmark test case
check sentence token alignment correctness
test basic example
test basic newline example
test xmldoc
basic text
basic newline text
xml doc path
xml doc pipeline props
xml pipeline
xml doc contents
pipeline props
basic example
sentence one
sentence two
sentence three
token index four
token index seven
token index fifteen
basic newline example
sentence four
xml doc annotation
token index one
token index ninety six
token index two ninety three
token index five forty two
token index five fifty four
token begin end annotation itest
test non hyphen sentences
test hyphen sentences
data_path
ner tokenization pipeline
standard tokenization pipeline
pre tokenized pipeline
non hyphen containing sentences
ner tokenization doc
standard tokenization doc
hyphen containing sentences
hyphen containing sentences pre tokenized
pre tokenized doc
nertokenization slow itest
language specific set up
nerbenchmark french slow itest
test requires
test requires for coref
check ner
test regex ner
test relation extractor
process serialization
test sentence newlines
test sentence newlines two
test sentence newlines three
check sutime annotation
test sutime property
vertex
string writer
message
coremap
coremap output
ner
debug
rel
oout
oin
first sentence
sent tokens
n expected sentences
n expected tokens
expected normalized ner
pipeline1
expected values1
pipeline2
expected values2
stanford core nlpitest
launch server
test live
test ready
test client
test client failure
post url
slurp url
test tregex json
test semgrex json
test semgrex annotation
test semgrex filter
server url
connection
response
query params
stanford core nlpserver itest
make sentence
make sentence core map
check labels
test words plannotation
test multiple words plannotation
test sentences annotation
test multiple sentences annotation
make annotation
test multicore annotation
test empty annotation
map
test sentences
short text
long text
first labels
second labels
labels
second sentence
local tagger
short ann
ann2
short ann2
postagger annotator itest
test quantifiable entity normalizing annotator
normalization
answer_text
answer_time
quantifiable entity normalizing annotator itest
expected tokens
pre tokenized sentence split itest
test french mwttokenization basic
french text basic
french text capitalized
capitalized doc
french text all caps
all caps doc
french pipeline preserve casing
capitalized doc preserve casing
all caps doc preserve casing
mwtannotator itest
test apostrophe match
apostrophe text
sample annotation
entity mention
matching entity mention index
entity mention2
matching entity mention index2
entity mention coref itest
tokenizer before after itest
test on dev
test on test
tokenizer french benchmark itest
test invalid outputter
test simple sentence
co nlluoutputter itest
test chinese segmentation
input strings
expected token lists
example one token list
example two token list
example three token list
example count
input string
found tokens
chinese segmenter regression itest
check tags
test basic matching
test overwrite
test priority
mapping
annotator
str
split
corpus
regex nerannotator itest
compare tokens lists
compare entity mentions lists
compare quotes lists
find core map difference
serializer
original doc
new doc
original tokens
new tokens
original mentions
new mentions
original quotes
new quotes
original core map
read core map
sample document
kis
read annotation
protobuf serialization sanity itest
test pipeline
join
token text
token pos
token lemma
token ne
tokens text
text1
sentence1
tree1
token text1
tokens1
text2
sentence2
tree2
token text2
tokens2
pipeline itest
test stanford core nlpspeed
test stanford core nlpspeed multi thread
dir
kbp2016file list
start time
current doc
end time
duration
files
kbp file paths
stanford core nlpspeed slow itest
kbpannotator spanish benchmark slow itest
test simple sentence co nll
test simple sentence json
annotation outputter itest
test simple
test collapsed graphs
test two sentences
test copy word graphs
verify sentence
verify tree
verify graph
verify word
full pipeline
serialized
deserialized
token annotations
custom annotation serializer itest
test pipeline annotator
test threaded annotator
verify answers
get test data
check annotation
test combined annotation
test statistical only option
test rules only option
ner_3class
ner_7class
ner_miscclass
ner annotator
unthreaded pipeline
threaded4pipeline
threaded4annotator
unthreaded annotator
sentence index
text
answers
include answer
col reader
str reader
gold input string
gold docs
test docs
gold doc
test doc
gold tokens
test tokens
gold token
test token
gold ner
test ner
examples
gold nertags
nercombiner annotator itest
mk annotation
mk large annotation
same as read
possible annotators
test annotators
test sentiment
test openie
test quote
test get possible annotators
test save
test save large
test save size
test can write read
test can write read clean xml
diff core maps
test can write read write read large file
test relation
test udfeats
test serialize ssplit tokens regression
test serialize nat log
test gender
test code point
test doc date
test calendar
test shift reduce
test annotator combinations
thorough_test
pride and prejudice chapters1to5
pride and prejudice chapters1
pride and prejudice first bit
pride and prejudice first sentence
read doc
doc token
read doc token
doc long value
read doc long value
numerized token
tok a
tok b
key a
key b
sent a
sent b
annotators
additional property
annotators as array
empty props
complete annotators list
json
compressed impl
compressed
uncompressed proto
compressed proto
pipe
cm1
cm2
pair1
ks2
kis2
read doc2
reread
combinations to try
combination
protobuf annotation serializer slow itest
tokenizer german benchmark itest
get type
build core label
sentence id
sentence text
gold tokens list
gold tokens string
system tokens string
tokenize sentence text
placeholder mwttoken
contained by multi word token
is multi word token of
f1stats
load tokenizer test examples
f1scores
test examples
system tokens list
conll_u_token_start
length_of_sentence_id_prefix
length_of_text_prefix
char begin
char end
curr mwt
mwt range
curr mwttoken
example tokens doc
tok
contained token
begin position
placeholder token
split token
multi word placeholder token
mwt placeholder begin
mwt placeholder end
found match
all lines
eval set
lang
expected f1
all f1stats
test example
tokenizer benchmark test case
mwttoken character offset begin annotation
mwttoken character offset end annotation
test example
process test example
string lists to core labels
test english nertokenization
test english nertokenization just statistical
test english nertokenization with ptb3escaping just statistical
test english nertokenization turned off
test german nertokenization
test french nertokenization
ner labels
docs
example doc
nertokenization itest
spanish to english tag
load co nlldocs
create pipeline annotations
write perl script input to path
test chinese neron onto notes dev
test chinese neron onto notes test
test english neron co nlldev
test english neron co nlltest
test english neron onto notes dev
test english neron onto notes test
run nertest
ner_benchmark_working_dir
spanish tag
curr doc
curr nertag list
doc pair
conll docs
conll doc
conll doc annotation
annotations
perl script input
doc num
curr annotation
curr co nlldoc
curr annotation tokens
token num
perl script line
input co nllfile
conll test path
chinese pipeline
english pipeline
f1threshold
conll annotations
model score
nerbenchmark slow itest
convert annotations
get annotations
test two threads
converted
file
num threads
num docs
baseline
threaded stanford core nlpslow itest
core nlpthread
test span string
test named span string
found noun phrase strings
gold noun phrase strings
sentence one span string gold
sentence one span string
node name
span string itest
test xmldoc with newlines
xml doc sentence tokens
xml doc char offsets
resource_dir
xml file path
xml annotation
token char offsets
chinese tokenization itest
get mentions annotator
compare mentions
test basic mentions
test dates
test dates2
test numbers
test percent
test news text
entity_mentions_annotator_name
prefix
expected mentions
min matchable
entity mentions annotator itest
test english wsjdev pos
test english wsjtest pos
test english bi directional wsjdev pos
test english bi directional wsjtest pos
test english caseless wsjdev pos
test english caseless wsjtest pos
test chinese test pos
test french dev pos
test french test pos
test german dev pos
test german test pos
test spanish dev pos
test spanish test pos
run postest
model path
data path
expected token accuracy
args string
test classifier
postagger benchmark itest
test deterministic coref annotator
test same string
coref props
chain id
ramage token
he token
ramage cluster id
your moms token
she token1
she token2
denver token1
denver token2
your moms cluster id
she1cluster id
she2cluster id
denver1cluster id
denver2cluster id
itest
deterministic coref annotator itest
nerbenchmark spanish slow itest
get file list
test no crashes
test parallelism
path file
sub file
sub sub file
sgml file
stanford core nlpslow itest
load gold data
convert relation name
convert kbptriples to strings
test kbpannotator results
doc idto text
doc idto relations
kbp_docs_dir
gold_relations_path
kbp_minimum_score
gold relation lines
relation line
doc idand relation
directory with docs
all files
kbp test doc file
kbp test doc id
kbp test doc path
kbp test doc contents
relation name
relation triple list
found relation strings
relation string
total gold relations
total correct found relations
total wrong found relations
total guess relations
final f1
doc id
doc gold relation set size
relation triples for this doc
rt list
gold relation
intersection of found and gold
recall
precision
kbpannotator benchmark
test default pipeline
example
entity mentions
nerconfidence itest
kbpannotator chinese benchmark slow itest
test one
expected words
expected begin positions
expected end positions
chinese segmenter annotator itest
test tag set4
test english tag set
test german tag set
test german udtag set
test chinese tag set
test spanish tag set
test french tag set
test arabic tag set
tags to ignore
lex parsers
maxent taggers
sr parsers
nn dep parsers
ref tagger name
ref tagger
tag set
name
maxent tag set
lex parser tag set
srp
sr parser tag set
nn dep parser tag set
english taggers
english parsers
english sr parsers
english nn parsers
german taggers
german parsers
german sr parsers
german nn parsers
german udtaggers
german udparsers
german udsr parsers
german udnn parsers
chinese taggers
chinese parsers
chinese sr parsers
chinese nn parsers
spanish taggers
spanish parsers
spanish sr parsers
spanish nn parsers
french taggers
french parsers
french sr parsers
french nn parsers
arabic taggers
arabic parsers
arabic sr parsers
arabic nn parsers
tagger parser pos tag compatibility itest
test chinese serialization
sample chinese document
chinese properties
doc chars
read doc chars
num chars
curr char
doc json
read doc json
chinese serialization itest
coref_example
coref_example_two
coref doc one
coref doc two
quote one
quote two
quote attribution annotator itest
test two newline is sentence break tokenize nls
test two newline is sentence break
test newline is sentence break tokenize nls
test newline is sentence break never
test eol only
test is one sentence
headline
document1
words to sentences annotator itest
test full pipeline
expected characters
expected segs
expected ner
characters
expected positions
chinese annotation pipeline itest
build french pipeline
expected ner
expected dependency parse
pipeline properties itest
get tokens regex ner annotator
check ner tags
reannotate
test tokens regex syntax
test tokens regex match group
test tokens regex normalized annotate
test tokens regex custom annotate
regex_annotator_name
caseless
cased
ignore case
temp file
regexes
annotator cased
annotator caseless
tokens regex nerannotator itest
test annotation
test annotator sequence
test depparse pipeline
test quote pipeline
test true case pipeline
test open iepipeline
test mention regression
dummy string
keys read
annotator i
annotator name
corenlp
declared
used
requirements correct slow itest
kbpannotator english benchmark slow itest
test reading in co nllufile
example document
example path
gold document
read in document
gold sentence
read in sentence
gold graph
read in graph
co nllureader itest
test core quote
test doc text
canonical entity mention
core quote sanity itest
sentence count
core sentence
sentence two offsets
expected lemmas
expected part of speech tags
expected named entity tags
expected parse
expected coref
arizona mention from sentence
arizona mention from document
expected noun phrases
expected verb phrases
tregex pattern
expected result tree
kbp relations from sentence one
sentence one relation one
gold sentence one relation one
first entity mention
fifth entity mention
gold first entity mention char offsets
gold fifth entity mention char offsets
first quote
read core document
core wrapper itest
test parens
expected start positions
arabic segmenter annotator itest
mwtprotobuf serialization itest
run sentence
test true case annotator
verbose
ans
tcw
text3
ans1
text4
text5
text6
ans4
true case annotator itest
read in expected nerlabels
run model test
test english3class
test english4class
test english7class
pipeline3class
pipeline4class
pipeline7class
expected path
expected lines
expected nerlabels
expected line
input file
output file
input sentences
expected labels
three class input
three class output
four class input
four class output
seven class input
seven class output
nerpipeline end to end slow itest
nerbenchmark german slow itest
check result
test morpha annotator
get test words
short pipeline
lemma
answer
tokenized text
tokenized tags
morpha annotator itest
test no posparser annotator
test parser annotator
test max len
test timeout
test threaded timeout
test flatten
assert parse ok
test annotator constructors
no pospipeline
no parser pipeline
parser only pipeline
timeout pipeline
threaded3timeout pipeline
threaded4timeout pipeline
threaded3pipeline
flat pipeline
parse
answer
tagged_xparses
xparses
parser annotator itest
annotation comparator
tokenizer spanish benchmark itest
test not spanish
test spanish tokenizer
spanish text
spanish tokens
spanish tokens2
tokenizer annotator itest
test load from one file
test load from two file
word vector file
word file
vector file
embedding
values
embedding itest
test multi word normalization
read tree
multi word test cases
test case
tree rep
spanish tree normalizer itest
run once before class
run once after class
test ordinals
expected numbers
expected texts
num
expected number
expected type
number normalizer itest
test currency old
test currency new
test cd old
test cd new
nsc old
nsc new
number sequence classifier expected output itest
load classifier
run classifier
get results string
run threaded test
default_sim_threads
default_multiple_threads
input encoding
load path
crf
thread name
millis
base results
model names
classifiers
base
repeated
classifier num
repeat num
thread results
test threaded crfclassifier
crfthread
test one english crf
test one german crf
test two english crfs
german1
german test file
english1
english2
english test file
threaded crfclassifier itest
test pku crf
test ctb crf
test two crfs
crf1
crf2
threaded segmenter itest
test crf
run simple crftest
run crftest
adapt
adapt2
run kbest test
run zero order
ner path
caseless path
test texts
caseless tests
test trip
offsets
is stored answer
txt1
crf caseless
prf
ioe
trip
mid
ret
strs
max
ner path2
iobes answers
k_best
txt
obw
input2
sequence model
k best sequences last
k best
k best sequences
best sequence
best1
last answer
beam
beam2
best
best token
probs
crfclassifier itest
test german crfclassifier training
log
tempdir
german training results
last line of results
scanner
train crfclassifier slow itest
test true caser
nlp
start_text
end_text
arg
anno
count
make numeric pipeline
test money
test ordinal
test date
test number
test time
test duration
normed
header
texts
answers
money strings
money answers
money normed
ordinal strings
ordinal answers
ordinal normed
date strings
date answers
date normed
number strings
number answers
number normed
time strings
time answers
time normed
duration strings
duration answers
duration normed
number sequence classifier itest
run and check
_test money
_test length
_test weight
extractor
normalized value
type
matched expressions
matched expression
value
expected quantity
actual quantity
quantifiable entity extractor itest
expected quantity
convert
eval conll
read tokens from onto file
eval onto
test con lldev
test con lltest
test onto dev
test onto test
conll_base_dir
conll_train
conll_dev
conll_test
conll_output_train
conll_output_dev
conll_output_test
onto_base_dir
onto_dev
onto_test
conll_eval
conll nerannotator
conll nerannotation pipeline
onto nerannotator
onto nerannotation pipeline
conll03_dev_total_f1
conll03_dev_loc_f1
conll03_dev_misc_f1
conll03_dev_org_f1
conll03_dev_per_f1
conll03_test_total_f1
conll03_test_loc_f1
conll03_test_misc_f1
conll03_test_org_f1
conll03_test_per_f1
onto_dev_total_f1
onto_dev_loc_f1
onto_dev_org_f1
onto_dev_per_f1
onto_test_total_f1
onto_test_loc_f1
onto_test_org_f1
onto_test_per_f1
ner props
tokenizer props
f1results
idx
orig tag
results file
cmd
dataset
flags
writer
itr
gold labels
doc string
doc annotation
predict labels
num labels
gold
predict
predict str
predict prefix
parsed f1
curr sentence tokens
words seen
entries
ner tag
onto sentences
sentence labels
sentence annotation
gold prefix
total f1
loc f1
org f1
per f1
check features
test sloppy gazette
feature
padded sentence
factory
collector
nerfeature factory itest
start nerserver
test query server
test server doesnt hang
test threaded server
english crfpath
loaded query file
charset
query
expected_answer
classifier
charset
all queries
query word
sin
host
query text
nerserver itest
nerclient thread
test scene graph
expected edges
expected nodes
scene
predicted
expected attributes
attributes
rule based parser itest
test home
test paths
benchmark results
val
high
low
benchmarking helper
test title case check
test to title case
title case itest
test only gloss
test full tokens
test parse array
test parse trees
in2
out2
tsvsentence iterator itest
get reader from in java nlp
test large data set
test emoji
test reader
gold results
test results
compare size
npe
loc
gold reader
hex number
line number
orig string
codepoints
cp upto
num str
emoji
ptbtokenizer itest
test french
french sentences
french sentence token lists
example sentence
example sentence tokens
example sentence core document
french tokenizer annotator itest
test disambiguation
verb stripper
verb
an cora pronoun disambiguator itest
run spanish
test spanish tokenizer word
test spanish tokenizer core nlp
test offsets spacing
test offset
test offsets text original text
test clitic pronoun offset
test ir
test contraction offsets
test compound offset
spanish inputs
spanish gold
ancora spanish gold
spanish tokenizer
aioobe
begin offsets
end offsets
original texts
spanish tokenizer itest
test spanish
spanish tokenizer annotator itest
test find split point
test split trivial
test split
test split three sentences
test split three sentences with conj
tree reader factory
t1first
t1second
t2first
t2intermediate
t2second
t2third
t3first
t3intermediate
t3second
t3third
split point
expected split
tree string
an cora processor itest
test strippable
check pronouns
test separate pronouns
test strip verb
original stem
normalized stem
pronouns
pronoun list
spanish verb stripper itest
test post processor
test umlauts
test umlaut spaces
input text
ordinal example
ordinal example gold tokens
number range example
number range example gold tokens
abbreviation example
abbreviation example gold tokens
fur
furry
umlaut example
umlaut gold tokens
antik
german tokenizer post processor itest
test nerstanford dependencies
test neruniversal dependencies
graph
pat str
pat
mat
semgrex pattern itest
test single thread
test three threads
test four threads
ner annotator properties
nlp pipeline
spied properties
temp path
output path
docsents path
sentence map
sentence map stream
patterns simple threaded itest
show
show list selection dialog
mouse clicked
get files
pattern
frame
panel
location
jar file
dialog
file list
mouse listener
scroll
okay
evt
cancel
gridbag
zin
entry
jar file chooser
get members
get symbol
get block
get unminimized fa
get symbols
minimize fa
build minimized fa
project node
has split
get split
add split
sort into blocks
make block
add splits
remove all
difference
get inverse images
get inverse arcs
make initial blocks
minimize
unminimized fa
member to block
sparse mode
sink_node
members
symbol
block
minimized fa
arc
source
target
node
block to members
member
symbol to target
inverse images
arcs
arc1
end nodes
non final nodes
inverse images by block
path list
random fa
quasi determinizer
minimizer
ntsp
isp
ocp
det graph
comb graph
min outputs
fast exact automaton minimizer
split
block
has active pair
get active pair
add active pair
active pairs
active pair
active block
minimized random fa
exact automaton minimizer
score
set score
initial state
set initial state
states
explore states
print trie dfsahelper
print trie dfsa
print att fsm format
print trie as rules helper
print trie as rules
dfsa id
visited
to visit
state
level
transition
dfsa
inputs2
all terminate
transition2
target2
new prefix
ucompacted fa
get source
get target
get id
get input
get output
transition id
set state id
state id
add transition
transitions
continuing inputs
successor states
set accepting
is accepting
is continuable
hash code
equals
states reachable
input to transition
accepting
successors
hash code cache
process graph
compute lambda
push lambdas
lambda
queue
first
old len
new node
new len
cnse
source lambda
target lambda
old output
new output
start lambda
start arcs
end lambda
end arcs
new graph
quasi determinizer
set determinism
clone
get arcs
get nodes
get inputs
set start node
set end node
get start node
get end nodes
get arcs by input
get arcs by source
ensure
get arcs by target
get arc by source and input
get arcs by target and input
get arc
add arc
remove arc
can add arc
get source node
get target node
set source node
set target node
set input
set output
process arc
process node
set dot weighting inverted
as dotstring
in flow
out flow
sum outputs
get source total
get output of path in graph
sample uniform path from graph
sample paths from graph
print path outputs
get path outputs
test graph paths
can add path
create graph from paths
add one path to graph
create random graph
create random paths
depth first search
depth first search helper
epsilon_input
default_start_node
arcs by source
arcs by target
arcs by input
arcs by source and input
arcs by target and input
start node
check determinism
other
arc processor
node processor
new arcs
arc processor2
arcs from source
arcs to target
iterator
source node
target node
sample node
forward
forward normalization
my arcs
total
dot weight inverted
inverted
mag
htd
clean string
weight
sum
list
num paths
print paths
a path
output list
source graph
test graph
new score
paths
markov order
path counter
path length mean
path length variance
num inputs
path length
marked
new arc
transducer graph
unweighted minimize
unweighted minimize old
time
num states
state to id
state1
distinct
dependent list
state2
distinguishable
pending ipairs
input i
transition1
target1
num1
num2
target ipair
mark stack
ip to mark
add list
pending ipair
dependent list1
state classes
state to rep
rep
state upair to dependent upair list
state upair to distinguished
streak
collisions
num done
bucket
pending upairs
target upair
up to mark
pending upair
dfsaminimizer
int pair
check dic
check in dic
a d
default_corpora_dict
corpora dict
cc path
ad path
tag affix detector
initialize training
train
finish training
load segmenter
segment
add string to lexicon
add lexicon
build segmentation lattice
max match segmentation
segment words
greedily segment words
println err
post process sentence
starts with chinese
ends with chinese
is chinese
exclude char
debug
len
edges nb
max length
lattice
minwords
maxwords
maxlen
chinese start chars
chinese end chars
chinese chars
exclude chars
num trees
post processed sent
post processor
post sent string
post sent array
post sent
lexicon reader
lexicon line
is one char
is in dict
cost
trans
segmented words
costs
bptrs
from state
trs
to state
lcost
density
next word
seg
lexicon file
sighan rw
stdout w
line nb
str r
new sent
prev word
cur word
prev char
cur char
merged word
serial version uid
max match segmenter
get table
read dict
contains
get w
one word
normalize
word detector reader
word detector line
orig leng
new leng
corpus dictionary
init
create tadetector
create out dict
create non dict
get clique features
is english
is eng pu
dictionary features c
features c
dictionary features cp c
features cp c
features cn c
features cp cp2c
features cp cp2cp3c
ta detector
out dict
non dict
c info
clique
pat e
pat ec
chp
chc
mp c
mc c
pat p
lbegin field name
lmiddle field name
lend field name
dict suffix
lbegin
lmiddle
lend
charc
charc2
charc3
charp
charp2
charp3
c i
u typec
c2i
u typec2
c3i
u typec3
p i
u typep
p2i
u typep2
p2lend
p lend
p lbegin
c lbegin
c lmiddle
rcharc
rcharc2
rcharp
rcharp2
tagsets
tag
cur1
cur2
cur
pre
prer
eng type
eng pu
orig s
orig c
p3i
u typep3
default_home
input filename
output filename
reader and writer
split bigrams
fin
iterable
prev sentence
bigram
non dict2
basedir
model
dict
segmenter
sample
segmented
seg demo
get char map
get tag
char map
charlist filename
char_dict
detector reader
detector line
chars
corpus char
get iterator
apply
shape of
add dictionary features
print plain text answer
print conllu answer
print answers
intern
print lattice
tag lattice to answer lattice
debug_more
date chars
date chars plus
number chars
letter chars
period chars
separating punc chars
ambiguous punc chars
mid dot pattern
cdtos
cdict
cdict2
plaintext
conllu
output format
dicts
dict
dicts2
default map
lwi
orig line
orig index
position
code point
surrogate
word string
shape
lwi size
leng
last
ans str
tag lattice
doc array
node id
answer lattice
a init state
state links
t source
a source
cur label
cur chr
orig space
answer constraint
min cost
predict space
transition cost
t dest
new asource
new answer
answer len
prev chr
new cost
a dest
sighan2005document reader and writer
ctbdocument parser
is letter ascii
combine segmented sentence
post processing answer
separate puncs
compile punctuation patterns
get escaped punc pattern
process colons
compile colons white patterns
compile colon patterns
process percents
process dots
glue punc
process commas
percents pat
percent str
hk post processor
as post processor
basic posts processor
ctp post processor
pk post processor
test content idx
unmod_ans
unmod_normed_ans
word iter
pwi
original white space
keep all whitespaces
num pat
punc patterns
correct punc
suppress mid dot postprocessing
pattern map
puncs
colons pat
colons
percents white pat
colons white pat
puncs pat
punc
colon
dots
non num pat
commas
chinese string utils
pkpost processor
ctppost processor
aspost processor
hkpost processor
base chinese post processor
get in dict
ins
affix filename
a detector reader
a detector line
affix dictionary
serialize dictionary
load dictionary
add dict
add one dict
max_lexicon_length
words_
cdtos_
serialize path
oos
ser dicts
expand mid dot
dictwords
mid dot
item
sub item
input dicts
flag map
args map
chinese dictionary
charc1
rcharc1
rcharc3
rcharp1
rcharp3
tagset
copy
get random sequence
find best using sampling
find best using annealing
collect samples
sample sequence repeatedly
sample sequence forward
process
new instance
sample sequence backward
sample position
sample position helper
print samples
random
verbose
num samples
sample interval
speed up threshold
listener
random_sampling
sequential_sampling
chromatic_sampling
prior en
prior ch
return last found sequence
sampling style
chromatic size
partition
classes
initial sequence
samples
best score
sequence
schedule
positions changed
temperature
return score
only sample these positions
a sequence
indie list
new pos prob
pos list
all pos
interval
indie list size
pos val
distribution
argmax
new tag
new prob
old tag
sequence gibbs sampler
info
prime next helper
has next
process document
fix
do basic stuff
fix doc lengths
iob tags
merge tags
add
add all
clear
clear memory
contains all
is empty
keep in memory
remove
retain all
size
wrapped
known lcwords
wrapped iter
spillover iter
month day pattern
max doc size
wts
new documents
new document
last tag
keep
best sequence with linear constraints
init product sizes
compute window score
forward viterbi initial
forward viterbi
linear constraints
left window
right window
pad length
tag num
product sizes
temp tags
window score
trace
best final score
best current product
product
product end
last product
tag num_last
temp product
best next product
prev pos
window
cur product
tag num_pos
product sizes_pos
window score_pos
shift
cur pos
end cur pos
oldp
products
score_pos
trace_pos
linear constraints_pos
score_product
endpos
score_posm1
tag num right
tag num left
factor
trace_product
shared product
window product score
new tag num
pred product
pred score
exact best sequence finder
known
three_classes_property
three_classes
verbose for true casing
alphabet
raw
known words
wrong
alpha matcher
all lower
all upper
start upper
toks
lower matcher
upper matcher
start upper matcher
is init_upper
lcw2
true casing for nistdocument reader and writer
line to true cases parser
from short name
default to preserve spacing
get answers
print answers tokenized text
print answers as is text
print answers tokenized text tsv
print answers as is text tsv
print answers as is text tabbed
print answers tokenized text tabbed
print answers xml
print answers tokenized xml
print answers inline xml
print answers tokenized inline xml
slash_tags
xml
inline_xml
tsv
tabbed
short name
short names
style
sgml
tokenizer factory
options
clazz
factory method
previous
prepend
before
after
previous token after
output style
preserve spacing
background
last entity type
entity type
prev
prev tag
after ws
bits
gold answer
lib svmreader and writer
column doc parser
include probabilities
white pattern
line count
answer prob
column document reader and writer
entity subclassify
is entity boundary
is same entity boundary
is different entity boundary
count entity results
background label
how
lower style
padded tokens
new answers
c ans
p ans
n ans
p base
p prefix
n base
n prefix
is start adjacent same
is end adjacent same
is first
is last
before entity
before prefix
after entity
after prefix
entity tp
entity fp
entity fn
entity correct
previous gold
previous guess
previous gold entity
previous guess entity
previous gold prefix
previous guess prefix
gold entity
guess entity
guess prefix
new gold
new guess
gold ended
guess ended
iobutils
mallet reader and writer
mallet doc parser
sequence sampler
get cliques
each clique
add all interning and suffixing
get word
clique c
clique cp c
clique cp2c
clique cp3c
clique cp4c
clique cp5c
clique cp cp2c
clique cp cp2cp3c
clique cp cp2cp3cp4c
clique cp cp2cp3cp4cp5c
clique cn c
clique cp cn c
known cliques
left
right
consumer
max left
max right
cliques
accumulator
addend
suffix
non null suffix
feat
num ways to make
pos max
product max
score pos
trace pos
max tag num
score pos prev
which derivation
best current products
best final scores
k best with scores
kbest sequence finder
get doc iterator
get next
create doc
mark boundary
delimiter pattern
whitespace pattern
replace whitespace
tokens annotation class name
token factory
delimiter regex
map string
token factory class name
include text
next item
get next func
doc get next
tokens annotation class
text key
glue
keep boundaries
return tokens on empty line
has doc id
has doc start
doc id
new doc id
item cnt
line cnt
return segments as docs
sentence boundaries
doc text
tokens class
set token char offsets
boundaries
cur word index
last word index
token str
split into docs
make core label
de endify
maybe increment counter
boundary
treat_file_as_one_document
doc pattern
white
string iter
chunk
in progress misc
misc counter
num tokens
num entities
last ans base
ans base
ans prefix
co nlldocument reader and writer
co nlliterator
get exponential schedule
num iterations
get temperature
get linear schedule
iteration
rate
cooling schedule
begin entity
end entity
section
entity
entity class
p num
s num
w num
ptb
prev string
prev answer
prev class
after last
mucdocument reader and writer
mucdocument parser
update sequence element
set initial sequence
model1
model2
models
old val
factored sequence listener
tmp tags
extend with
tclone
beam size
exhaustive start
recenter
new beam
init seq
old beam
tag seq
next tag num
next seq
a new beam1
a new beam
best seq
seq
beam best sequence finder
tag seq
tag list
get graph
class index
viterbi search graph
graph states
start state
end state
state id
cur tag
pred tag
source state
dest state
viterbi search graph builder
set properties
flags to num args
get feature factory
get not null true string rep
default_background_symbol
string rep
use ngrams
conjoin shape ngrams
lowercase ngrams
dehyphenate ngrams
use prev
use next
use tags
use word pairs
use gazettes
use sequences
use prev sequences
use next sequences
use long sequences
use boundary sequences
use taggy sequences
use extra taggy sequences
dont extend taggy
use taggy sequences shape interaction
strictly zeroeth order
strictly first order
strictly second order
strictly third order
entity subclassification
retain entity subclassification
use gazette phrases
make consistent
use viterbi
binned lengths
verbose mode
use sum
tolerance
print features
use sym tags
use sym word pairs
print classifier
print classifier param
intern2
self test
sloppy gazette
clean gazette
no mid ngrams
max ngram leng
use reverse
greekify ngrams
use paren matching
use lemmas
use prev next lemmas
normalize terms
normalize timex
use nb
use qn
use float
qnsize
qnsize2
max iterations
word shape
use shape strings
use type seqs
use type seqs2
use type seqs3
use disjunctive
disjunction width
use disjunctive shape interaction
use disj shape
use word
use class feature
use shape conjunctions
use word tag
use nphead
use npgovernor
use head gov
use last real word
use next real word
use occurrence patterns
use typey sequences
justify
prior type
sigma
epsilon
use position
use begin sent
use gaz features
use more gaz features
use abbr
use minimal abbr
use abbr1
use minimal abbr1
use more abbr
delete blank lines
use genia
use tok
use abstr
use abstrfreq dict
use abstrfreq
use freq
use abgene
use web
use webfreq dict
use is url
use urlsequences
use is date range
use entity types
use entity type sequences
use entity rule
use ordinal
use acr
use ante
use more tags
use chunks
use chunky sequences
use prev vb
use next vb
use vb
sub cwgaz
document reader
use wide disjunctive
wide disjunction width
use radical
use bigram in two clique
morph feature file
use reverse affix
char half window
use word1
use word2
use word3
use word4
use rad1
use rad2
use wordn
use ctbpre1
use ctbsuf1
use asbcpre1
use asbcsuf1
use pkpre1
use pksuf1
use hkpre1
use hksuf1
use ctbchar2
use asbcchar2
use hkchar2
use pkchar2
use rule2
use dict2
use out dict2
out dict2
use dictleng
use dict ctb2
use dict asbc2
use dict pk2
use dict hk2
use big5
use neg dict2
use neg dict3
use neg dict4
use neg ctbdict2
use neg ctbdict3
use neg ctbdict4
use neg asbcdict2
use neg asbcdict3
use neg asbcdict4
use neg hkdict2
use neg hkdict3
use neg hkdict4
use neg pkdict2
use neg pkdict3
use neg pkdict4
use pre
use suf
use rule
use hk
use msr
use msrchar2
use pk
use as
use filter
large ch seg file
use rad2b
keep english whitespaces
sighan post processing
use ch pos
normalization table
dictionary
serialized dictionary
dictionary2
norm table encoding
sighan corpora dict
use word shape gaz
word shape gaz
split documents
print xml
use seen features only
last name list
male name list
female name list
train file
adapt file
dev file
text files
read stdin
load text classifier
load jar classifier
load aux classifier
serialize to
serialize to text
interim output freq
initial weights
gazettes
self train file
bio submit output
num runs
answer file
alt answer file
drop gaz
print gaz features
num start layers
dump
split on head
feature count threshold
feature weight threshold
feature factory
feature factory args
background symbol
use observed sequences only
print probs
print first order probs
save feature index to disk
remove background singleton features
do gibbs
use nerprior
use acq prior
use uniform prior
use mucfeatures
annealing rate
annealing type
load processed data
init viterbi
use unknown
check name list
use sem prior
use first word
use number feature
ocr fold
ocr train
classifier type
svm model file
inference type
use lemma as word
combo props
use prediction
use alt gaz features
gaz files file
use prediction2
base train dir
base test dir
train files
train file list
test files
train dirs
test dirs
use only seen weights
pred prop
pad
use observed features only
dist sim lexicon
use dist sim
remove top n
num times remove top n
randomized ratio
remove top npercent
purge features
boolean features
iob wrapper
use segmentation
memory thrift
timit datum
serialize datasets dir
load datasets dir
push dir
purge datasets
keep obin memory
fake dataset
restrict transitions timit
num datasets per file
use title
lower newgene threshold
use either side word
use either side disjunctive
two stage
crf type
feature threshold
feat thresh file
feature diff thresh
num times prune features
newgene threshold
do adaptation
use internal
use external
self train confidence threshold
self train iterations
self train window size
use huber
use quartic
adapt sigma
num folds
start fold
end fold
cache ngrams
use smd
use sgdto qn
use stochastic qn
use scaled sgd
scaled sgdmethod
sgdpasses
qnpasses
tune sgd
stochastic method
initial gain
stochastic batch size
use sgd
gain sgd
use hybrid
hybrid cutoff iteration
output iterations to file
test obj function
test variance
sgd2qnhess samples
test hess samples
crforder
crfwindow
estimate initial
biased train file
confusion matrix
output encoding
use kbest
search graph prefix
search graph prune
use features c4gram
use features c5gram
use features c6gram
use features cp c4gram
use features cp c5gram
use features cp c6gram
use unicode type
use unicode type4gram
use unicode type5gram
use4clique
use unicode block
use shape strings1
use shape strings3
use shape strings4
use shape strings5
use good for names cp c
use dictionary conjunctions
print features upto
use dictionary conjunctions3
use word utype conjunctions2
use word utype conjunctions3
use word shape conjunctions2
use word shape conjunctions3
use mid dot shape
augmented date chars
print nr
class bias
print label value
use robust qn
combo
use generic features
train hierarchical
domain
transfer sigmas
do fe
restrict labels
announce object bank entries
l1reg
mixed case map file
aux true case models
use2w
use lc
use yet more cp cshapes
use if integer
export features
use in place sgd
use topics
evaluate iters
evaluate train
tune sample size
use phrase features
use phrase words
use phrase word tags
use phrase word special tags
use common words feature
use proto features
use wordnet features
token factory args
tokenizer options
use coref features
wiki feature db file
use noisy non noisy feature
use year
use sentence number
use label source
cased dist sim
dist sim file format
dist sim max bits
number equivalence dist sim
unknown word dist sim class
use neighbor ngrams
word function
default_plain_text_reader
plain text document reader and writer
use bag of words
evaluate background
num lop expert
initial lop scales
initial lop weights
include full crfin lop
backprop lop training
random lop weights
random lop feature split
non linear crf
second order non linear
num hidden units
use output layer
use hidden layer
gradient debug
check gradient
use sigmoid
skip output regularization
sparse output layer
tie output layer
block initialize
softmax output layer
load bisequence classifier en
load bisequence classifier ch
bisequence classifier prop en
bisequence classifier prop ch
bisequence test file en
bisequence test file ch
bisequence test output en
bisequence test output ch
bisequence test alignment file
bisequence alignment test output
bisequence prior type
bisequence alignment prior penalty ch
bisequence alignment prior penalty en
alignment prune threshold
alignment decode threshold
factor in alignment prob
use chromatic sampling
use sequential scan sampling
max allowed chromatic size
keep empty sentences
use bilingual nerprior
sampling speed up threshold
entity matrix ch
entity matrix en
multi thread gibbs
match nerincentive
use embedding
prepend embedding
embedding words
embedding vectors
transition edge only
prior lambda
add capital features
arbitrary input layer size
no edge feature
terminate on eval improvement
terminate on eval improvement num of epoch
use memory evaluator
suppress test debug
use owlqn
print weights
total data slice
num of slices
regularize softmax tie param
softmax tie lambda
total feature slice
num of feature slices
add bias to embedding
hardcode softmax output weights
use nerprior bio
entity matrix
multi thread classifier
use dual decomp
bi alignment prior is pmi
damp ddstep size with alignment prob
dual decomp alignment
dual decomp initial step size alignment
dual decomp not bio
berkeley aligner load path
use berkeley aligner for viterbi
use berkeley competitive posterior
use denero
align ddalpha
factor in bi edge potential
no neighbor constraints
include c2eviterbi
init with posterior
ner skip first k
ner slower times
power align prob
power align prob as addition
init with nerposterior
apply nerpenalty
print factor table
use ada grad fobos
init rate
group by feature template
group by output class
prior alpha
split word regex
group by input
group by hidden unit
unigram lm
bigram lm
word seg beam size
vocab file
normalized file
average perceptron
load crfsegmenter path
load pctsegmenter path
crf segmenter prop
pct segmenter prop
intermediate segmenter out
intermediate segmenter model
dual decomp max itr
dual decomp initial step size
dual decomp debug
use cwsword features
use cwsword features all
use cwsword features bigram
pct segmenter len adjust
use train lexicon
use cwsfeatures
append lc
perceptron debug
pct segmenter scale by crf
pct segmenter scale
separate asciiand range
dropout rate
dropout scale
multi thread grad
max qnitr
dropout approx
unsup dropout file
unsup dropout scale
start evaluate iters
multi thread perceptron
lazy update
feature count thresh
serialize weights to
ge debug
do feature discovery
load weights from
load class index from
serialize class index to
learn chbased on en
learn enbased on ch
load weights from en
load weights from ch
serialize to en
serialize to ch
test file en
test file ch
unsup file en
unsup file ch
unsup align file
sup file en
sup file ch
serialize feature index to
load feature index from en
load feature index from ch
lambda en
lambda ch
alternate training
weight by entropy
use kl
use hard ge
use crffor unsup
use gefor sup
use known lcwords
feature factories
feature factories args
use noisy label
error matrix
print train labels
label dictionary cutoff
use ada delta
use ada diff
ada grad eps
ada delta rho
use random seed
terminate on avg improvement
strict good co nll
remove strict good co nllduplicates
prior model factory
use undirected disjunctive
split slash hyphen words
max additional known lcwords
none
wfrag
word
both
slash hyphen treatment
use title2
show nccinfo
show ccinfo
crf to examine
use sutime
apply numeric classifiers
combination mode
ner model
use more neighbor ngrams
dict2name
phrase gazettes
print props
binned length strs
iae
num factories
num args
joiner
seq classifier flags
value of
value of helper
check sorted
relative index
index of relative index
left message
right message
read resolve
relative indices
interner
other c
new c
sorted
shift amount
clique
clique equality wrapper
scores of
score of
get possible values
model1wt
model2wt
dist
dist_i
dist1
dist2
wt1
wt2
factored sequence model
get pub date
prepare heidel time input
make timex map
to node sequence
to timex
begin offset
end offset
requires
requirements satisfied
base_path
default_path
heideltime path
output reader
heideltime_path_property
heideltime_language_property
heideltime_output_results
translate
input writer
pub date
timex anns
date calendar
stream
timex
time mlopen
time mlclose
timex tag open
attr
timex tag close
token idx
node idx
partial
token end idx
match str
timex node
timex map
open matcher
attr matcher
close matcher
char idx
attrs
tag begin
tag begin end
tag end begin
tag end
tid
alt val
begin point
end point
heidel time kbpannotator
heidel time output reader
node
timex node
create extractor
init env
add end points
check args
determine rel flags
binder
filenames
value type
begin time
duration start tokens
duration start val
duration end tokens
duration end val
duration unit tokens
duration unit
duration start
duration end
temporal
quant
scale
arg1
cms
arg2
period
all temporal args
temporal args
flags set
generic time expression patterns
timex type match node pattern
matched expression value type match node pattern
bind
get all holidays map
get all holidays cvmap
get all holidays
is getter
get configuration
to formatted string
is grounded
get time
get duration
get range
to isostring
intersect
resolve with year
resolve
holiday manager
holidays
var prefix
xml path
xml path type
manager props
holiday xml url
ump
holiday entry
all holidays
desc key
sub configs
method
granularity
resolved
year
jolly day holidays
my xmlmanager
jolly holiday
get localized message
parse or null
parse using cache
cache
calls
misses
timex annotations
parsing error
sutime simple parser
sutime parsing error
annotate single sentence
timex extractor
quiet
time index
doc date
cal
date format
all time expressions
all numerics
aligned sentence
time expressions
numbers
annotation copy
time annotator
update extract rule
create
get text pattern
append quantifier
append regex
update temporal
get group
parse value
get date time field type
append regex0
add value
parse integer
parse offset millis
make regex
parse date time zone
update time zone names
to formatter
to text regex
to text pattern
append numeric fields
append numeric field
append text field
append component
append literal field
append regex part
append era text
append century of era
append year of era
append year
append two digit year
append weekyear
append two digit weekyear
append week of weekyear
append month of year
append month of year short text
append month of year text
append day of year
append day of month
append day of week
append day of week text
append day of week short text
append halfday of day text
append clockhour of day
append clockhour of halfday
append hour of day
append hour of halfday
append minute of hour
append second of minute
append fraction of second
append time zone offset
append time zone id
append time zone name
append time zone short name
append group start
append group end
append literal
parse pattern to
is special regex char
parse token
is numeric token
text annotation field
format
formatter
action
annotation extractor
locale string
format extractor
dtf
builder
time pattern
text pattern
locale
group
field value str
quantifier
field type
min value
max value
min digits
max digits
property
possible numeric date components
field types
string_length_rev_comparator
value mapping
valid values
is short
zero offset parse text
negative
digits
frac
dtz
time zones by id
time zone ids
time zone ids regex
time zones by name
time zone names
time zone regexes
regex
time1
time2
tz map
tz names
tz regex
use relaxed hour
cur group
has group
pivot
lenient
zero offset text
show separators
min fields
max fields
index ref
token len
lenient parse
sub
special_regex_chars
special_regex_char
buf
peek
in literal
time formatter
java date format extractor
joda date time format extractor
is default extractor present
default_time_expression_extractor_class
time expression extractor class
default_extractor_present
class name
time expression extractor factory
process timebank csv sent
process timebank csv
join word tags
process temp eval2doc
words to sentence
sentences to document
find timex
update timex text
read timex attr exts
process temp eval2tab
process temp eval2
process temp eval3
process temp eval3file
get pipeline
config logger
create timex nodes
create timex nodes presorted
process text file
process text
text to annotated xml
annotation to tml text element
annotation to xml document
text to annotation
python
pr stats
val pr stats
est pr stats
timex id
timex val
timex orig val
timex str
initialized
doc filename
doc pub date
sent id
orig items
eval stats
new fields
gold timex
guess timex
last index
end index
eval
data started
add old
ext pw
attr pw
debug pw
attr debug pw gold
attr debug pw
golds
sent index
sent token start
token start
context
sent token begin
tmx
token count
ext fields
ext string
attr fields
sent words
sent text
document id
doc tokens
extents file
attrs file
ext br
last doc id
last timex
doc name
sent no
token no
attr br
attrname
attrvalue
doc dates
cur doc name
cur sent no
last sentence
dct
default formatter
required formatter
doc date entry
command
eval file output
teinput pattern
out dir
timeml node
doc id node
dct node
dct timex node
title node
extra info node
text node
annotated text elem
annotated doc
new timeml node
string
required doc date format
use gutime
tokenize
time annotator
textfile
timebank_csv
tempeval2
tempeval3
char begin offset
timex list
previous end
timex elems
processed
unprocessed
timex elem
elem str
char start
inner elems
xml doc
timex anns all
text elem
timex nodes
date elem
doc elem
input type str
input type
sutime main
eval stats
timebank timex
timebank sent
timex attributes
basic
more
mark time ranges
restrict to timex3
te rel heur level
include nested
include range
search for doc date
language to rules files
grammar filename
binders
default_grammar_files
default_british_grammar_files
default_spanish_grammar_files
default_binders
binder property
n binders
binder classes
binder prefix
binder class
options
get single annotation extractor
add mod
extract annotation
get temporal
set temporal
orig temporal
char offsets
token offsets
temporal func
priority
time expression converter
new expr
extract func
source annotation
time expression
time index annotation
annotation
children annotation
time annotations
timex annotation
timex annotations
extract time expression core maps
finalize
to core maps
extract time expressions
resolve time expression
resolve time expressions
find reference date
timex patterns
expression extractor
section date
ref date
core maps
orig text
timex attributes
range temporal
ref date str
merged numbers
anno te
kept
children
child
child te
nested time expressions
grounded
time expression extractor impl
get field
get duration type
get range duration type
has field
has yyyymmdd
has yymmdd
set field
get supported duration fields
get unsupported duration period
combine
get most general
get most specific
get joda time period
combine more general fields
discard more specific fields
pad more specific fields
is compatible
resolve dow to day
with week year
resolve week
get instant
from timezone
get partial
add force
is more general
is more specific
zero pad
no further fields
minimum value
maximum value
timex time value
timex date value
consistent with forced
timex duration value
utc
standard isofields
standard isoweek fields
standard isodate fields
standard isotime fields
empty_iso_partial
empty_iso_week_partial
empty_iso_date_partial
empty_iso_time_partial
instant_zero
quarters
chronology
half years
decades
centuries
quarter of year
half year of year
month of quarter
month of half year
week of month
decade of century
year of decade
field
supported durations
supported
yoc
ref year
century
hour
dt type
d type
sdf
mgf
p1most general field
decade
dft
cmp
msf
use week
most specific
pwy
timezone
moy
dom
hod
moh
som
msos
scalar
df1
df2
df1duration field type
df2duration field type
df1unit
df2unit
padding
smallest field set
index in standard
index in week
to check
reference
force date
force units
approximate
opts
should be done
month diff
week diff
day diff
hr diff
min diff
sec diff
diff
month terminal
week terminal
cand
forced list
forced
ordering
cand index
cand i
seen time
years
months
joda time utils
conversion options
get current time
get number of temporals
get number of temporal exprs
get number of temporal funcs
get temporal expr
get temporal func
add temporal expr
add temporal
add temporal func
add to index temporal expr
add to index temporal
add to index temporal func
get period
get granularity
get uncertainty granularity
get standard temporal type
is ref
is approx
get tid
get tid string
get tfid
get tfid string
include timex alt value
get timex attributes
get timex type
get timex value
get time label
set time zone
get mod
add mod approx
create temporal
get date time fields
_create temporal
get interval
is comparable
compare to
has time
reduce granularity to
subtract
closest
distance
make composite
min
get joda time instant
get joda time partial
get intersected range
add supported
add unsupported
get formatter
get base
get temporal op
get temporal arg
get op flags
append date formats
append time formats
with standard fields
get compatible
to list
init base
get year
set year
get month
set month
get day
set day
set date
parse instant
parse date time
get inexact duration
make inexact
to time
multiply by
divide by
get joda time duration
get joda time interval
multiply duration by
divide duration by
date
time
duration
set
before
after
on_or_before
on_or_after
less_than
more_than
equal_or_less
equal_or_more
start
mid
end
approx
early
late
creation_time
expiration_time
modification_time
publication_time
release_time
reception_time
freq
mod
anchor time id
comment
value from function
temporal function
function in document
pad_field_unknown
pad_field_unknown2
pad_field_unknown4
resolve_now
resolve_to_this
resolve_to_past
resolve_to_future
resolve_to_closest
dur_resolve_to_as_ref
dur_resolve_from_as_ref
range_resolve_time_ref
relative_offset_inexact
range_offset_begin
range_offset_end
range_expand_fix_begin
range_expand_fix_end
range_flags_pad_mask
range_flags_pad_none
range_flags_pad_auto
range_flags_pad_finest
range_flags_pad_specified
format_iso
format_timex3_value
format_full
format_pad_unknown
timex version
temporal expr index
temporal index
temporal func index
id_pattern
exp
approx
standard temporal type
time label
uncertainty granularity
tlt
offset hours
per
time type
year
day
week
fortnight
month
quarter
halfyear
millis
second
minute
hour
halfhour
quarterhour
decade
century
millennium
time_ref
time_ref_unknown
time_unknown
time_none
time_none_ok
time_now
time_present
time_past
time_future
duration_unknown
duration_none
monday
tuesday
wednesday
thursday
friday
saturday
sunday
weekday
weekend
january
february
march
april
may
june
july
august
september
october
november
december
spring_equinox
summer_solstice
winter_solstice
fall_equinox
spring
summer
fall
winter
noon
midnight
morning
afternoon
evening
night
sunrise
sunset
dawn
dusk
daytime
lunchtime
teatime
dinnertime
morning_twilight
evening_twilight
twilight
yesterday
tomorrow
today
tonight
unknown
refdate
reftime
time_of_day
season_of_year
quarter_of_year
timex type
unit
composite value
temporal type
modifier
next
arg2next
next_immediate
resolved this
this
prev
arg2prev
prev_immediate
union
intersect
offset
minus
plus
min
max
multiply
divide
create
add_modifier
offset_exact
ref
times
ref millis
offset flags
dow
poy
most general
cpt
compatible
ntod
ndow
npoy
partial ref
has date
range
grounded range
grounded base
temp op
temp arg
op flags
tfid
that
date time zone
tz pt
sdft
always pad
is iso
is timex3
era
append half
append quarter
append month day
append week day
input granularity
pad type
pbase
resolved granularity
ref granularity
resolved2
t1b
t2b
candidate
unsupported
era_bc
era_ad
era_unknown
month
day
year era adjust needed
halfday_am
halfday_pm
halfday_unknown
minute
halfday
pattern_iso
pattern_iso_datetime
pattern_iso_time
pattern_iso_date_1
pattern_iso_date_2
pattern_iso_date_partial
pattern_iso_ambiguous_1
pattern_iso_ambiguous_2
pattern_iso_ambiguous_3
pattern_iso_time_of_day
date_time_formats
datetime
parsed timezone
parsed offset
current offset for my zone
ignored
date str
allow partial
ref instant
iso date
iso time
tz base
dt field types
dtft
instant
min time
max time
likely range
half duration
remainder
standard unit
min duration
max duration
min2
max2
begin tid str
end tid str
begin str
end str
duration str
grounded begin
grounded duration
grounded end
range flags
temporals
tz temporals
new temporals
hourly
nightly
daily
monthly
quarterly
yearly
weekly
occurs in
periodicity
resolved occurs in
resolved base
merged
sutime
time index
temporal
time
ref time
simple time
composite partial time
ordinal time
time with range
inexact time
relative time
partial time
iso date
iso time
iso date time
grounded time
duration
duration with fields
duration with millis
duration range
inexact duration
range
temporal set
explicit temporal set
periodic temporal set
find reader
find annotation
to annotation
pre terminals
is preterminal
directory
readers
to return
xml
date pattern
sentence elements
crtsent
sent elem
pre terminal
pos tag
word tree
descendant
parsed gigaword reader
is date okay
date string
annotator type
sutime pipeline
parse boolean
do get
do post
get rule filepaths
get time annotator properties
display annotation
add results
data dir
tagger filename
request
rules dir
read rules
heuristic level
relative heuristic level
rule file
rules
include offsets
tagged
token output
date error
sutime servlet
to xml element
from xml
from map
get date
make calendar
copy calendar
element
range str
parts
document time
last day
year range
month range
day range
week
start day
end day
day of year
timex
document to string
node to string
print node
create text node
create element
parse element
get attribute
remove children
get matching nodes
get node text
get node
get node texts
get attribute value
t factory
pretty print
include xml declaration
xml source
output target
db factory
doc builder
node path
xmlutils
to input xml
to timex core maps
gutime path
gutime_path_property
gutime_output_results
input xml
use first date
doc close
output xml
timex index
sent begin
sent end
sublist begin
sublist end
lex
original document
begin map
end map
have token offsets
tok begin
tok end
timex maps
doc nodes
text nodes
timex text
search step
gutime annotator
bad nested timex
bad nested timex2
heidel time annotator
exact match
smallest enclosing
match type
subtree
timex begin
timex end
possible matches
tree begin
tree end
tree iter
sorted matches
width1
width2
begin token
end token
msg
timex tree annotator
init components
window closing
exit item action performed
load parser item action performed
load data item action performed
exit form
parser panel
data filename
untok eng item
tok chinese item
untok chinese item
j menu2
load parser item
load data item
j separator1
j menu1
exit item
j menu bar1
parser
get tree
set tree
width
width result
height
pick font
paint tree
super paint
paint component
set min font size
set max font size
get tree dimension
vertical_align
horizontal_align
max font size
min font size
sister skip
parent skip
below line skip
above line skip
node tab
node center
child tab
f m
local
num kids
sub wr
local left
sub left
total left
local right
sub right
total right
depth
space
font
font name
font metrics
node str
node width
node height
node ascent
tree width
layer multiplier
layer height
child start x
child start y
line start x
line start y
line end y
c width
line end x
start x
start y
h align
v align
tjp
ptb tree string
tree jpanel
width result
scroll back
scroll forward
highlight text
highlight sentence
nearest delimiter
highlight selected sentence
highlight edited sentence
set status
set font
set chinese font
load file
get tokenizer factory
save output
load parser
load jar parser
start progress monitor
stop progress monitor
ancestor added
ancestor moved
ancestor removed
action performed
focus lost
mouse dragged
text pane focus lost
parse next button action performed
clear button action performed
text pane mouse dragged
text pane mouse clicked
parse button action performed
load parser button action performed
save output button action performed
load file button action performed
back button action performed
forward button action performed
untokenized_english
tokenized_chinese
untokenized_chinese
one_second
parser_load_time
parse_time
seek_forward
seek_back
jfc
jfc location
choose jar parser
page dialog
normal style
highlight style
start index
tree panel
lp thread
parse thread
timer
glass pane
scroll when done
seek dir
processor
status
fonts
toke
word list
url or file
doc pre
no tags
doc str
a doc
progress
button
cancelled
failures
fos
exists
max count
zip filename
successful
parser query
event
data file label
tree container
top panel
text scroll pane
back button
status label
load file button
load button panel
buttons and file panel
parse button
parse next button
forward button
parser file label
clear button
split pane
status panel
data file panel
button panel
text pane
progress bar
parser file panel
load parser button
save output button
parser panel
save output thread
load parser thread
parse thread
jfile chooser location
timer listener
min args
usage
tlpp
root match
rhs counter
kid
biggest keys
rhs
rhsfrequency
arg index
error
print tag list
rotator
dev
onto notes file preparation
extra args
update parser options
arg defs
remove bracket
pwo
start symbol
n trees
manipulate top bracket
tree to rule string
standard deviation
option arg definitions
file name
binary rule types
branching factors
n unary rules
n binary rules
binary branching factors
sub tree
mean
variance
rule branching factor
max len
print trees
flatten trees
print pos
print tn t
count trees
vocab
word type
vocab frequency
get punct class
eol class raw
sf class
colon class raw
colon class
comma class raw
comma class
currency class raw
currency class
p ellipsis
slash class raw
slash class
l bracket class raw
l bracket class
r bracket class raw
r bracket class
quote class raw
quote class
punct equivalence classer
punc tag
punc types
punct frequency dist
set labels
write trees
read label map
parse sentences
fail
default
keep_original
label map
missing
default label
unknowns
labels file
separator
remap labels
remap
phrase
sentences file
tagger file
binarizer
save unknowns file
binarize
use label keys
parse and set labels
make objects
child filtered eval
subtree filter
running averages
set
child pattern
filtered eval
evaluate
head finder
punct reject word filter
punct reject filter
dep string
option arg defs
max gold yield
guess file
opt
rest
pw out
guess treebank
gold treebank
metric
gold itr
guess itr
gold line id
guess line id
skipped guess trees
guess tree
guess yield
gold tree
gold yield
eval guess
eval gold
unlabeled attachment eval
top match eval
make lineages
update cat averages
edit distance
display
validate command line
sent avg
sent exact
corpus avg
corpus num
cat avg
cat num
tree stack
label stack
root label
lineages
node depth
lin
node label
lineage
new avg
new num
guess lineages
gold lineages
local scores
guess lin
gold lin
lev dist
local sent avg
rand
corpus level
sent level
sent ex
avg map
avg
usage
min_args
language
max_gold_yield
leaf ancestor eval
get gold trees
get results
convert dataset
build response
score dataset
process request
process input stream
parses
gold trees
scored result
response builder
treebank
evaluator
evaluate external parser
count span errors
simplify constituents
gold constituents
guess constituents
simple gold constituents
simple guess constituents
errors
gold words
guess words
gold tag
guess tag
constituents
new constituents
con
labeled
tree span scoring
check crossing
emit sorted trees
store trees
compare
zero cb
constit
sort by f1
worst ktrees to emit
do cat level
label regex
parsed args
evalb cat
file prefix
guess pw
gold pw
c fact
guess dep pw
gold dep pw
gold deps
guess deps
cur f1
first f1
second f1
evalb
cbeval
f1comparator
parse and report
get pcfgscore
get best parse
get kbest parses
get best score
get best pcfgparse
get best dependency parse
get best factored parse
get best pcfgparses
restore original words
has factored parse
get kbest pcfgparses
get kgood factored parses
get pcfgparser
get factored parser
get dependency parser
set constraints
said mem message
parse succeeded
parse skipped
parse fallback
parse no memory
parse unparsable
original sentence
success
pw err
debinarize
leaf iterator
kbest pcfg
kbest
external parser query
update
get pfractionals
get rfractionals
get test instances
num relevant examples
num test instances
exact
precisions
precisions2
recalls
recalls2
pnums2
rnums2
f1s
cur p
cur pnum
cur r
cur rnum
last p
last r
last f1
p sent
p eval b
r sent
r eval b
f1sent
f1eval b
evaluation metric
make collins objects
rel map
relations
this guess deps
this gold deps
current precision
current recall
current f1
c f1
emit
cats
f1map
cat
pnum2
rnum2
prec
rec
max_guess_yield
dep eval
done eval
collins dep eval
make objects by cat
measure oov
do cat level eval
percent oov
percent oov2
cat map
tly
cat set
guess cats
gold cats
all cats
this guess cats
this gold cats
gold tagging
guess tagging
oov rate
tagging eval
get lbscore
get tag score
nan scores
process results
get input sentence
summarize
test on treebank
debinarizer
subcategory stripper
collinizer
boundary remover
pq factory
evals
parser query evals
tsv
binarizer only
pcfg lb
pcfg child specific
pcfg la
pcfg cb
pcfg da
pcfg ta
dep da
dep ta
fact lb
fact child specific
fact la
fact cb
fact da
fact ta
pcfg ruo
pcfg cuo
pcfg cat e
pcfg ll
dep ll
fact ll
k good lb
top kevals
num skipped evals
ln_to_log2
extra evals
filter
kids
pw file out
pw stats
tree print
kbest pcfgtrees
trans gold tree
iii
sot
tbd
tbtr
log scores
tree id
k best tree
entropy
denom
log score
log pr
tree fact
f yield
g yield
trans guesses
tree pcfg
tree pcfgeval
tree dep
gold tree b
gold tree eval
dep daeval
undone tree
fact tree b
test treebank
treebank total timer
tlp params
fname
parser query eval
evaluate treebank
treebank evaluation dataset
preparsed evaluation dataset
extract deps
use tag
max guess yield
skip guess
tag mode
eval name
guess sent
guess chars
gold sent
gold chars
tsarfaty eval
get eval label set
evalb
p label filter
obj map
obj set
label set
cat precisions
cat precision nums
cat recalls
cat recall nums
evalb by cat
get sent ave f1
get evalb f1
get last f1
get evalb f1percent
get exact
get exact percent
get num
localize
my make objects
record score
precision2
recall2
dep1
dep2
cur precision
cur recall
over
under
local trees
r size
del2
tot score
abstract eval
rule error eval
cat error eval
score eval
comparison eval
counting eval
guesses
best f1
best tree
best of top keval
init files
write tree
close files
init evalbfiles
close evalbfiles
write evalbline
default_gold_filename
default_test_filename
gold writer
test writer
default_writer
gold filename
test filename
evalb format writer
base model paths
test treebank path
test treebank filter
unused args
treebank description
new args
underlying parser
combined parser
dvparsers
base model path
dvparser
reranker
combine dvmodels
dvmodel file
lexparser file
label results
tag results
cross validate test options
get model
get evals
get deep trees
transformer
deep trees
node vectors
transformed tree
dvmodel reranker
query
num neighbors
root vector
records
rpq
subtrees
record
bestmatches
norm f
ordered
find nearest neighbors
parse record
unk
unk words
unknown word printer
unary rules
binary rules
binary grammar
unary grammar
state index
unary rule
child state
child basic
binary rule
left state
left basic
right state
right basic
rule
filter confusing rules
get op
get dvmodel
get base parser
get top parses for one tree
get top parses
execute one training batch
run gradient check
build train transformer
attach model to lexicalized parser
save model
load model
get model from lexicalized parser
help
filename
dv kbest
best kparses
output updates
compressed parses
results record path
max train time millis
batch count
debug cycle
best label f1
sum grad square
num batches
shuffled sentences
batch
start tree
end tree
total elapsed
tag f1
label f1
temp name
status line
minimizer
convert timing
theta
last cost
curr cost
first time
grad
eps
gradf
new parser
train treebank path
train treebank filter
cached train trees path
run training
initial model path
args with defaults
train sentences
train compressed parses
cacher
dvparser
get binary matrix names
get unary matrix names
average binary matrices
average unary matrices
maps
matrix names
averages
binary
matrix
original
output model filename
input model filenames
binary transform maps
binary score maps
unary transform maps
unary score maps
word maps
binary transform averages
binary score averages
unary transform averages
unary score averages
word averages
new model
average dvmodels
output matrix
output tree matrices
find root tree
vectors
input path
deep tree
root tree
parse and print matrices
scorers
total score
combined dvmodel reranker
random context matrix
random transform matrix
add random unary matrix
add random binary matrix
set rules for training set
filter rules for batch
search rules for batch
basic category
read word vectors
total param size
params to vector
vector to params
get wfor node
get score wfor node
get start word vector
get end word vector
get word vector
get vocab word
get unknown word vector
print matrix names
print matrix stats
print all matrices
binary transform index
unary transform index
binary score index
unary score index
index to binary transform
index to unary transform
index to binary score
index to unary score
print parameter type
binary transform
unary transform
binary score
unary score
word vectors
num binary matrices
num unary matrices
binary transform size
unary transform size
binary score size
unary score size
num cols
num rows
identity
unknown_word
unknown_number
unknown_caps
unknown_chinese_year
unknown_chinese_number
unknown_chinese_percent
start_word
end_word
convert simple matrix
convert dense matrix
transform
unary
compressed trees
new binary transforms
new binary scores
new unary transforms
new unary scores
new word vectors
word vector
category
basic
number_pattern
caps_pattern
chinese_year_pattern
chinese_number_pattern
chinese_percent_pattern
dg_pattern
unknown number vector
unknown caps vector
unknown chinese year vector
unknown chinese number vector
unknown chinese percent vector
number count
caps count
chinese year count
chinese number count
chinese percent count
raw word vectors
vector
unk word
unknown word vector
total size
child label
left label
right label
last piece
normf
left child
right child
original pos
dvmodel
convert to bytes
convert to trees
tree basic categories
tree filter
bos
gos
transformed
filtered
uncompressed
bis
gis
ois
raw tree
simplified
parser model
treebanks
description
cache parse hypotheses
decompression processor
cache processor
dump matrix
matrix string
new line
output dir
binary wdir
binary score dir
unary wdir
unary score dir
embedding file
dump matrices
get context words
concatenate context words
output spans
forward propagate tree
domain dimension
get all highest scoring trees test
get highest scoring tree
calculate
get margin
backprop derivative
child vec
span
word node
current vector
score w
train_lambda
all best trees
best vectors
score hyp
delta margin
return tree
gold vectors
score gold
local value
local derivative
binary w_dfs g
binary w_dfs b
binary score derivatives g
binary score derivatives b
unary w_dfs g
unary w_dfs b
unary score derivatives g
unary score derivatives b
word vector derivatives g
word vector derivatives b
score timing
tree num
tree debug line
is done
done
value delta
local derivative good
local derivative b
current params
reg cost
current param
best hypothesis
binary w_dfs
unary w_dfs
binary score derivatives
unary score derivatives
word vector derivatives
delta
delta up
derivative
current vector derivative
delta current
wtdelta
left vector
right vector
children vector
w_df
left derivative
right derivative
left wtdelta
right wtdelta
child vector
child vector with bias
child derivative
child wtdelta
dvparser cost and gradient
scoring processor
get beam size
set beam size
get max sentence length
set max sentence length
get best scored parse
print sentence
print sentences
run charniak
charniak_dir
charniak_bin
parser executable
max sentence length
scored parse
k best parses
delete temp files
out file
err file
sent string
infile
outfile
errfile
err
charniak parser
read scored trees
string to parses
parses to string
print scored trees
ws delimiter
input desc
parse str
tree list
scored tree
close buffer needed
expect consecutive sentence ids
last sentence id
parses expected
sentence id
cur parse
cur parses
charniak scored parses reader writer
scored parses iterator
listen
handle quit
handle tokenize
handle lemma
handle dependencies
handle tree
handle parse
server socket
still running
tagger model
client socket
command pieces
command args
osw
binarized
default_port
lexicalized parser server
read result
get tokenized text
get lemmas
get dependencies
get parse
send quit
socket
mode
lexicalized parser client
is terminal
make transitions
initial configuration
can apply
get oracle
can reach
is oracle
single root
moves
n stack
n buffer
d tree
in buffer
dep in list
left l
right l
n left
n right
arc standard
load model file
load from model file
model file
extra properties
obj
model cache
dependency parser cache
dependency parser specification
get head
get label
get root
is single root
is tree
is projective
visit tree
equal
print
roots
dependency tree
get language
print parameters
root
null
nonexist
separator
training threads
word cut off
init range
max iter
batch size
ada eps
ada alpha
reg parameter
drop prob
hidden size
embedding size
num pre computed
num cached
eval per iter
clear gradients per iter
save intermediate
no punc
do word embedding grad update
sentence delimiter
escaper
pre tokenized
properties
escaper class
tlp canonical name
language str
config
dependency parser core nlpdemo
tagger path
dependency parser demo
get pos set
get word id
get pos id
get label id
get features
get feature array
gen train examples
generate ids
gen dictionaries
write model file
write embedding
is model new format
read embed file
setup classifier for training
predict inner
make grammatical relation
make grammatical structure
test co nll
test co nllreturn scores
parse text file
initialize
default_model
known pos
known labels
foo
word ids
pos ids
label ids
pre computed
system
f word
f pos
f label
pos_offset
dep_offset
stack_offset
stack_number
num trans
tok pos count
oracle
sorted tokens
doubles
a double
first line
n dict
n pos
n label
e size
h size
n tokens
n pre computed
embed file
embed id
embeddings
n words
dim
pre model
train sents
train trees
dev sents
dev trees
l dict
best uas
found embed
copy layer1
copy layer2
train set
opt score
opt trans
this word
head word
relation
root node
stored
sentence label
test sents
test trees
num words
num oovwords
num sentences
test sent
wordspersec
sentspersec
preprocessor
tagged sentence
seconds
dependency parser
get batch size
get drop out prob
merge
backprop saved
add l2regularization
get cost
get percent correct
get grad w1
get gradb1
get grad w2
get grad e
get to pre compute
compute cost function
take ada gradient step
init gradient histories
clear gradient histories
validate training
finalize training
pre compute
compute scores
matrix multiply
matrix multiply slice
matrix multiply slice sum
add cube in place
get w1
getb1
get w2
get e
grad saved
eg2w1
eg2w2
eg2e
eg2b1
saved
pre map
is training
job handler
grad w1
gradb1
grad w2
grad e
params
hidden
hidden3
node index
opt label
sum1
sum2
max score
grad hidden3
grad hidden
drop out prob
percent correct
other cost
features seen
map x
regularization weight
feature ids
percentage pre computed
to pre compute
num chunks
chunks
id integer
cached
left column offset
slice
bias
classifier
cost function
feedforward params
cost
num transitions
get transition id
get punctuation tags
get uas
get uasno punc
punctuation tags
correct arcs
correct arcs no punc
correct heads
correct heads no punc
correct trees
correct trees no punc
correct root
sum arcs
sum arcs no punc
n correct head
n correct head no punc
n no punc
parsing system
maxent tagger
output props
con lluoutputter
co nllutag updater
scaling
generate dict
get random
get random sub list
load conll file
write conll file
print tree stats
r mean
r std
std
a a
r a
cut off
a str
seed
subset size
input size
index to swap
conll ureader
conll sent
token line
non tree
multi root
non projective
util
get feature
example
add example
num features
data
dataset
remove second top stack
remove top stack
get stack size
get buffer size
get sentence size
get stack
get buffer
get core labels
get pos
get left child
get right child
has other child
get left valency
get right valency
get left label set
get right label set
make label set string
get str
stack
buffer
lbls
cnt
configuration
use split
gather stats
dissect tree
aggregate stats
accept
get name
add stats for tree
get perc lens less than
add phrasal branch
compute final values
opt arg defs
language name
path names
train
dev
test
split file lists
make vocab
train vocab
lang name
split map
ocs
tree facts
add to vocab
max breadth
max depth
depth node
corp stats
display words
display oov
all stats
ag stats
paths are files
all split stats
split filter
split stats
pathname
stats
filter map
corpus name
yield length
breadth
lens
sorted keys
pos tags
phrasal branching2
phrasal branching num2
depth2
breadth2
length2
lengths
breadths
depths
mean branching by label
mean depth
stddev depth
mean branching factor
mean constituents
mean length
stddev length
mean breadth
stddev breadth
oovrate
oov words
min length
min depth
min breadth
split prefix
show_words
show_oov
corpus paths
treebank stats
split filter
observed corpus stats
set to string
morpho spec
word tag counter
morph tag counter
morph counter
word counter
tag counter
lemma counter
lemma tag counter
rich tag counter
reduced tag counter
reduced tag lemma counter
word lemma map
lemma reduced tag counter
reduced tag tag counter
tag reduced tag counter
preterm list
yield len
morph
lemma tag
rich tag
reduced tag
lemmas
sb no lemma
sb mult lemmas
word lemmas
reduced tags
treebank factored lexicon stats
lex options
word index
tag index
compute after
unk counter
pos id
unkprinter
get tlpparams
treebank language pack
default core nlpflags
known states
requires tags
parse tree
get extra evals
get parser query evals
initial state from gold tag tree
initial state from tagged sentence
build training options
read treebank
read binarized treebank
check leaf branching
check root transition
filter treebank
binarize treebank
find known states
redo tags
find root states
find root only states
find root only states helper
verify transitions
set option flags
beam_flags
preterminals
word label
tag label
tag node
basic_training_options
force_tags
tlpp class
treebank path
treebank filter
filtered trees
basic transformer
transformed trees
binary head finder
binarized trees
n threads
root states
root only states
training data
dev treebank path
serialized path
retag timer
transition timer
transition index
dev treebank
extra flags
remaining args
continue training
training timer
shift reduce parser
retag processor
reorder
reorder incorrect binary transition
reorder incorrect shift transition
chosen transition
gold transition
chosen binary
gold binary
shift count
cursor
leftover binary
last binary
reordering oracle
is legal
top
score delta
shift transition
create transition sequences
create transition sequence
create transition sequence helper
compound unary
transition lists
is root
left head
right head
create transition sequence
find emergency transition
new state
require legal
base model
other labels
compound unary transition
featurize
factories
combination feature factory
averaged models
cv averaged models
early_termination
gold
reorder_oracle
beam
reorder_beam
training method
default_beam_size
feature frequency cutoff
save intermediate models
retrain after cutoff
oracle shift to binary
oracle binary to shift
decay learning rate
l1reg
l2reg
retrain shards
retrain shard feature drop
augment subsentences
shift reduce train options
transition counts
srquery
transition type eval
idle transition
is binarized
side
left
right
left top
right top
left next
head label
production
new top
other label
other side
binary transition
parse internal
get best binarized parse
get best transition sequence
final state
debinarized
unparsable
best parses
rearrange final punctuation tregex
rearrange final punctuation tsurgeon
max beam size
next beam
best state
predicted transitions
predicted transition
shift reduce parser query
shift reduce demo
updates
num correct
num wrong
first errors
correct transitions
wrong transitions
reorder success
reorder fail
first error
training result
binarized
debinarized
tree recorder
get binary side
is temporary
is equivalent category
head index
left index
right index
constraint matches tree top
find state on agenda
transition short name
agenda
transition
shift reduce utils
average scored models
average models
condense features
filter features
num weights
max abs
output stats
find highest scoring transition
find highest scoring transitions
train tree
train batch
output first errors
output reorderer stats
output transition stats
train model
prune features
learning rate
feature weights
paren
scored models
num models
feature it
string weight entry
word length
reorderer
gold state
highest scoring transition from gold state
highest score from gold state
new agenda
highest scoring state
highest current state
current state
is gold state
state transitions
new gold state
predicted index
gold index
gold features
last transition
keep going
gold num
predicted num
augmented data
augment fraction
first error copy
most common
num reorder success
num reorder fail
total guesses
inner
sorted inner
allowed features
best iteration
best models
feature frequencies
best size
drop
pruned features
initial model
current model
shards
perceptron model
train tree processor
add unary node
create node
grand child
unary transition
new train options
new test options
train options
test options
set option flag
compound unaries
feature factory class
shift reduce options
add unary stack features
add unary queue features
add binary features
add unary feature
add binary feature
add trigram feature
add position features
add separator feature
add separator features
add edge features
add edge features2
add extra trigram features
con feature
word tag feature
tag feature
word con feature
tag con feature
constituent
wt feature
name1
label1
feature11
feature12
name2
label2
feature21
feature22
feature type
feature1
feature2
value1
value2
label3
feature3
value3
between
separator between
count between
separator between name
count between name
s0label
s1label
s0separator
s1separator
neighbor name
neighbor
node value
previous label
next label
s2label
q0label
q1label
token position
s3label
s0llabel
s0rlabel
s0ulabel
s0lllabel
s0lrlabel
s0lulabel
s0rllabel
s0rrlabel
s0rulabel
s0ullabel
s0urlabel
s0uulabel
s1llabel
s1rlabel
s1ulabel
q2label
q3label
q p1label
q p2label
recent l0label
recent r0label
recent l1label
recent r1label
s0node
s1node
q0node
basic feature factory
legal
finalize transition
get feature from core label
get recent dependent
get stack label
get queue label
get core label
unary
headword
headtag
value
node num
feature factory
training update
unpack index
unpack score
pack
add scaled
condense
get score
update weight
write bytes
read bytes
empty
packed
other length
threshold
nonzero
new packed
increment
reg
weight
record binarized
record debinarized
record transition types
shift reduce test options
write object
read object
put
contains key
key set
entry set
bytes
weight map
get stack node
get queue node
get separator between
get separator count
get separator
find separators
is finished
end of queue
are transitions equal
separators
finished
head
next separator
next left
has left
next right
has right
separator regex
equivalent separators
equivalent separator
state
train transitions
binarized tree
num skips
training example
add distsim features
distsim
feature name
cluster
distsim feature factory
o score
i score
i score total
o possible
i possible
has parse
display head scores
extract best parse
flatten
create arrays
get best parses
get kgood parses
get ksampled parses
i score h
o score h
i score hsum
doi score hsum
raw distance
bin distance
head score
head stop
o possible by l
o possible by r
i possible by l
i possible by r
array size
my max length
edge
hook
num tags
has tag
true tag str
word context str
tagging i
tagging
h word
h tag
a word
left headed
a tag
head distance
bin dist
end head
end tag
arg head
arg tag
arg left score
stop left score
dep score
start head
start tag
arg right score
stop right score
goal tag
sub score
score right
score mid
score left
big bd
big htag
big atag
biggest
tol
head word str
head tag str
bin d
arg word str
arg tag str
new children
new child
exhaustive dependency parser
num closed rules
get rule
closed rule iterator
num rules
rule iterator
purge rules
close rules under max
relax rule
score rule
add rule
make crarrays
closed rules by parent
closed rules by child
closed rule iterator by parent
closed rule iterator by child
rule iterator by parent
rule iterator by child
rules by parent
rules by child
rules with parent
read data
write data
write all data
rules with child
closed rules with parent
closed rules with child
closed rules with p
closed rules with c
core rules
best rules under max
b r
isz
jsz
result r
best r
empty_unary_rule_array
lur
all rules
self r
line num
r i
unary grammar
do inside scores
do inside scores helper
step_size
threshold
pruned something
skip
narrow r
i possible l
left rules
narrow l
i possible r
min1
max1
p s
parent state
old iscore
best iscore
found better
l s
r s
tot
best words in span
old norm iscore
best norm iscore
new words in span
norm tot
right rules
i s
unaries
tot words in span
cur words in span
norm cur
goal
iterative ckypcfgparser
project
tag str
good
test tag projection
update counters
smooth rule weight
post basic category index
alpha
annotation introducing chars
annote chars
bgug
sym weights
sym counts
basic cat
p sum
p rule
p smooth
saw at zero
seen at zero
linear grammar smoother
set do selective split
local tree string
is synthetic
binarize local tree
markov outside binarize local tree
markov inside binarize local tree new
make synthetic label
make simple synthetic label
make synthetic label1
make synthetic label2
inside binarize local tree
outside binarize local tree
transform tree
simple tree binarizer
inside factor
markov factor
use wrapping labels
selective split threshold
mark final states
unary at top
do selective split
state counter
simple labels
no rebinarization
head num
top cat
new label
sb1
sb2
head loc
done left
sub label str
head str
sub label
right str
left str
starting
state count
label str
left string
right string
final piece
middle piece
left processed
right processed
final cat
eat left
right category
child left str
child label str
child right str
child result
head child
child num
file ext
uwl
uat
sst
mfs
new t
tree binarizer
split rules
split rules with lc
split rules with rc
rule iterator by right child
rule iterator by left child
rule list by parent
rule list by right child
rule list by left child
rules with lc
rules with rc
rule set with lc
rule set with rc
rule map
synthetic
rule list
binary grammar
left sister labels
right sister labels
kid labels
sister counters
side counters
print stats
do_tags
node rules
cutoffs
suppcutoff
rewrite
side sisters
side rules
side sister
sis
java sb
top scores
cntr
support
cntr2
support2
annotated label
p12
p22
psd
cutoff
out string
top score
pas
sister annotation stats
seen counter
un seen counter
index to start unk counting
document_unknowns
boundary_tag
total trees
i tw
i t
i w
w str
t str
s str
i ts
arabic unknown word model trainer
to word tag
get signature
number match
date match
ordinal match
proper name match
seen first
tag hash
unknown gt
use gt
itw
tag l
log prob
word probs
s11
s12
tw1
tw2
wt3
chinese unknown word model
transform tree helper
force cnf
debinarizer
set options
set options or warn
set option or warn
set option
langpack
end index plus one
order
to del
num bins
del split
composite
use unknown word signatures
default_word_vector_file
num hid
smooth in unknowns threshold
smart mutation
unknown suffix size
unknown prefix size
uw model trainer
flexi tag
use signature for known smoothing
word classes file
do pcfg
do dep
free dependencies
directional
gen stop
use smooth tag projection
use unigram word smoothing
coarse distance
dc tags
node prune
reranker kbest
base parser weight
lex options
default test sentence
sister splitters
collinizer evalb
memory treebank
disk treebank
typed dependency head finder
left phrasal
child basic cats
contains v
node cleanup
mark konj parent
mark contains v
mark zu
mark colons
mark hdparent
leave gf
gf char
lab
c cat
cat sb
tue ba dzparser params
reverse
build fa
register rule
advance right
left accepting
advance left
right accepting
allocate
advance
set transition
set loop state
num fas
left fa
right fa
tag o
left tags
right tags
state str
found semi
found dots
array
in state prev
in state next
loop state
accepting state
num symbols
prev state
loops
outside rule filter
score prob tag given word signature
get signature index
get signature7
get signature6
get signature5
get signature4
get signature3
get signature2
get signature1
get signature8
debug_uwm
min_unknown
max_unknown
c_tseen
smooth
pb_t_s
p_t
p_w
pb_w_t
word sig
c_ts
c_s
c_u
c_t
p_t_u
sentence position
uw sig
sig
has digit
has non digit
has lower
has upper
has dash
wlen
num caps
lowered
ch2
ch0
has letter
has period
has comma
last class
new class
digit
dist sim
english unknown word model
increment trees read
trees read
abstract unknown word model trainer
get unknown level
all digit plus
arabic unknown word model
delete punct
fix collins base np
wh option
c num
tree collinizer
better
extract parse
relax temp edge
discover edge
discover hook
build oscore
project hooks
register real
trigger hooks
trigger all hooks
relax temp hook
project unaries
process edge
process hook
process item
discover item
make initial item
make initial items
score dependencies
set goal
post mortem
very_verbose
chart
fscorer
dparser
projection
tagged word list
original labels
relax hook1
relax hook2
relax hook3
relax hook4
built hooks
built edges
extracted hooks
extracted edges
child list
n good trees
n good trees list
temp edge
result edge
back
back e
back h
best oscore
i temp
o temp
temp hook
lscorer
lat edge
hdi
real
new l
new r
real edges
result hook
item list
terminal count
word object
word str
tag i
initial items
n good remaining
span found
ex hook
num hooks
num edges
num unmatched hooks
leach
proj
bi lex pcfgparser
n5bi lex pcfgparser
eval gfs
original dependencies
is known
rule iterator by word
train unannotated
num sub args
get segmenter data from treebank
print args
save segmenter data to serialized
save segmenter data to text
make treebank
get segmenter data from file
get segmenter data from serialized file
get unknown word model
set unknown word model
chinese lexicon
word segmenter
basic category function
feature spec
train treebank
collins punc transformer
binary train trees
my transformer
annotated tb
clex
filt
segmenter file or url
parser file or url
serialized file or url
ice
fnfe
sce
save to serialized file
save to text file
serialized input file or url
text input file or url
serialized output file or url
text output file or url
test filter
train filter
testlow
testhigh
uwm
raw trees
chinese lexicon and word segmenter
tag string
to lexical entry
to tagged word
extract word
extract tag
any_word_int
any_tag_int
stop_word_int
stop_tag_int
any
stop
chars to escape
split char
int tagged word
basic segment words
segment words with markov
get segmented word length distribution
initial posdist
markov posdists
poses
initial
rule counter
entry1
delta word index
split backtrace
posbacktrace
word buf
r tag dist
r tag
r tag num
next pos
a gold yield
our words
our word
chinese markov word segmenter
prune tw
tree to dependency helper
dump sizes
tree to dependency list
score all
tune
get cached itw
expand dependency
tag project
expand arg
expand stop
count history
score tb
prob tb
get stop prob
num word tokens
arg counter
stop counter
smooth_a t_h twd
smooth_a tw_h twd
smooth_stop
interp
smooth_a tw_a t
smooth_a tw_h td
smooth_a t_h td
smooth_a ptw_a pt
basic category tags in dependency grammar
tag projection
use distance
use coarse distance
smooth params
arg tw
punct tags
punct tag
dep list
temp end head
l head
r head
l tag
l word
r word
h t
a t
h w
a w
dependency
stop l
stop r
best smooth_stop
best smooth_a tw_h twd
best smooth_a t_h twd
best interp
stop prob
best smooth_a tw_a t
best smooth_a tw_h td
best smooth_a t_h td
tag itwlist
head t
smooth tp
smooth tpindex
tp_prefix
bin str
val bin dist
arg t
head p
head tp
arg p
arg tp
dist bin dist
wild for stop
min_probability
a tw
h tw
pb_stop_h twds
pb_go_h twds
any head
any arg
any tag arg
c_a tw_h twd
c_a t_h twd
c_h twd
c_a tw_h td
c_a t_h td
c_h td
a pt
c_a ptw_h ptd
c_a pt_h ptd
c_h ptd
c_a ptw_a pt
c_a pt
h pt
projected arg
projected any head
projected any arg
c_a tw
c_a t
c_a w
p_a tw_h td
p_a t_h td
p_a tw_a t
p_a w
p_a ptw_a pt
p_a ptw_h ptd
p_a pt_h ptd
pb_a tw_h twd
pb_a t_h twd
unknown head
c_stop_h twds
c_stop_h tds
c_h twds
c_h tds
p_stop_h tds
compressed arg c
compressed stop c
full arg counter
full stop counter
doing stop
temp head
temp dependency
mledependency grammar
end head
process head word
set evaluate grammatical functions
set input encoding
set output encoding
get output encoding
get input encoding
pp attachment eval
test memory treebank
mledependency grammar smoothing params
parseval objectify
untyped dependency objectify
unordered untyped dependency objectify
typed dependency objectify
unordered typed dependency objectify
dependency objectify
dependency objectify helper
make dependency
typed dependency classer
tree tokenizer factory
dependency grammar extractor
is eval gf
set eval gf
read grammatical structure from file
get grammatical structure
supports basic dependencies
set generate original dependencies
generate original dependencies
eval gf
label constituents
spans
left edge
right edge
typer
head dtr
head term
dep term
head left
right headed
annotation mark
punct class
empty_args
abstract treebank parser params
subcategory stripper
remove gfsubcategory stripper
untyped dependency typer
unordered untyped dependency typer
typed dependency typer
unordered typed dependency typer
annotate punctuation function
local tree to rule
compute local tree score
treebank root
local tree
parent
next child
local tree score
found br
grammar coverage checker
tally leaf
tally pre terminal
tally internal node
tally root
form result
tally local tree
tally tree
tally trees
tally tree iterator
extract
tree iterator
trees1
weight1
trees2
weight2
spanish unknown word model trainer
dependency counter
mledependency grammar extractor
use first
unknown gttrainer
i total
use good turing unknown word model
tag lab
prob
chinese unknown word model trainer
initialize annotation patterns
set head finder
setup morpho features
remove baseline feature
options string
retain nptmp
retain npsbj
retain prd
retain ppclr
change no labels
collinizer retains punctuation
discard x
annotation patterns
active annotations
tag spec
base cat
new category
morpho str
feats
new cat
baseline features
additional features
genitive node tregex string
tregex pattern compiler
nth
nth str
tregex matcher
key2
do basic cat
key1
annot1
annot2
pattern2
pse
val2
mat2
nn tags
nn tag class
jj tags
jj tag class
vb tags
vb tag class
eq class
active feats
f type
feat name
did something
arabic treebank parser params
arabic subcategory stripper
simple string function
add relative node function
add relative node regex function
add equivalenced node function
add equivalenced node function var
annotate punctuation function2
add equivalenced conj node
list basic categories
has v
ctlp
char tags
use character based lexicon
use maxent lexicon
use maxent dep grammar
segment markov
sun jurafsky head finder
bikel head finder
discard frags
use similar word map
segmenter class
parent str
grand parent str
grand parent
base parent str
base grand parent str
base tag
base category
left aunts
right aunts
seen ip
left sis
right sis
has cc
has pu
has lex v
has ba
kidkid
sisters
has vpsister
sister
has comma sis
has ipsis
cat2
chinese split dou hao
chinese split punct
chinese split punct lr
mark vvsister ip
mark psister ip
mark ipsister vvor p
mark adgrandchild of ip
gpa ad
chinese very selective tag pa
chinese selective tag pa
mark ipsister ba
mark vpadjunct
mark npmod np
mark modified np
mark npconj
mark multi ntag
mark ipsis dec
mark ipconj
mark ipadjsubj
chinese split vp
merge nnvv
unary ip
unary cp
pa root dtr
mark postverbal p
mark postverbal pp
split base np
tag word size
mark cc
split nptmp
split pptmp
split xptmp
dominates v
default_use_good_turning_unknown_word_model
use char based unknown word model
length penalty
use unknown character model
penalty type
chinese params
dep gram feature level
chinese treebank parser params
register edge indexes
register real edge
is built l
is built r
get real edges with l
get real edges with r
get pre hooks
get post hooks
get edges
insert
add edge
add hook
registered pre hooks
registered post hooks
registered edges by left index
registered edges by right index
real edges by l
real edges by r
built lindexes
built rindexes
empty
empty hooks
temp index
temp weak index
hook chart
chart index
weak chart index
word id
tag id
morph id
lemma id
get loc
feature str
factored lexicon event
is edge
back hook
exhaustive test
edge
parse files
num sents
num unparsable
num no memory
num fallback
num skipped
element delimiter
tag delimiter
doc type
document preprocessor
normalized name
ext
fseparator
fname file
num processed
ans tree
parse files
transformed children
child index
conjoined list
node string
conjoined labels
conjoined labels builder
node strings
annotated trees
cnf tree
un cnftree
cnftransformers
to cnftransformer
from cnftransformer
annotate trees
deannotate trees
get trees
remove dependency roots
remove dependency root
collinize
tree transformer
tree un transformer
deannotated trees
pruned trees
last gone list
treebank annotator
set attr
get attr
set label
set weight
lattice edge
unknown
null word
null tag
null_itw
normalize nonterminal
build normalizer
normalizer
empty_sisters
italian treebank parser params
italian subcategory stripper
grammar
sent2
sent3
tag3
sentence3
tdl
parser demo2
demo dp
demo api
raw words
raw words2
parser demo
neginf doubles
output transitions
output betas
get state split count
count original states
initial betas and lexicon
split state counts
split betas
recalculate betas
use new betas
recalculate temporary betas
test convergence
rescale temporary betas
recount tree
recount weights
recount outside
recurse outside
recount inside
merge states
recalculate merged betas
merge transitions
build merge correspondence
count merge effects
build state index
build grammars
save trees
min_debug_iteration
max_debug_iteration
max_iterations
start symbols
tree weights
train size
original states
state split counts
binary betas
unary betas
temp word index
temp tag index
temp lex
lex_smooth
state_smooth
unary transitions
binary transitions
betas
parent states
child states
left states
right states
new state split counts
epsilon
temp unary betas
temp binary betas
new betas
child weight
left weight
right weight
split states
converged
test converged
total state mass
parent label
old value
new value
state weights
state total
state weight
smoothing
child weights
left weights
right weights
prob in
prob out
child inside
parent outside
left inside
right inside
root scores
parent scores
left inside scores
right inside scores
left scores
right scores
word weight
child scores
delta annotations
sorted deltas
splits to merge
merge correspondence
tree weight
old unary transitions
old binary transitions
new unary transitions
new binary transitions
old transitions
parent correspondence
child correspondence
new transitions
left correspondence
right correspondence
deltas
correspondence
total mass
state mass
mass
node prob in
node prob out
node delta
prob in merged
prob out merged
prob merged
prob unmerged
parent index
tree count
cycle
splitting grammar extractor
is pre hook
is post hook
sub state
hook
empty_string_array
hebrew treebank parser params
prob word tag
prob lemma tag
prob morph tag
init rules with word
treebank to lexicon events
get tuning set
get options
no_morph_analysis
morph index
word tag
word tag unseen
lemma tag unseen
morph tag
morph tag unseen
lex rules
uw rules
boundary id
boundary tag id
lemma morph
rich morph tag
reduced morph tag
p_w_tf
p_l_t
p_m_t
p_w_t
c w
c wt
c tseen
p_t_w
c tunseen
c l
c lt
p_l
p_t_l
c m
c mt
p_m
p_t_m
raw trees itr
tree itr
preterm yield
boundary word id
types
i tu
lexicon
events
preterm
tuning set
language options
feature list
n correct
no rules
gold tag id
tag score
hyp tag id
acc
factored lexicon
is upper case
base_label
spanish unknown word model
o to o
hungarian params
hungarian treebank parser params
hungarian subcategory stripper
head tag
arg word
num c
negra penn collinizer
to string no score
binary rule
dep score tree
pparser
num to find
cwt tree
bin head finder
num parses to consider
pcfg best
good parses
fast factored parser
unary rule
parse pcfg
get tree print
add sentence final punct if needed
bparser
fallback to pcfg
what failed
added punct
mledg
sentence b
boundary
expected size
strip subcat
binary tree
binary trees
strip subcategories
goal str
oome
uoe
sfp words
lexicalized parser query
add constraint
get num nodes
get constraints
get num edges
get edges over span
set edge
add boundary
edge starts at
max node
all edges
spanning edges
lattice
outside factor
compact grammar
print train tree
train tree file
train length limit
cheat pcfg
h sel split
hsel_cut
open class types threshold
fraction before unseen counting
g pa
post pa
post gpa
selective split
selective split cut off
selective post split
selective post split cut off
post split with base category
sister annotate
mark unary
mark unary tags
split pre pre t
tag pa
tag selective split
tag selective split cut off
tag selective post split
tag selective post split cut off
right rec
left rec
collins punc
splitters
post splitters
delete splitters
print tree transformations
print annotated pw
print binarized pw
print states
left to right
no tag split
rule smoothing
rule smoothing alpha
rule discount
print annotated rule counts
print annotated state counts
pre transformer
tagged files
predict splits
split count
split recombine rate
simple binarized labels
default_k_best
default_training_iterations
training iterations
default_batch_size
default_regcost
default_qn_iterations_per_batch
qn iterations per batch
qn estimates
qn tolerance
debug output frequency
random seed
default_learning_rate
default_delta_margin
unknown dashed word vectors
dv simplified model
default_scaling_for_init
scaling for init
max train time seconds
default_unk_word
lowercase word vectors
diagonal
random
off_diagonal
random_zeros
transform matrix type
use context words
train word vectors
default_stalled_iteration_limit
stalled iteration limit
mark strahler
my pw
previous state
train options
extract paths
translate and sort
translate
change if necessary
equals binary
equals unary
equal sets
build and compact toy grammars
remove low count paths
test grammar compaction
compactor
all test paths
all train paths
ascii output path
train low
train high
test low
test high
suffix order string
min arc num string
max merge cost string
size cutoff string
min portion arcs string
ignore unsupported suffixes string
split param string
cost model string
verbose string
min arc cost string
train threshold string
heldout threshold string
smooth param string
scoring data
allow epsilons string
save graphs
index range low
index range high
toy
p extractor
all paths
arg types
str class
c args
old index
new index
new ug
new bg
map1
map2
is equal
rule1
rule2
set1
set2
new set1
new set2
otsp
exact minimizer
new path counter
num arcs
num nodes
thresh
num retained
compacted grammar
string unary rule
string binary rule
grammar compaction tester
string unary rule
string binary rule
basic category tag projection
word length counter
char counter
tagged words
tagged word
sym
singleton chars
singleton words
singleton word poses
singleton word posdist
singleton char rads
singleton char rad dist
word length dist
percent
arg map
ctpp
stat args
raw train treebank
train filt
parser args
lex args
lex file
test args
test filt
eqclass
eqcheck
basic eval
collins eval
eval types
good pos
proc
gold top
gold char buf
a gold sentence
sent iter
our brackets
gold brackets
collins tree
collins gold
chinese character based lexicon training
is digit
french unknown word model
get num lattices
load
sentence
node
node_id
edge
from_node
to_node
segment
weight
e_attr_node
e_attr
e_attr_val
node_offset
lattices
is object
xml document
xml nodes
xml node
node map
real node idx
last boundary node
xml edges
edge idx
xml edge
from
norm from
norm to
xml attrs
attr idx
xml attr
num lattices
lattice xmlreader
contains vp
mark rc
mark zu vp
mark lp
mark colon
default leave gf
default gfcharacter
tree normalizer insert npin pp
tree normalizer leave gf
negra penn treebank parser params
read input
merge simultaneous nodes
remove empty nodes
build word time arrays
build words at time
build words start at
build words end at
remove redundency
remove redundent pair
change start times
change end times
remove silence
merge duplicates
print words
get prob
process lattice
get lattice words
get num states
get words over span
prettyprint
usesum
usemax
merge type
silence
lattice words
node times
words at time
words start at
words end at
word line pattern
word line matcher
end node
pronun
pronunciation
node time pattern
node time matcher
index map
prev node
prev time
changed
a words at time
w1start
w2start
w1end
w2end
new start
old start
new end
old end
new start time
to remove
old start time
twin
new end time
old end time
silences
num merged
parse gram
htklattice reader
lattice word
source ug
source bg
target ug
target bg
null grammar projection
steps
prob random walk
c_w
seen
chinese lexicon
o possible l
o possible r
build ofilter
validate binarized tree
score non binarized tree
score binarized tree
tick
initialize possibles
do outside scores
do inside chart cell
initialize chart
extract best parses
get backwards star
get candidates
lazy kth best
lazy next
nudge down array size
consider creating arrays
clear arrays
orf
words in span
o filtered start
o filtered end
original core labels
original tags
label index
terminal label
o s
bound
first child
second child
spill guts
dump tagging
flood tags
narrow lextent
wide lextent
narrow rextent
wide rextent
is tag
succeeded
tot l
tot r
length normalization
narrow rextent_start
wide rextent_start
narrow lextent_end
wide lextent_end
i score_start
i score_start_end
candidate tag regex
assigned some tag
lex score
state name
internal tree
norm best score
lattice edges
context str
binary i
norm score
left child tree
right child tree
unary i
child tree
best trees
left child trees
right child trees
child trees
k best trees
k prime
d hat v
tails
rule score
children scores
l child
r child
d hat
cand v
bs v
derivation
d hat ti
new derivation
internal trees
scored trees
exhaustive pcfgparser
vertex
arc
derivation
wt count
tag count
seen words
logprob
unknown gttrainer
projection scorer
build annotations
baseline annotation features
poder_form
hacer_time_form
default_prefix_length
prefix length
spanish treebank parser params
mark conj type function
mark prefix function
default_pre_tagger
no recovery tagging
do recovery
use n5
use fast factored
iterative cky
max_items
unseen smooth
increasing length
pre tag
force tags
force tag beginnings
tagger serialized file
no functional forcing
pcfg threshold
pcfg threshold value
print all best parses
dep weight
prune punc
add missing final punctuation
output format options
write output files
output files directory
output files extension
output files prefix
outputk best equivocation
max span for tags
print pcfgk best
eval pcfgk best
print factored kgood
fast factored candidate multiplier
fast factored candidate addend
use lexicon to score dependency pw gt
use non projective dependency parser
testing threads
quiet evaluation
test options
yield tag
tagger reranker
scorer1
scorer2
twin scorer
determine head
determine binary head
fallback hf
lval
rval
binary head finder
generic treebank parser params
seen end
german unknown word model
boundary remover
french unknown word model trainer
english unknown word model trainer
is punc
pre terms
pre term helper
transform root
transform node
collins punc transformer
get posdistribution
is foreign
unknown char class
get backed off dist
sample from
get word length distribution
cannonical symbol
get ch
char distributions
known chars
posdistribution
context_length
training sentences
singletons
posspecific char ngrams
poscounter
this ch
number of keys
counter entries
this prior
prior weight
new dist
char list
next char
char score
gen
pos
gen word length dist
unknown_type
digit_type
letter_type
begin_word_type
end_word_type
char_type
unk_class_type
unk class
digit
letter
begin_word
chinese character based lexicon
symbol
process tree helper
get splitters
get split categories
get english split categories
do tags
p rules
g prules
tag node rules
tag prules
tag gprules
g p
gpr
kidn
pair str
triple str
all scores
lst
par
gpar
use cut off
algorithm
phrasal cut off
tag cut off
parent annotation stats
rerank
reranker query
reranked
equal trees
tree pos
reranking parser query
ensure probs
apply thresholds
seen tags only
feat extractor
fix unk function words
word pattern
char pattern
bigram pattern
conj pattern
word threshold
char threshold
bigram threshold
conj threshold
feature thresholds
universal threshold
function word tags
tag dist
log probs
iterator cutoff factor
last word
initial weight file
train float
feature dir
tol
tune sigma
train count threshold
feature level
default_feature_level
train on low count
train by type
subtract tag score
true tag
tags for word
accumulated
datum counter
minim
num removed
total and correct
chinese maxent lexicon
build uwm
german unknown word model trainer
score gt
get lexicon
add tagging
use end
use first cap
end length
unknown level
sub str
base unknown word model
compile annotations
add feature
remove feature
get annotation string
compiler
compiled
behavior
annotation str
lower case
matched tree
lexical head
head value
tregex powered treebank parser params
annotate head function
do compaction
exact grammar compactor
get list
path extractor
get map
set lex
dump sim word avg stats
prob tbwith sim words
prob similar word avg
string basic category
sim smooth
arg head file
head arg file
sim arg map
sim head map
hash map
word map breader
word map line
line pattern
triple list
stats counter
unknown arg
valence bin distance
sim2arg
sim2head
sim arg
sim head
c sim_a tw_h td
c sim_h td
p sim_a tw_h td
smooth sim_a tw_h twd
reg prob
sum scores
sum weights
num t
temp dep
prob arg
count head
sim prob
smooth prob
chinese sim word avg dep grammar
back edge
item
copy lexicalized parser
train from treebank
parse strings
parse multiple
lexicalized parser query
get parser from file
make secondary treebank
save parser to serialized
save parser to text file
confirm begin block
get parser from text file
get parser from serialized file
print options
build train binarizer
get annotated binary treebank from treebank
remove delete splitters from splitters
get parser from treebank
serialized_parser_property
default_parser_loc
bestparse
nthreads
uwm clazz
text file or url
tim
train transformer
word function transformer
secondary treebank
tune treebank
whole treebank
ptt
deleted
del
base del
check basic
elem
base elem
del str
secondary train treebank
extra tagged words
train treebank raw
bg extractor
smoother
compacted
dg extractor
tune path
tune filter
secondary treebank path
secondary treebank weight
secondary train filter
tokenizer factory class
tokenizer method
option args
file records
lex num rules
lexicalized parser
dump stats
non terms
new kids
biggest counts
post splitter
sub string
w entry
base unknown word model trainer
tree to events
list to events
train with expansion
build pt_t
examine intersection
print lex stats
evaluate coverage
get base tag
populate tags to base tags
uw model
uw model trainer class
debug_lexicon
debug_lexicon_score
rules with word
m_tt
m_t
base tag counts
word taggings
i tw2
i tprint
itw list
tag words
total count
new tw
c_tw
total unseen
c_tunseen
pb_t_w
p_t_w2
pb_w0_t
pb_w1_t
debug last word
debug loc
debug probs
debug no probs
debug prefix
best smooth
seen
lis
stats_bins
known types
wsize
w arr
missing words
missing tags
missing tw
i tw1
unseen
tags to base tags
impos
base lexicon
set lexicon
num tag bins
tag bin
root tw
valence bin
num dist bins
distance bin
reg distance bin
coarse distance bin
set coarse distance bins
set reg distance bins
init tag bins
stop tw
wild tw
expand dependency map
coarse distance bins
reg distance bins
itw interner
r tw
bins
tag bin index
head tw
intern temp dependency
return dependency
abstract dependency grammar
compute input prior
smart negate
write file
convert grammar to graphs
get graph from map
get top category of synthetic state
add one unary rule
add one binary rule
is synthetic state
convert graphs to grammar
compacted graphs
raw_counts
normalized_log_probabilities
output type
new state index
input prior
train paths
test paths
original state index
graphs
graph iter
compacted graph
ugbg
base dir
dot string
was added
bar
topcat
parent string
child string
bracket
left or right
symbol counter
grammar compactor
unary rule counter
binary rule counter
binary grammar extractor
add tagger to parser
left ann
right ann
ann cat
max strahler
max multiplicity
strahler
tree annotator
likely adjectival suffix
past tense verb number suffix
present tense verb number suffix
taa marbuu ta suffix
abstraction noun suffix
masdar prefix
seen digit
adjectival suffix pattern
singular past tense suffix pattern
plural first person past tense suffix pattern
plural third person masculine past tense suffix pattern
plural third person masculine present tense suffix pattern
taa marbuu ta suffix pattern
abstraction noun suffix pattern
masdar prefix pattern
arabic unknown word signatures
set feature level
load features
apply feature count threshold
make features
morpho
rads
use length
use freq
bigrams
conjunctions
mild conjunctions
turn off word features
cmfs
threshed features
both
length bin
freq bin
chinese word feature extractor
clean tags
wordify
cut last
add last
serialize file
binary test trees
bound bg
bound ug
pcfg pe
combo pe
pcfg te
combo te
pcfg teno punct
combo teno punct
dep te
dep de
combo de
args class
arguments
t num
tt size
test tree len
time mil1
both passed
time mil2
elapsed
tree2b
tree3
tree3db
tree4
tc evalb
tree4b
tw list
w list
factored parser
any_distance_int
int dependency
add root
print rule counts
print state counts
post splitter
annotated rule counts
annotated state counts
do subcategorization
annotation hf
binarization hf
pre term child list
boundary term
boundary pre term
tr tree
tr2
subt
dtr
key list
binary train treebank
tree annotator and binarizer
tree null annotator
first of several nnp
last of several nnp
deduce tag
right phrasal
sub catify
ditrans
change base cat
has clausal v
has i
has c
kidkids
my label
newkids
final child
english train
english test
sister split1
sister split2
sister split3
sister split4
retain nptmpsubcategories
retain tmpsubcategories
retain advsubcategories
make copula head
leave it all
split in
split quotes
split sfp
split percent
split nppercent
tag rbgpa
split nnp
join pound
join jj
join noun tags
split ppjj
split trjj
split jjcomp
split more less
unary dt
unary rb
unary prp
mark reflexive prp
unary in
split cc
split not
split rb
split aux
vp sub cat
mark ditrans v
split vp
split vpnpagr
split stag
mark contained vp
split npprp
dominates i
dominates c
split sgapped
split num np
split poss
split tmp
split sbar
split npadv
split npnnp
correct tags
sister split level
gpa root vp
make pptointo in
collapse wh categories
english params
category word tag tree factory
found jj
found me
annotate have
d tag
found in
found order
infinitive
word2
seen pred cat
seen np
seen cc
seen s
saw sbefore pred cat
seen num
label bot
old kids
label top
newer children
first is t
num nnp
child str
new base cat
retain_tmp_args
english treebank parser params
english subcategory stripper
english test
english train
prune
helper
test tree
temp tree
pcfg tree
pcfg constituents
pruned children
child start
num ch
is extra
child end
child constituent
new tree list
node pruner
step
hidden to seen
seen to hidden
lambda
steps
seen1
hidden1
subtotal
random walk
load mwmap
read penn format
mw counter
factored features
to lower
cutoff
n lines
option
french treebank parser params
add possequence function
x tree
flatten tall trees
print out of memory
tree factory
lst2
max height
parser utils
parser annotations
candidate part of speech annotation
constraint annotation
parser constraint
load tagger
lemmatize
load model from zip
morpha
model name
object
zentry
parser grammar
get treebank description
get weighted treebank description
double_pattern
flag
has weight
arg utils
parsing threadsafe processor
no such parse exception
def
set value
set from string
label factory
end position
set begin position
set end position
ofs
string label
string label factory holder
encoded label str
old label
new label from string
string label factory
make copy
make soft copy
get original
backing label
get string
set tag
set word
set lemma
set ner
set doc id
set index
pseudo position
set pseudo position
set sent index
set before
original text
set original text
set after
copy count
set copy count
to primes
to copy index
is copy
no_word
num copies
label copy
begin pos
end pos
other word
my ind
other ind
my sent ind
other sent ind
my doc id
other doc id
cached hash code
sensible
doc comp
sent comp
index comp
core label
indexed word
segmenter core annotations
characters annotation
xmlchar annotation
divider
word tag factory
is start
is end
tag1
multi token tag
tag
to sentence
deep copy
to core label list
to core label list with character offsets
ml1
core utilities
word from string
init from strings
parse string keys
set category
ner confidence
is newline
set is newline
is mwt
is mwtfirst
set is mwt
set is mwtfirst
capacity
saved listener
generic keys
generic values
core key class
value class
original word
is first mwt
tag_separator
value_index
value_tag
value_tag_index
map
value_map
value_index_map
word_index
value_tag_ner
lemma_index
all
default_format
cls
as class comparator
core label
core label factory
cwt
category word tag factory
get reader
set reader
set tokenizer factory
get keep original text
set keep original text
read document
read next document text
parse document text
get buffered reader
read text
keep original text
url
divider
labeled word
label factory holder
as features
add label
title
set title
blank document
presentable text
print state
basic document
text reader
text url
w t
word lemma tag
w lt
w lt2
w lt3
word lemma tag
tagged word
arg
all_no
rel
core annotations
text annotation
lemma annotation
part of speech annotation
named entity tag annotation
named entity tag probs annotation
coarse named entity tag annotation
fine grained named entity tag annotation
stacked named entity tag annotation
true case annotation
true case text annotation
tokens annotation
generic tokens annotation
sentences annotation
quotations annotation
unclosed quotations annotation
quotation index annotation
sentence begin annotation
sentence end annotation
paragraphs annotation
token begin annotation
token end annotation
calendar annotation
doc idannotation
index annotation
begin index annotation
end index annotation
forced sentence until end annotation
forced sentence end annotation
sentence index annotation
line number annotation
value annotation
category annotation
original text annotation
before annotation
after annotation
coarse tag annotation
co nlldep annotation
co nllpredicate annotation
co nllsrlannotation
co nlldep type annotation
co nllutoken span annotation
co nllusecondary deps annotation
co nllufeats
co nllumisc
co nlldep parent index annotation
idfannotation
argument annotation
marking annotation
semantic head word annotation
semantic head tag annotation
verb sense annotation
category functional tag annotation
neridannotation
normalized named entity tag annotation
srlidannotation
shape annotation
left term annotation
parent annotation
inannotation
span annotation
answer annotation
answer prob annotation
preset answer annotation
gold answer annotation
features annotation
interpretation annotation
role annotation
gazetteer annotation
stem annotation
polarity annotation
morpho num annotation
morpho pers annotation
morpho gen annotation
morpho case annotation
chinese char annotation
chinese orig seg annotation
chinese seg annotation
chinese is segmented annotation
arabic char annotation
arabic seg annotation
character offset begin annotation
character offset end annotation
codepoint offset begin annotation
codepoint offset end annotation
cost magnification annotation
word sense annotation
srlinstances annotation
num txt sentences annotation
tag label annotation
domain annotation
position annotation
char annotation
unknown annotation
idannotation
gaz annotation
possible answers annotation
dist sim annotation
abbr annotation
chunk annotation
governor annotation
abgene annotation
genia annotation
abstr annotation
freq annotation
dict annotation
web annotation
female gaz annotation
male gaz annotation
last gaz annotation
is urlannotation
link annotation
mentions annotation
entity mention index annotation
canonical entity mention index annotation
coref mention to entity mention mapping annotation
entity mention to coref mention mapping annotation
entity type annotation
is date range annotation
predicted answer annotation
original char annotation
utype annotation
entity rule annotation
sections annotation
section index annotation
section author character offset begin annotation
section author character offset end annotation
section tag annotation
quotes annotation
quoted annotation
section annotation
section date annotation
section idannotation
section start annotation
section end annotation
word position annotation
para position annotation
sentence position annotation
sentence idannotation
entity class annotation
answer object annotation
best cliques annotation
best full annotation
last tagged annotation
label annotation
neighbors annotation
contexts annotation
dependents annotation
word form annotation
true tag annotation
subcategorization annotation
bag of words annotation
height annotation
length annotation
lbegin annotation
lmiddle annotation
lend annotation
d2_lbegin annotation
d2_lmiddle annotation
d2_lend annotation
ublock annotation
space before annotation
state annotation
prev child annotation
first child annotation
unary annotation
do annotation
have annotation
be annotation
not annotation
percent annotation
grandparent annotation
head word string annotation
month annotation
day annotation
year annotation
prior annotation
semantic word annotation
semantic tag annotation
covert idannotation
arg descendent annotation
xml element annotation
xml context annotation
topic annotation
wordnet syn annotation
phrase words tag annotation
phrase words annotation
proto annotation
common words annotation
doc date annotation
doc type annotation
doc source type annotation
doc title annotation
location annotation
author annotation
numeric type annotation
numeric value annotation
numeric object annotation
numeric composite value annotation
numeric composite type annotation
numeric composite object annotation
numerized tokens annotation
use marked discourse annotation
utterance annotation
speaker annotation
speaker type annotation
paragraph annotation
paragraph index annotation
mention token annotation
left children node annotation
exception annotation
antecedent annotation
label weight annotation
column data classifier annotation
label idannotation
kbptriples annotation
wikipedia entity annotation
statement text annotation
gender annotation
is newline annotation
is multi word token annotation
mwttoken text annotation
is first word of mwtannotation
value label
value label
to core key
get value type
value_key
tag_key
word_key
lemma_key
category_key
index_key
arg_key
marking_key
semantic_head_word_key
semantic_head_pos_key
verb_sense_key
category_functional_tag_key
ner_key
shape_key
left_term_key
parent_key
span_key
before_key
after_key
current_key
answer_key
goldanswer_key
features_key
interpretation_key
role_key
gazetteer_key
stem_key
polarity_key
ch_char_key
ch_orig_seg_key
ch_seg_key
begin_position_key
end_position_key
docid_key
sentindex_key
idf_key
end_position_key2
chunk_key
normalized_ner_key
morpho_num_key
morpho_pers_key
morpho_gen_key
morpho_case_key
wordnet_syn_key
proto_syn_key
doctitle_key
doctype_key
docdate_key
docsourcetype_key
link_key
speaker_key
author_key
section_key
sectionid_key
sectiondate_key
stacked_ner_key
headword_key
governor_key
gaz_key
abbr_key
abstr_key
freq_key
web_key
pos_tag_key
cpos_tag_key
deprel_key
headidx_key
core key
old key
key class
new key
string key
lookup
value cache
annotation lookup
set branch limit
append
replace all extended
replace first extended
replace all
replace first
get find type
set find type
is match with result
set match with result
find
find0
find next non overlapping
find next all
find all non overlapping
find match start
find match start no backtracking
find match start backtracking
clear matched
get state message
region
region end
region start
to basic sequence match result
group nodes
group value
group info
group match results
group match result
node match result
reset
get start states
update keep bids
add bids to collapse
add matched groups
add matched results
link
unlink
get bid
new bid
get parents
get branch state
get matched groups
get matched group
set group start
set group end
clear group start
get matched results
get matched result
set matched result
get branch id
get match state info
remove match state info
set match state info
start matched count inc
start matched count dec
end matched count inc
clear matched count
set matched interval
get matched interval
merge branch states
get matched signature
get branch states
elements
branch size
swap
swap and clear
compare matches
get match index
get match indices
select match index
complete match
set matched groups
is all match
is match
add states
add state
clean
include empty matches
matching completed
match with result
next match start
find_nonoverlapping
find_all
find type
cur match iter
cur match states
prev matched signatures
branch limit
blimit
replacement
group name
old find type
match start
matched branches
match all tokens
match all
c states
todo
bid
matched groups
matched results
match state info
bids to collapse
collapsed bids
bids
tstate
bid index
branch states
active matched states
keep bid states
pids
pbs
group id
capture group id
cur position
old obj
next branch index
next total
initial value
match state count
cbid
cbs
old states
match longest
cur bid set
new states
keep bid set
tmp states
matched0
p1buffer
p2buffer
bid1
bid2
all match indices
bestbid
best matched
best matched length
match length
match state index
all match
get pattern expr
get priority
set priority
get weight
get action
set action
get total groups
compile
get matcher
find node pattern
find node patterns
optimize
build
assign group ids
update bindings
optimize or
optimize or string seqs
_get string annotation_
update out states
match0
mark optional
add child bid
is all child matched
get all child matched bids
connect
pattern str
pattern expr
total groups
var group bindings
node sequence pattern
transformed pattern
allow optional
allow branching
out list
add next
varnames
nodes_equal_checker
any_node_pattern_expr
seq_begin_pattern_expr
seq_end_pattern_expr
bindings
multi node pattern
state factory
frag
next id
new patterns
capture
varname
min match
max match
greedy match
greedy
cur out
optimize_min_size
optimized string seqs
string patterns
string seq patterns
is string seq
strings
already optimized
final optimized patterns
optimized
included
conj start
match_state
has saved value
is optional
matched states
consume
next state
matched interval
propagate
n branches
repeat start
matched count
min match left
max match left
total branches
matched group
matched nodes
back ref state
start bid
start pos
child count
reachable child bids
matched bids
state info
out state
out states
get new env
get multi pattern matcher
any_node_pattern
default_env
token sequence patterns
token sequence pattern
lookup annotation key
lookup annotation key with classname
get default tokens aggregators
get default tokens aggregator
get default tokens result annotation key
get default result annotation key
get default result annotation extractor
get default nested results annotation key
get default text annotation key
get default tokens annotation key
annotation key
env lookup
mismatch cost
ins cost
del cost
get child trie
put child trie
get children
get value
is leaf
update trie strings
contains value
put all
update keys
update values
update entries
get key
initial capacity
cur trie
parent trie
key iter
k trie map entry
last key
values list
top cost
top key
max size
max cost
priority queue
value map
cost function
trie map counter
collection valued trie map
trie map factory
new map
new set
set map
collection factory
trie_map_factory
init capacity
trie map utils
multi match delta cost
prev multi match
cur multi match
get multimatches
get multimatched
get multivalues
get multioffsets
multimatches
multimatched
multivalues
multioffsets
get matched
get matched length
get begin
get end
get custom
set custom
custom match object
find closest matches
find all matches
find non overlapping
get non overlapping
update all matches
update all matches with start
with match
to approx match
to sorted list
add to queue
default cost
partial match comparator
root with delimiter
multimatch delimiter
multimatch
keep alignments
extra
prev matches
cur matches
complete
pam
npam
all matches
match_length_endpoints_comparator
match_length_scorer
compare func
score func
non overlapping
segments
trie
last multimatched matched start index
last multimatched original start index
alignment length
delta cost
newly matched
match_cost_function
multi matches without offsets
multimatch queues
all
default_cost
partial_match_comparator
comp
mm1
mm2
get alignments
alignments
create getter
text annotation pattern
env attr pair
text_attr_equal_checker
core map node pattern
get min nodes
set min nodes
get max nodes
set max nodes
is greedy match
set greedy match
min nodes
max nodes
node patterns
throwable
token sequence parse exception
eof
identifier
regexvar
regexgroup
regexmrvar
regexmrgroup
backref
nonnegint
int
longint
real
regex
str
numcmp
strregexcmp
strsimple
token image
set tab size
get tab size
expand buff
fill buff
begin token
update line column
read char
get column
get line
get end column
get end line
get begin column
get begin line
backup
re init
get image
get suffix
done
adjust begin line column
get track line column
set track line column
static flag
bufsize
available
bufpos
new token
kind
begin line
begin column
end line
end column
image
special token
of kind
token
initialise
add_escapes
eol
current token val
expected token sequences val
token image val
current token
expected token sequences
retval
parse exception
get expression extractor
update expression extractor
parse sequence
parse sequence with action
parse node
parse long integer
parse quoted string
append special tokens
get string from tokens
rule list
rule
expression extractor rule
assignment rule
assignable expression
expression
index
function call expression
value expression
composite field value
field value
basic value
assignable var
var or regex var
method call expression
assignable nested var expression
nested var expression
nested function call expression
list expression
list expression2
basic cond expression
cond group
cond expression
case expression
string regex
seq regex
string number value
seq regex basic
seq regex repeat times
seq regex disj
seq regex disj conj
seq regex group
bracketed node
seq var
seq back ref
node disj
node conj
node disj conj
node group
node basic
core map node
attr value
core map word pattern
multi node pattern
core map var value
core map var node pattern
core map expr node pattern
seq regex with action
action
annotate action
set attr values
set attr value
number token
integer token
cmp token
relaxed string token
relaxed string
relaxed string no identifier
jj_2_1
jj_2_2
jj_2_3
jj_2_4
jj_2_5
jj_2_6
jj_2_7
jj_2_8
jj_2_9
jj_2_10
jj_2_11
jj_2_12
jj_2_13
jj_2_14
jj_2_15
jj_2_16
jj_2_17
jj_2_18
jj_2_19
jj_2_20
jj_2_21
jj_2_22
jj_2_23
jj_2_24
jj_2_25
jj_2_26
jj_2_27
jj_2_28
jj_2_29
jj_2_30
jj_2_31
jj_2_32
jj_2_33
jj_2_34
jj_2_35
jj_3r_seq regex group_756_9_128
jj_3r_seq regex group_756_9_121
jj_3r_seq regex group_755_5_112
jj_3r_relaxed string token_1140_3_108
jj_3r_method call expression_364_8_90
jj_3r_cmp token_1133_3_52
jj_3r_method call expression_361_3_33
jj_3r_integer token_1126_3_49
jj_3r_var or regex var_353_9_66
jj_3r_var or regex var_351_9_65
jj_3r_var or regex var_349_9_64
jj_3r_number token_1119_3_135
jj_3r_var or regex var_347_9_63
jj_3r_var or regex var_345_9_42
jj_3r_var or regex var_345_9_62
jj_3r_seq regex disj conj_720_12_107
jj_3r_assignable var_339_9_89
jj_3r_assignable var_337_9_72
jj_3r_assignable var_337_9_88
jj_3r_seq regex disj conj_719_5_71
jj_3r_basic value_327_9_80
jj_3r_basic value_325_9_79
jj_3r_basic value_323_9_78
jj_3r_basic value_321_9_77
jj_3r_basic value_319_9_76
jj_3r_basic value_317_9_67
jj_3r_basic value_317_9_75
jj_3r_seq regex repeat times_691_7_126
jj_3r_seq regex repeat times_689_8_125
jj_3r_composite field value_285_27_81
jj_3r_field value_298_13_39
jj_3_28
jj_3r_seq regex repeat times_681_8_124
jj_3_27
jj_3r_seq regex repeat times_679_8_123
jj_3r_seq regex repeat times_677_8_122
jj_3r_seq regex repeat times_676_3_118
jj_3r_composite field value_279_9_22
jj_3r_core map expr node pattern_1045_9_96
jj_3r_seq regex basic_657_12_115
jj_3r_core map var node pattern_1039_9_95
jj_3r_seq regex basic_651_9_117
jj_3r_core map var value_1033_9_134
jj_3r_value expression_271_5_45
jj_3r_attr value_961_80_131
jj_3r_seq regex basic_649_9_106
jj_3r_value expression_269_5_44
jj_3r_seq regex basic_647_9_105
jj_3r_value expression_268_3_26
jj_3r_seq regex basic_645_9_104
jj_3r_seq regex basic_643_9_103
jj_3r_function call expression_257_10_74
jj_3r_seq regex basic_641_9_102
jj_3r_seq regex basic_639_9_101
jj_3r_function call expression_256_8_61
jj_3r_seq regex basic_639_7_97
jj_3r_multi node pattern_1019_8_120
jj_3r_seq regex basic_637_5_87
jj_3r_function call expression_253_3_40
jj_3r_multi node pattern_1015_6_127
jj_3_35
jj_3r_index_244_3_30
jj_3r_attr value_965_47_133
jj_3r_multi node pattern_1006_5_119
jj_3_34
jj_3r_multi node pattern_1004_5_111
jj_3_13
jj_3_12
jj_3_11
jj_3_10
jj_3_9
jj_3_8
jj_3r_core map word pattern_986_9_110
jj_3r_seq regex_604_7_98
jj_3r_expression_224_3_31
jj_3r_seq regex_602_7_70
jj_3r_attr value_965_23_132
jj_3r_seq regex_601_4_59
jj_3r_assignable expression_217_3_38
jj_3r_attr value_964_19_58
jj_3r_attr value_962_19_57
jj_3r_string regex_592_5_23
jj_3r_attr value_961_18_56
jj_3r_assignment rule_209_3_21
jj_3r_case expression_579_11_48
jj_3r_attr value_960_13_37
jj_3_7
jj_3_6
jj_3r_case expression_577_4_29
jj_3_5
jj_3r_core map node_936_25_100
jj_3r_expression extractor rule_188_5_20
jj_3_4
jj_3r_core map node_936_23_94
jj_3_33
jj_3r_core map node_948_9_86
jj_3r_core map node_943_9_85
jj_3_3
jj_3_2
jj_3_1
jj_3r_core map node_926_13_93
jj_3r_cond expression_542_12_83
jj_3r_core map node_925_9_69
jj_3r_core map node_925_9_84
jj_3r_cond expression_541_5_68
jj_3r_node basic_916_4_54
jj_3r_node basic_913_4_53
jj_3r_node basic_913_4_35
jj_3r_cond group_528_5_92
jj_3r_cond group_526_5_91
jj_3r_cond group_525_3_82
jj_3_32
jj_3_26
jj_3_31
jj_3_30
jj_3r_basic cond expression_507_7_34
jj_3r_node group_892_3_55
jj_3_25
jj_3r_basic cond expression_504_3_99
jj_3r_list expression2_490_6_47
jj_3r_node disj conj_860_12_130
jj_3r_list expression2_486_3_28
jj_3r_node disj conj_859_5_36
jj_3r_list expression_473_6_46
jj_3r_list expression_469_3_27
jj_3_24
jj_3_23
jj_3_22
jj_3r_nested function call expression_442_6_41
jj_3_21
jj_3r_nested function call expression_440_3_24
jj_3_20
jj_3r_seq back ref_808_5_114
jj_3_19
jj_3_18
jj_3r_nested var expression_410_6_43
jj_3_17
jj_3r_seq var_792_3_113
jj_3r_nested var expression_408_3_25
jj_3r_bracketed node_780_5_116
jj_3_29
jj_3_16
jj_3r_bracketed node_776_3_109
jj_3_15
jj_3_14
jj_3r_assignable nested var expression_382_6_73
jj_3r_relaxed string_1148_5_51
jj_3r_seq regex group_758_9_129
jj_3r_relaxed string_1147_3_50
jj_3r_relaxed string_1147_3_32
jj_3r_assignable nested var expression_380_3_60
jj_la1_init_0
jj_la1_init_1
jj_consume_token
fill in stack trace
jj_scan_token
get next token
get token
jj_ntk_f
jj_add_error_token
generate parse exception
trace_enabled
enable_tracing
disable_tracing
jj_rescan_token
jj_save
tail
include special
string regex
rule type token
var
type token
param
fieldname
seq regex
field expr
exprs
expr1
expr2
disj children
conj children
cond
cases
else expr
has start
has end
multi node
capturing
xla
xsp
token_source
jj_input_stream
jj_nt
jj_ntk
jj_scanpos
jj_lastpos
jj_la
jj_gen
jj_la1
jj_la1_0
jj_la1_1
jj_2_rtns
jj_rescan
jj_gc
old token
jj_ls
jj_expentries
jj_expentry
jj_kind
jj_lasttokens
jj_endpos
oldentry
is matched
la1tokens
exptokseq
token sequence parser
lookahead success
jjcalls
add escapes
lexical err
get message
lexical_error
static_lexer_error
invalid_lexical_state
loop_detected
error code
eofseen
lex state
error line
error column
error after
cur char1
reason
token mgr error
set debug stream
jj stop string literal dfa_0
jj start nfa_0
jj stop at pos
jj move string literal dfa0_0
jj move string literal dfa1_0
jj move string literal dfa2_0
jj move string literal dfa3_0
jj move string literal dfa4_0
jj move string literal dfa5_0
jj move string literal dfa6_0
jj move string literal dfa7_0
jj move string literal dfa8_0
jj start nfa with states_0
jj move nfa_0
jj fill token
jj can move_0
skip lexical actions
more lexical actions
token lexical actions
jj check nadd
jj add states
jj check nadd two states
jj check nadd states
re init rounds
switch to
debug stream
active0
old0
jjbit vec0
jjbit vec2
starts at
hi byte
jjstr literal images
cur token image
jjnext states
cur lex state
default lex state
jjnew state cnt
jjround
jjmatched pos
jjmatched kind
matched token
error_line
error_column
error_after
lex state names
jjnew lex state
jjto token
jjto skip
jjto special
jjto more
input_stream
jjrounds
jjstate set
jjimage
jjimage len
length of match
token sequence parser token manager
is mostly compatible
has tokens regex pattern
create assignment rule
create rule
create extraction rule
lookup extract rule creator
create token pattern rule
create text pattern rule
create multi token pattern rule
create annotation extractor
add rules
var expr
stage
annotation field
tokens annotation field
tokens result annotation field
result annotation field
result nested annotation field
match find type
matched expression group
match with results
rule type
is composite
active
extract rule
filter rule
string object entry
anno key
aer
rule creator
composite_rule_type
token_pattern_rule_type
text_pattern_rule_type
filter_rule_type
token_pattern_extract_rule_creator
composite_extract_rule_creator
text_pattern_extract_rule_creator
multi_token_pattern_extract_rule_creator
default_extract_rule_creator
registered rule types
template
value extractor
value extract rule
expr extractor
expr extract rule
aer template
match result
extracted
names
rule string
add word boundaries
func
sequence match rules
find non overlapping max score
find all non overlapping matches per pattern
get triggered patterns
pattern trigger
triggered
trigger
triggered patterns
init default bindings
get defaults
set defaults
set default tokens aggregators
set default text annotation key
set default tokens annotation key
set default tokens result annotation key
set default result annotation key
set default nested results annotation key
get default results annotation extractor
set default results annotation extractor
get sequence match result extractor
set sequence match result extractor
get string match result extractor
set string match result extractor
get variables
set variables
clear variables
get default string pattern flags
set default string pattern flags
get default string match flags
set default string match flags
bind string regex
expand string regex
get string pattern
unbind
get node pattern
push
pop
variables
thread local variables
string regex variables
defaults
default string pattern flags
default string match flags
sequence match result extractor
string match result extractor
default tokens annotation key
default text annotation key
default tokens result annotation key
default result annotation key
default nested results annotation key
default tokens aggregators
default tokens aggregator
aggregate to tokens
default results annotation extractor
aggregators
string_regex_var_name_pattern
var pattern
replace
expanded
string pair entry
pex
vars
env
token sequence matcher
normalized
tokens regex annotator demo
multi matcher
tokens regex matcher demo
tokens regex demo
my annotations
my tokens annotation
my type annotation
my value annotation
run pipeline
properties default tokenize
pipeline default retokenize
pipeline with retokenize
tokens regex retokenize demo
tokens regex matcher
get annotation patterns
new string regex pattern
populate
get pattern
get normalized
get targets
getter
literal_pattern
is literal
case insensitive
string match flags
custom
anno pattern
match results
targets
is_num
cmp type
number
expression
core map expression node pattern
groups
group start
group end
default_merge_action
aggregator
merged elements
merged group
ordered groups
match pattern
result builder
sentence idx
match builder
location builder
group idx
process tokens regex request
seq match result
accept branch
reject branch
actions
min end
max end
phrase table
intervals
multi core map node pattern
string sequence annotation pattern
get order
set order
group count
get first var group
nodes to string converter
group tokens
var name
match begin
match end
set normalization cache size
read phrases
read phrases with tag scores
get longest phrase
split text
to word list
to normalized word list
add phrases
add phrase
get normalized form
create normalized form
lookup normalized
find matches
check word list match
find non overlapping phrases
find matches normalized
is longer
add form
get word list
get text
get data
get alternate forms
get phrase
get token begin
get token end
to array
phrase_end
ignore punctuation
ignore punctuation tokens
n phrases
n strings
normalized cache
init size
cache size
new normalized cache
tab pattern
check tag
columns
field delimiter regex
count delimiter regex
field delimiter pattern
count delimiter pattern
lineno
map factory
mutable double
array map factory
linked hash map factory
phrase col index
tag col index
phrases
longest
phrase text
phrase texts
tagged phrase texts
phrase data
max_list_size
phrase added
new phrase added
old phrase new form added
oldphrase
matched token end
newphrase
lookup list
n maps
punct whitespace pattern
delim pattern
poss pattern
acceptable phrases
need normalization
check start
phrase size
phrase word
phrase matches
find all
token index map
todo stack
iterator stack
token next
continue at
alternate forms
form
forms
phrasematch_length_endpoints_comparator
words array
use normalized lookup
modified
phrase table
phrase table iterator
stack entry
phrase
phrase match
token list
string list
phrase string collection
any_node
case_insensitive
normalize
unicode_case
lookup function object
get description
get param desc
get type name
compute
is integer
remove tag
signature
nargs
type name
nullable
param infos
result type name
add_function
subtract_function
multiply_function
divide_function
mod_function
max_function
min_function
pow_function
negate_function
bools
and_function
or_function
not_function
concat_function
uppercase_function
lowercase_function
print_function
format_function
join_function
create_regex_function
param_info_value_function
param_info_list
map_values_function
param_info_function
map_function
param_info_token_regex
param_info_token_list
param_info_token_list_replace
tokens_match_function
tokens_replace_function
replaced
param_info_string_regex
param_info_string
param_info_string_replace
string_match_function
string_replace_function
corelabel_factory
param_info_token
token_string_split_function
include matched as tokens
number_comparator
comparator
comp type
not_equals_function
equals_function
annotation_function
cmv
annotation field class
annotation object
cm list
get_annotation_tag_function
set_annotation_tag_function
tag value
remove_annotation_tag_function
tags_value_function
set_value_tag_function
get_value_tag_function
remove_value_tag_function
composite_value_function
field name
composite_keys_function
object_field_function
field value
field param types
list2
list_value_function
map_value_function
map_keys_function
aggregate_function
call_function
registered functions
value functions
named value function
param info
type checked function
numeric function
boolean function
string function
numeric comparator
convert value to boolean
convert value to boolean value
as object
as expression
as value
create value
get tags
set tags
simplify
has value
do evaluation
assign
is arg types compatible
check value
get attributes
get expression
to compatible object
attempt type conversion
simplify no type conversion
evaluate no type conversion
type_var
type_function
type_regex
type_string_regex
type_token_regex
type_regexmatchvar
type_string
type_number
type_composite
type_list
type_set
type_annotation_key
type_class
type_tokens
type_boolean
var_self
true
false
nil
keep null
typename
evaluated
disable caching
value expr
bind as value
vobj
digits_pattern
groupname
groupid
function
new params
cond expr
true expr
false expr
cond value
conds
param types
target param types
ex2
newline
params all has value
simplified params
func value
evaled
objs
params not null
constructor
constructors
cons
cons param types
simplified object
evaled obj
main obj
methods
m param types
is evaluated
type field expr
type value
obj val
evaluated cv
value field
string expression entry
expressions
wrapped expression
typed expression
add tag
tag list
tags1
tags
tags annotation
group_before_match
group_after_match
group var
to_interval
priority_comparator
score_comparator
order_comparator
length_comparator
len1
len2
offset_comparator
priority_score_length_order_offset_comparator
default_comparator
scorer
get match type
set match type
put spaces around target string
mark target string
find target string offsets exct
get regex
create pattern
get exct ws regex
get lws regex
get lnrm regex
find target string offsets regex
find offsets
find target string offsets
exct
exctws
lws
lnrm
case insensitive match
match type str
target string
begin mark
end mark
mark only if space
mark before
mark after
char before
char after
target string pattern cache
longest_string_comparator
target strings
word regex
punct fields
lnrm delim pattern any
lnrm delim pattern
target pattern
multi word string matcher
longest string comparator
add composite rule
add basic rule
add filter rule
append rules
create merged rule
collapse
get env
set extract rules
create extractor from files
create extractor from file
create extractor from string
extract core maps to list
extract core maps
extract core maps merged with tokens
cleanup tags
apply composite rule
extract expressions
annotate expressions
filter invalid expressions
keep temporary tags
set verbose
keep tags
collapse extraction rules
tokens annotation key
stages
limit iters
stage id
basic extract rule
composite extract rule
orig rule
collapsed
rule handled
start token offset
start token offset final
cleaned
limit
max iters
iters
new exprs
stage ids
expressions
to discard
extract okay
nfiltered
annotate group
get merged list
merge group
create merged chunk
coremap_list_to_string_converter
always triggered
annotation triggers
lowercase string triggers
string trigger filter
always triggered temp
trigger candidates
key level
effective value length
string_trigger_candidate_comparator
core map node pattern trigger
string trigger candidate
set annotations
create matched expression
get char offsets
get token offsets
get chunk offsets
is include nested
set include nested
get annotation
replace merged
replace merged using token offsets
remove null values
remove nested
remove overlapping
get best matched
chunk offsets
expression to value
result annotation extractor
tokens aggregator
annotation keys
nested
base char offset
annotation2
matched exprs
token begin to list index map
token end to list index map
istart
iend
okay chunks
coremap_to_token_offsets_interval_func
coremap_to_char_offsets_interval_func
expr_to_token_offsets_interval_func
expr_priority_comparator
expr_order_comparator
expr_length_comparator
expr_token_offset_comparator
expr_token_offsets_nested_first_comparator
expr_priority_length_comparator
expr_length_priority_comparator
expr_weight_scorer
matched expression
single annotation extractor
tag_label
tagged word factory
set category word tag
print word tag
suppress terminal details
category word tag
read
save
tag divider
word tag string
word tag
tag factory
lemma_label
word lemma tag factory
as features counter
set id
get feature count
word factory
to tagged list
to untagged list
list to string
list to original text string
word to string
extract ngram
just value
word iterator
print before before start
sentence utils
empty_string
word
word factory holder
range contains
read serialized protobuf file
file in
extract quotes util
get classifier
score best mention new
quote to mention classifier
training set
lcf
max confidence
max data idx
gold data idx
data range
data idx
is mention confidence
mention data
extract quotes classifier
chapter_break
sentence to chapter
chapter num
chapter annotator
chapter annotation
get remainder in sentence
get quote paragraph index
construct sentence
add enhanced sentences
get token range preceding quote
get token range following quote
construct core map
annotate for dependency parse
get paragraph rank
get paragraph begin number
get paragraph end number
get sents in paragraph
get sents for quote paragraphs
read gendered noun list
read family relations
read animacy list
read person map
read character list
is pronominal
setup coref
map bamman to character map
same sent
pair after
new sentence
wsp
tokens concat
doc sentences
quote begin token index
quote begin sentence index
begin sentence
prev quote
prev quote token end
curr paragraph
quote end token index
quote end sentence index
end sentence
next quote
next quote token begin
next sentence
end token index
cc deps
sentence quote removed
quote para begin
quotes in paragraph
paragraph
paragraph begin
paragraph end
gender map
noun and stats
gender
family relations
animacy list
person list
person map
person
alias
character list
aliases
potential pronoun
lower
bamman file
character map
bamman tokens
pronoun coref map
representative mention
cm sentence
cm tokens
bamman tokens
index to character name
character id
prev end
prev name
begin index
char name
begin index to name
char id
btoken
quote attribution utils
enhanced sentence annotation
male
female
unk
person
read token file
novel
chars to tokens
token offset
token id
normalized tok
character id
novel tok
bamman coref reader
do mention to speaker
animacy set
skip chains
curr chain
quote_idx
para_idx
skip chain
first pair
first paragraph
prev_idx
loose conversational speaker sieve
mssieve
get top speaker list
top speaker list
majority speaker sieve
mention begin
mention end
mention tokens
mention type
speaker
deterministic speaker sieve
make mention data
top speaker in range
remove quote names
get gender
get top speakers
update predictions
get family animate vocative
get conversational previous prediction
get conversational next prediction
get quote containing range
gender list
backward_window
backward_window_big
forward_window
forward_window_big
forward_weight
backward_weight
qsize
quote run
back span start
closest mentions backward
forward span end
closest mentions
top speakers
top speaker
next prediction
prev prediction
fam prediction
names in paragraph quotes
mention text
closest mentions forward
override gender
top speaker in range ignore gender
backwards mentions
char begin key
speaker and method
quote_index
quote containing mention
related name
speaker names
quotes in prev prev
quote paragraph
prev prev
prevprev quote
speaker name
quotes in next next
next next
next next quote
q size
baseline top speaker sieve
get paragraph begin token
get paragraph end token
get quotes in paragraph
get range exclusion
eliminate duplicates
output model
punctuation
punctuation for features
paragraph id
paragraph begin token
quote paragraph id
paragraph end token
paragraph to quotes
original range
exclusion list
leftover ranges
curr range
ex range
left range
map quote to data range
map datum to mention
gold list
sieve
quote idx
initial size
quote first sentence
quote paragraph idx
right value
left value
sent idx
mentions in previous paragraph
mentions in next paragraph
candidate mentions
ranked distance
num backwards
is left
between tokens
mention paragraph idx
sentence in mention paragraph
quote paragraph begin token
quote paragraph end token
paragraph distance
curr paragraph idx
curr sentence idx
prev paragraph begin
prev paragraph end
next paragraph index
next paragraph begin
next paragraph end
mention paragraph begin
mention paragraph end
quotes in mention paragraph
names in mention paragraph
q in mention paragraph
quote imp
quotes in quote paragraph
names data
p list
scan for names result pair
scan for names result string
quotes in prev paragraph
quote ipp
quote range
sentence in prev paragraph
prev paragraph non quote runs
non quote range
mention candidates
new list
seen text
mention candidate
clf
quotes classifier
home
specific file
props para
annotator props
qaa
supervised sieve training
features data
sieve data
resolve ambiguities
get names in paragraph
do coreference
create name matcher
scan for names new
scan for names
scan for pronouns
token range to string
find closest mention in span forward
find closest mention in span backward
find closest mentions in span forward
find closest mentions in span backward
scan for animates
one speaker sentence
range contains char index
token to location
get quote paragraph
pronoun
name
animate_noun
root name node
quote names
curr quote
curr quote paragraph
names in paragraph
coref map key
referent
child nodes
full name
curr node
text run
potential names
name indices
pointer
potential name
potential index
remove first word
non quote run
non quote runs
token range
entity mentions in doc
potential matching entity mention index
potential matching entity mention
token_idx
pronoun indices
animacy indices
closest pronoun index
closest animate
closest name index
animate indices
curr span
quotes by sentence
quote begin tok
sentence begin id
quote end tok
sentence end id
quotes in sent
existant mentions
same
first m
char index
start token
start token char begin
end token char end
sieve
token node
mention data
mention
get closest mention
do quote to mention
closest backward
closest forward
back distance
forward distance
closest mention sieve
trigram patterns
doc quotes
preceding token range
names and name indices
last name index
prev token
second prev token
pronouns indices
last pronoun index
following pair
following token range
first name index
next token
second next token
first pronoun index
trigram sieve
vocative quote to mention
curr quote index
prev paragraph
vocative found
name and indices
vocative indices
name index
prev prev token
animates
animate vocatives
animate index
vocative sieve
one name sentence
one name sentence sieve
two prev quote
two prev para
token begin idx
curr quote begin sentence
is alone in paragraph
curr token
conversational sieve
first quote and paragraph idx
prev quote idx
quote and paragraph idx
loose conversational sieve
fill in mention
get mention data
before quote punctuation
subj verb pattern
common speech words
sieve name
qmsieve
in range
dependency parses
subj verb pairs
subj
vbs
nsubj
sge
svpair
verb tok pos
subj tok pos
start char
dependency parse sieve
supervised sieve
paragraph end quote closest before
is before
is only quote in paragraph
prev quote paragraph
next quote paragraph
closest mention
paragraph end quote closest sieve
test pp
family file
animate file
gender file
characters file
core nlp
processed annotation
quote attribution test
get just text
get processed core nlpproperties
process core nlpif does not exist
get annotated file
read connection
get end index
read xmlcharacter list
write character list
read xmlformat
text elems
processed file
core nlpprops
base file name
connection list
connections
curr index
token begin char
token end char
mention start token index
mention end token index
c name
id to mention
mention id to speaker list
chapter node
chap elems
quote children
quote child
quote text
quotation offset
mention_id
annotated quote text
node text
xmlto annotation
gold quote info
data
output map results default keys
get quote chapter
mention key order
speaker key order
skipped
correct
incorrect
key order
results counter
num incorrect
mention pred type results
speaker pred type results
mention results
speaker results
speaker pred
mention begin pred
mention end pred
mention result
speaker result
m correct
m incorrect
m skipped
m precision
m recall
m f1
m accuracy
s correct
s incorrect
s skipped
s precision
s recall
s f1
s accuracy
quote attribution evaluation
single_sentence_document
single_sentence_tokenized_document
proto
arabic sentence
spanish sentence
run lemma
run sentiment
run depparse
coref
empty_props
spanish document
french document
pad opt
governor
character offset begin
character offset end
incoming dependency label
german sentence
french sentence
run ner
arabic document
chinese segmenter
chinese document
is positive
is negative
is extreme
is mild
is neutral
from int
very_positive
positive
neutral
negative
very_negative
sentiment
chinese sentence
get or create
set backend
use server
serialize
deserialize
json minified
xml minified
docid
set docid
force sentences
run pos
mock lemma
run regexner
run parse
run natlog
run openie
run kbp
as annotation
from proto
caseless_props
backend
default tokenize
default ssplit
default pos
default lemma
default ner
default regexner
default parse
default depparse
default natlog
default entity mentions
default kbp
default openie
default mention
default coref
default sentiment
custom annotators
impl
have run openie
have run kbp
api key
api secret
lazy
port str
secret
lazystr
functions
ssplit
corefs
cache annotation
basic dependencies
enhanced dependencies
enhanced plus plus dependencies
depparse
natlog
openie
triples
kbp
sentiment class
cached annotation
cid
mention proto
document
german document
keyphrase spans
keyphrases
head of span
all spans
mode in span
loopy dependency path between
dependency path between
unescape html
span begin
expect next tag
expect next lemma
in lookahead
update expectation
coarse tag
token span
governors
candidate start
selector
rtn
candidates
indexed words
backpointers
fringe
vertex index
in edge
gov index
out edge
dependent
dep index
root to start
root to end
start ancestor
seen vertices
end ancestor
least common node index
sentence algorithms
algorithms
sentence token offset begin
sentence token offset end
ner tags
regexner
incoming dependency labels
dependency graph
operator at
operators nonempty
natlog polarities
natlog polarity
openie triples
kbp triples
as core map
as core labels
raw token
raw sentence
update tokens
update parse
update dependencies
update open ie
update kbp
update sentiment
substring
lazy list
sentenceid
semgrex
tokens builders
doc fn
mod props
mapping file
ignorecase
prop
mentions of tag
last mention
all corefs
to delete entirely
setter
enhanced
sentence
count unks
print summary
populate predicted labels
cag
trees with unks
trees with unks correct
has unk
format
tree path
filter unknown
evaluate
forward propagation exception
attach labels
read trees with gold labels
read trees with predicted labels
read trees with labels
filter unknown roots
sentiment string
annotation class
numeric label
unknown_root_filter
class names
sentiment utils
convert tree
transform_tree_to_word
transform_parens
single word replacements
tregex
surgery
transformations
binary transformations
three class transformations
parent pointers
phrase ids
sentiment scores
num classes
connected
phrase id
class label
tree ids
dictionary filename
sentiment filename
tokens filename
parse filename
split filename
train filename
dev filename
file id
read sentiment dataset
transformation
ngram record size
ngram record maximum length
print length accuracies
rnntest options
classify
imdb
stanford
twitter
unlabelled
alpha
last lemma
model location
use l1
datasize
sum accuracy
sum p
sum r
fold
train test
fold classifier
ave accuracy
simple sentiment
sentiment datum
set unknown labels
set predicted labels
extract labels
set span label
span to labels
sentiment model path
sentiment model
main label
collapsed unary
pair string entry
build binarized dataset
sum error
get predicted class
add matrices
add tensors
init derivatives
init tensor derivatives
score derivatives
scale and regularize
scale and regularize tensor
backprop derivatives and error
compute tensor delta down
get tensor gradient
predictions
binary td
binary tensor td
binary cd
unary cd
word vector d
derivatives
num slices
forward prop trees
training tree
batch derivatives
current matrices
drop bias column
reg matrix
active matrices only
gold label
gold class
node weight
delta class
local cd
delta from class
delta full
old word vector d
left category
delta down
wt_df
left delta down
right delta down
wtdelta
wtdelta no bias
delta tensor
full vector
scaled full vector
node vector
classification
tensor
tensor in
tensor out
sentiment cost and gradient
model derivatives
sentiment core annotations
sentiment annotated tree
sentiment class
print confusion matrix
approx accuracy
approx combined accuracy
count length accuracy
count tree
count root
exact node accuracy
exact root accuracy
length accuracies
equivalence class names
labels correct
labels incorrect
label confusion
root labels correct
root labels incorrect
root label confusion
length labels correct
length labels incorrect
ngrams
num_ngrams
equivalence classes
confusion
a class
accuracies
approx label accuracy
approx root label accuracy
abstract evaluate
copy word vector
replace word vector
load matrix
binary name
text name
matrix file
base path
use escaped parens
slices
wcat
combined wv
convert matlab model
processed children
collapse unary transformer
epoch
dev path
new arg index
sentiment training
get class weight
epochs
debug output epochs
class weights
reg transform matrix
reg classification
reg word vector
initial adagrad weight
adagrad reset frequency
reg transform tensor
shuffle matrices
initial matrix log path
class weight string
rnntrain options
predicted trees
predicted tree
gold node
predicted node
cur options
gold path
predicted path
external evaluate
random word vectors
use tensors
simplified model
combine classification
default_class_names
binary_default_class_names
approximate_equivalence_classes
binary_approximate_equivalence_classes
default_equivalence_class_names
rnnoptions
model from matrices
random binary tensor
random transform block
random classification matrix
random word vector
init random word vectors
get tensor for node
get class wfor node
get unary classification
get binary classification
get binary transform
get binary tensor
save serialized
load serialized
print param information
binary tensors
binary classification
unary classification
binary tensor size
binary classification size
unary classification size
binary productions
unary productions
unary label
unary basic
cur index
sentiment model
set sentiment labels
set index labels
output tree vectors
output tree scores
output tree
penntrees
vectors
probabilities
trees
output formats
default_tlpp_class
input format
next annotation
stdin
formats
pout
sentiment pipeline
get generalized subtree span
get modifier subtree span
get proper noun subtree span
get subtree span
include in span
exclude from span
compute scope
validate quantifier by head
add negation to dependency graph
annotate operators
annotate unaries
annotate polarity
do one sentence
do one failed sentence
det
gen_subj
gen_obj
gen_cop
gen_clause
gen_prep
neg_quantifier
neg_pattern
quantifier
single word quantifiers
patterns
unary_pattern
doubt_words
doubt_pattern
valid arcs
edge label
nmod_obl_arcs
modifier_arcs
noun_component_arcs
jj_component_arcs
to include
to exclude
operator
quantifier span
subject
is proper noun subject
sentence length
subj span
obj span
subject subtree
vanilla object span
is unary
gloss fn
quant index
positive offset to check
offset end
gloss
gov
proper subject
named entity quantifier
quantifier info
has expl
new subject
outgoing edge
scope
old scope
is operator
token matcher
doubt
spec or null
in scope
polarity
do polarity
ne quantifiers
natural logic annotator
search
search implementation
aggregate deleted edges
truth of premise
max ticks
max results
deleted edges
confidence
deletion mask
current index
last deleted edge
determiner removals
ands to add
conj and
is subject
incoming edges
num iters
tree with ands
and
topological vertices
num ticks
current word
next index
can delete
lexical relation
token polarity
projected relation
tree with deletions and new mask
new mask
multiplier
result tree
tree with deletions
just deleted
other edges
forward entailer search problem
search result
search state
by fixed index
apply to truth value
known dependency arc
for dependency insertion
insertion to deletion
for dependency deletion
equivalent
forward_entailment
reverse_entailment
negation
alternation
cover
independence
fixed index
maintains truth
negates truth
maintains falsehood
negates falsehood
initial truth value
insert arc to natural logic relation
dependency label
insertion rel
forward entailer
to span
subject object pairs
find trace targets
find trace sources
count datums
process directory
consumed as subjects
subject spans
subject chunk
trace_target_pattern
trace_source_pattern
trace targets
trace sources
vp pattern
has subject
verb chunk
object chunk
trace id
verb span
trace span
subject span
object span
spans in tree
num trees processed
sources
training data from sentence
create clause dataset
get valid chunk
get valid subject chunk
get valid object chunk
get valid adverb chunk
segment verb
segment acl
allow nominals without ner
not_pat
not_over_not_word
verb_patterns
vp_patterns
full pattern
noun_token_patterns
noun_dependency_patterns
already extracted
token pattern
missing prefix be
missing suffix of
subject tokens
object tokens
relation tokens
beof comp
relation gloss
missing suffix be
istmod
relaux
ignored arc
prep word
preposition is prefix
prep chunk
optional prep chunk
rel node
should remove
valid_subject_arcs
valid_object_arcs
valid_adverb_arcs
original root
allow extra arcs
seen indices
is copula
primary case
has conj
cc edge
has parent conj
conj edge
noop arc
consume all
num known dependents
adverbs
subj noop arc
obj noop arc
rel obj
rel obj span
prep
prep edge
prep string from edge
adverbial modifiers
adv
adverb chunk
adverb token
append i
rel append
edge from subj
relation span
pp span
edge from rel
adv span
maybe obj span
maybe ppspan
found there
too may arcs
new root
relation triple segmenter
change score
padded words
assumed truth
max index
glosses
added connective
sentence fragment
do filter
handle simple cors
handle preflight cors
handle non cors
handle invalid cors
destroy
decorate corsproperties
check request type
is origin allowed
parse and store
parse string to set
is valid origin
is logging enabled
is any origin allowed
get exposed headers
is supports credentials
get preflight max age
get allowed origins
get allowed http methods
get allowed http headers
filter config
allowed origins
any origin allowed
allowed http methods
allowed http headers
exposed headers
supports credentials
preflight max age
logging enabled
decorate request
servlet request
servlet response
filter chain
request type
config allowed origins
config allowed http methods
config allowed http headers
config exposed headers
config supports credentials
config preflight max age
config logging enabled
config decorate request
origin
exposed headers string
access control request method
access control request headers header
access control request headers
headers
cors request type
join separator
origin header
access control request method header
content type
set allowed origins
set allowed http methods
set allowed http headers
lower case headers
set exposed headers
origin uri
response_header_access_control_allow_origin
response_header_access_control_allow_credentials
response_header_access_control_expose_headers
response_header_access_control_max_age
response_header_access_control_allow_methods
response_header_access_control_allow_headers
request_header_origin
request_header_access_control_request_method
request_header_access_control_request_headers
http_request_attribute_prefix
http_request_attribute_origin
http_request_attribute_is_cors_request
http_request_attribute_request_type
http_request_attribute_request_headers
simple
actual
pre_flight
not_cors
invalid_cors
http_methods
complex_http_methods
simple_http_methods
simple_http_request_headers
simple_http_response_headers
simple_http_request_content_type_values
default_allowed_origins
default_allowed_http_methods
default_preflight_maxage
default_supports_credentials
default_allowed_http_headers
default_exposed_headers
default_logging_enabled
default_decorate_request
param_cors_allowed_origins
param_cors_support_credentials
param_cors_exposed_headers
param_cors_allowed_headers
param_cors_allowed_methods
param_cors_preflight_maxage
param_cors_logging_enabled
param_cors_request_decorate
corsfilter
run with pipeline
backoff
common props
full props
backoff props
entailments
fragment
last char
servlet
open ieservlet
project lexical relation
is upwards
is downwards
projection function
operators in narrowing scope order
mono
polarity
triple
clauses
clause
open iedemo
process what is
process wh nnwill
process wh nnis
process wh nnhave is
process wh nnhave nn
process what is there
process where do
process where is
process who is
process who did
process what do
process when do
process what have
process how
process how much do
post process
to statement
word_missing
word_missing_location
word_missing_person
word_missing_time
word_adjective
word_way
word_from
word_at
word_in
word_to
from not at dict
trigger what is
body
added be
added suffix
tok i
prep num
obj type
be iter
trigger wh nnwill
answer type
lbl
trigger wh nnis
trigger wh nnhave
have
post
trigger wh nnhave nn
trigger what is there
opt span
trigger where do
question
specloc
word at
question lemmas
trigger where is
trigger who is
now
trigger who did
has verb
added person
trigger what do
mid do
mid in
post do
trigger when do
trigger what have
pre verb
post verb
trigger how
prp
do or can
word be
trigger how much do
connective
statement
uppercase
past
participle
plural
tense
found verb
translator
statements
question to statement translator
unknown token marker
natural logic annotations
operator annotation
polarity direction annotation
entailed sentences annotation
entailed clauses annotation
relation triples annotation
from index
clause_split
clause_interm
not_a_clause
training data dump
featurizer
num examples processed
dataset dump writer
raw example
problem
fragment and score
subject guess
object guess
candidate gold
decisions to add as datums
is simple split
decision
full classifier
to save
fold data
truth
serialized model
original tree
with is done
prerequisites met
split to child of edge
simple clause
add word
add subtree
strip aux mark
mock node
top clauses
apply to
order actions
hard_splits
indirect_speech_lemmas
extra edges by governor
extra edges by dependent
is clause classifier
edge to index
edge index
subject or null
distance from subj
object or null
thunk
pp or null
negative subsample ratio
positive datum weight
unknown datum weight
clause split weight
clause interm weight
classifier factory
sorted vertices
extra edges
to keep
nodes to remove
ref replace map
incoming edge
to modify
ignored edges
words to add
edges to add
to clean
to copy
mock
threshold probability
max clauses
candidate fragments
hard coded splits
action space
nontrivial edge
grandchild
first state
ticks
log prob so far
last state pair
last state
features so far
root word
extra edge
obj or null
aux edge
rel string
outgoing edge relation
forced arc order
done forced arc
log probability
best label
default_featurizer
edge rel taken
edge rel short
parent has subj
parent has obj
child has subj
child has obj
last rel short
parent neighbor
parent neighbor rel
child neighbor count
child neighbor
child neighbor rel
clause splitter search problem
training options
conjugate english
infinitive
singular_present_first_person
singular_present_second_person
singular_present_third_person
present_plural
present_participle
singular_past_first_person
singular_past_second_person
singular_past_third_person
past_plural
past
past_participle
english_tenses
tense map
column
negated
conjugated
monotone
antitone
nonmonotone
invalid
is explicit
is binary
quantifier length
quantifier begin
quantifier end
quantifier head
subject begin
subject end
object begin
object end
operator spec
mono from string
monotonicity signature
from string
every
each
the_lot_of
all_of
each_of
for_all
for_every
for_each
everyone
num
num_num
num_num_num
num_num_num_num
few
implicit_named_entity
neither
no_one
nobody
not
but
except
unary_no
unary_not
unary_no_one
unary_nt
unary_but
unary_except
general_neg_polarity
some
several
either
the
some_of
one_of
at_least
a_few
at_least_a_few
there_be
there_be_a_few
there_exist
num_of
not_all
not_every
most
many
enough
lots_of
plenty_of
heaps_of
a_load_of
loads_of
tons_of
just_num
only_num
at_most_num
glosses
values by length desc
surface form
subj mono
subj type
obj mono
delete relation
quantifier glosses
word to lower case
additive
multiplicative
guess ner
extract ner
clean tree
strip prep cases
is cyclic
ner overlap
dump accuracy
tokens to span
ner guesses
begin ner
end ner
best ner
to delete
to add
candidate appos
root incoming edges
dangling nodes
invalid edges
incoming iter
has incoming
has multiple incoming
that edge
dobj count
is prep target
incoming
found reverse
ner a
ner b
privative_adjectives
deletion probability
subj deletion probability
obj deletion probability
pp deletion probability
verb ppaffinity
verb subj ppaffinity
verb subj obj ppaffinity
verb subj ppppaffinity
verb subj ppobj affinity
verb obj affinity
upper probability cap
affinity models
pp reader
subj ppreader
subj obj ppreader
subj ppppreader
subj ppobj reader
obj reader
edge type
neighbors
neighbor rel
raw score
edge rel
natural logic weights
clauses in sentence
entailments from clause
entailments from clauses
relation in fragment
relations in fragments
relations in clause
relations in sentence
canonicalize coref
annotate sentence
grok coref mention
triple to string
reverb
ollie
qa_srl
adjective pattern
filelist
output
splitter model
no model
splitter threshold
splitter disable
entailments per sentence
ignore affinity
affinity probability cap
all nominals
resolve coref
strip entailments
clause splitter
forward entailer
without open ieprefix
adj fragments
adj
pobj
fragments
canonical mention map
canonical mention
outgoing edges
canonicalized parse
canonical mention score
tokens to mark
existing mention
requirements
mention as tokens
ner votes
ner count
ner score
exception count
exec
files to process
file to submit
open ie
set file chooser
get page
get status
browse files
approve
enable open button
changed update
insert update
remove update
url text field action performed
browse button action performed
cancel button action performed
open button action performed
close dialog
cancel_option
approve_option
modal
write object to file
write object to file no exceptions
write object to temp file
write object to temp file no exceptions
get buffered output stream
write string to file
write string to file no exceptions
write string to temp file
write string to temp file no exceptions
read object from file
get data input stream
get data output stream
read object from urlor classpath or file system
read object announcing timing from urlor classpath or file system
read object from object stream
read object from file no exceptions
write stream from string
read stream from string
find stream in class loader
find stream in classpath or file system
exists in classpath or file system
get input stream from urlor classpath or file system
input stream from file
reader from file
reader from stdin
reader from string
read lines
get stream
get line iterable
copy until eol
close ignoring exceptions
iter files recursive
find next
slurp file
slurp gzipped file
slurp file no exceptions
slurp urlno exceptions
get url encoding
slurp reader
slurp input stream
write stream to stream
read csvwith header
read csvstrictly
get file input stream
get file output stream
get buffered file reader
get buffered reader from classpath or file system
get print writer
get print writer ignoring exceptions
get print writer or die
get bzip2piped input stream
get bzip2piped output stream
read column set
read object from columns
read map
string from file
lines from file
get jnlplocal scratch
ensure dir
delete dir recursively
get extension
encoded input stream reader
encoded output stream writer
encoded output stream print writer
copy file
delete recursively
console
prompt user input
throwable to stack trace
slurp_buffer_size
eol char
default encoding
filename url or class path
num lines
filename or url
file input stream wrapper
reader open
next line
include eol
buffer size
char buffer
char buffer pos
chars in buffer
last was lf
eol reached
line separator
buff
amount read
quote char
escape char
rows
cells
cell map
csv contents
num columns
in quotes
next is escaped
column i
bzcat
err writer
err gobbler
tab
obj class
field names
delimiter
ignore header
machine name
username
tgt dir
auto flush
source channel
target channel
recursive
true target
child target
raf
lines read
lines reversed
seek
block list paths to remove
prompt
callback
ioutils
get lines iterable
line reader iterable
eol preserving line reader iterable
prime next file
coll
include dirs
recursively
roots index
file array stack
file array stack indices
ind
directory listing
fcollect
fcollect2
fcollect3
fcollect4
fcollect5
fcollect6
file sequential collection
file sequential collection iterator
gzip file
delete dir
exists and non empty
mkdir or fail
check exists or fail
check not exists or fail
source file
dest file
destination
uncompressed file name
compressed file name
a children
nsee
test dir name
test file name
test dir
ret_val
delete success
file system
mark
mark supported
close
slack
off
reader input stream
minimum
maximum
the number
number range file filter
ranges
one
number ranges file filter
write
string output stream
extension
uc ext
extension file filter
conjunction file filter
negation file filter
find regex file filter
file filters
conjunction file filter
negation file filter
find regex file filter
flush
null output stream
out gobbler
bzip2
bzip2piped output stream
accept
ignore
setup err writer
println
setup out writer
default_encoding
cached err writer
cached err encoding
cached out writer
cached out encoding
encoding print writer
cause
runtime ioexception
copy serialized object
read short
write short
read int
write int
read long
write long
b24
b16
b56
b48
b40
b32
byte array utils
first record
determine num fields
whitespace
delim
next result
record iterator
reg ex file filter
print file
encoding file reader
tee stream
get mentions in textual order
get mentions with same head
get mention map
get representative mention
get chain id
more representative than
delete mention
mention map
a that
sentence number
animacy
coref cluster id
mention id
positions
represents
men
coref chain
coref mention
coref mention comparator
mention comparator
print constants
use_truecase
use_gold_speaker_tags
use_gold_ne
use_gold_parses
use_gold_pos
use_gold_mentions
use_gold_mention_boundaries
use_discourse_salience
use_discourse_constraints
remove_apposition_predicatenominatives
remove_singletons
use_conll_auto
print_conll_output
conll mention eval script
skip_coref
sievepasses
use_animacy_list
share_attributes
allow_reparsing
language_default
language_prop
states_prop
demonym_prop
animate_prop
inanimate_prop
male_prop
neutral_prop
female_prop
plural_prop
singular_prop
sieves_prop
mention_finder_prop
mention_finder_propfile_prop
score_prop
log_prop
ace2004_prop
ace2005_prop
muc_prop
conll2011_prop
conll_output_prop
conll_scorer
parser_model_prop
parser_maxlen_prop
postprocessing_prop
maxdist_prop
replicateconll_prop
gender_number_prop
countries_prop
states_provinces_prop
optimize_sieves_prop
optimize_sieves_keep_order_prop
optimize_sieves_score_prop
run_dist_cmd_prop
run_dist_cmd_work_dir
score_file_prop
singleton_prop
singleton_model_prop
dict_list_prop
dict_pmi_prop
signatures_prop
allow_reparsing_prop
monitor_dist_cmd_finished_wait_millis
constants
lexical chain match
is named mention
check entity match
mention matcher
min tokens
ignore gender
supported ner types
role set
mention cluster
potential antecedent
main mention
ant mention
name match
coref dictionary match
relaxed head match
strict head match2
pronoun match
mark role
discourse match
alias match
exact string match
strict head match3
strict head match1
name match precise
precise constructs
flags to string
use role skip
skip this mention
coreferent
get ordered antecedents
sort mentions for pronoun
indef
mention2
ant
semantics
m string
ant string
m speaker
a speaker
meth
antecedent sentence
my sentence
ordered mentions
ordered mentions by sentence
m1position
coref clusters
ordered antecedents
same sentence
msorted
deterministic coref sieve
strict head match4
relaxed exact string match
reset docs
next doc
recall errors
extract spans
extract gold mentions
corpus path
replicate co nll
singleton model
lemmatize
thread safe
tree lemmatizer
all words
basic deps
pre speaker
utterance
cur speaker
all gold mentions
all predicted mentions
sm2
gold mentions
predicted mentions
core map
gold mentions sent
gold mentions spans
list of mentions
mention spans
coref chain map
max coref cluster id
coref id str
new mention id
id chain entry
cluster mention cnt
co nllmention extractor
entity both have proper
entity same proper head last word
entity alias
entity iwithin i
entity person disagree
entity words included
entity have incompatible modifier
entity is role appositive
entity is relative pronoun
entity is acronym
is acronym
entity is predicate nominatives
entity is apposition
entity attributes agree
entity relaxed heads agree between mentions
entity heads agree
entity exact string match
entity relaxed exact string match
entity have different location
entity number in later mention
entity have extra proper noun
antecedent is mention speaker
antecedent matches mention speaker annotation
mention matches speaker
entity same speaker
get speaker cluster id
entity subject object
entity token distance
entity cluster all coref dictionary
entity coref dictionary
context incompatible
sentence context incompatible
is context overlapping
mention cluster have proper
potential antecedent have proper
antecedent
disagree
entity words to exclude
words except stop words
min id
max id
longer
shorter
first word
second word
acronym
acronym pos
a longer1
char num
a longer
has extra ant
has extra this
head agree
m span
ant span
this has extra
length this
length m
this word set
ant word set
location modifier
pos1
has location modifier
location m
location a
a string
lowercased
m has extra
a has extra
m proper nouns
a proper nouns
numbers
antecedent words
except words
m proper
a proper
whitespace_pattern
speaker info
strict match
spkstr
mstr
spk desc str
same speaker
m utter
previous speaker
previous speaker coref cluster id
a utter
m speaker str
ant speaker str
m speaker cluster id
ant speaker cluster id
speaker string
speaker cluster id
speaker mention id
men cluster
ant cluster
dict column
dict version
mention_pair
high_freq
ant head
ranks
highest rank
reverse ranks
context1
context2
rules
calculate precision
calculate recall
calculate precision ball
calculate recall ball
calculate precision bcai
calculate recall bcai
calculate precision bconll
calculate recall bconll
ball
brahman
bcai
bconll
_type
p den
r den
r num
scorer bcubed
span to string
lowercase normalized span string
ner tokens
ner name
set singleton
get singleton features
get mention string
set discourse
set person
set semantics
is list member of
add list member
add belongs to list
is member of same list
is list like
set type
set gender
set number
set animacy
known suffix
set head string
set nerstring
heads agree
numbers agree
genders agree
animacies agree
entity types agree
included in
attributes agree
add apposition
is apposition
add predicate nominatives
is predicate nominatives
add relative pronoun
appear earlier than
longest nnpends with head
lowest npincludes head
string without article
preprocess search term
build query text
remove phrase after head
remove parenthesis
is the common noun
find dependent verb
inside in
get premodifiers
get postmodifiers
get split pattern
is coordinated
get context helper
get context
get premodifier context
is relative pronoun
is role appositive
is demonym
get position
get relation
get modifiers
get quantification
get negation
get modal
get report embedding
get coordination
mention tree
head string
ner string
original ref
head indexed word
gold coref cluster id
utter
is direct object
is indirect object
is preposition object
depending verb
twinless
generic
is singleton
sentence words
original span
mention sub tree
context parse tree
dependents
preprocessed terms
synsets
appositions
predicate nominatives
relative pronouns
list members
belong to lists
span string
m str
singleton predictor
predictor
coreference_score
person num
first letter
first name idx
second to last
converted str
verb dependency
mention span string
sub tree span string
gender number result
ner toks
enumeration pattern
tgrep pattern
common nesuffixes
suff
small
big
strict
lowest np
search terms
removed
pos comma
pos wh
premod
postmod
premodifiers
components
premod1
premod2
premodifier
postmodifier
p tokens
phrase_string
named entities
previous netype
previous neindex
ne strings
named entity
ne_str
this string
this string lower
this cased string
ant cased string
this normed
ant normed
this demonyms
ant demonyms
child pairs
child pair
poss
det
sibling
parent pairs
parent pair
marker
parent_relations
max gold id
coreference system
has real speaker name
get speaker name
get speaker desc
get speaker name strings
get mentions
contains mention
add mention
get coref cluster id
speaker id
speaker name strings
speaker desc
speaker id is number
speaker id is auto determined
default_speaker_pattern
comma pos
mention name
coref cluster id
speaker info
get next document
set filter
get document id
set document id
get part no
set part no
get sentence word lists
add sentence
set annotation
get coref chain map
concat field
words to parse
get coref spans
get ner spans
get labelled spans
get lowest common ancestor
get tree non terminal
annotate document
read next document
get mention
include
write tab sep
append frac
append int count stats
field_last
field_doc_id
field_part_no
field_word_no
field_word
field_pos_tag
field_parse_bit
field_speaker_author
field_ner_tag
field_coref
fields_min
doc iterator
cur file index
filepath
cur file
use coref bioesencoding
annotate token coref
annotate token speaker
annotate token pos
annotate token ner
annotate tree coref
annotate tree ner
background ner tag
file filter
file pattern
sort files
document id part
part no
sentence word lists
ner chunks
doc cnt
cur doc
star pattern
tagword
asterisk
hyphen
field index
default marker
check end label
open spans
remove star
word pos
open paren index
last delimiter index
is delimiter
ner spans
ner span
coref spans
coref span
left leaf
right leaf
accept pre terminals
ner chunk
tlabel
coref id
doc start
doc start length
cur sent words
cur doc id
coref g
sentence anno
new anno
coref s
all c
sentence info
chainmap
sentence tree
sentence sub trees
tree span map
word span map
ctree
final sentence
all heads
word info
next word info
mention tree label counter
mention tree non preterm label counter
mention tree preterm non preterm no match label counter
mention tree mixed label counter
mention token length counter
ner mention token length counter
mention exact tree span
non preterm span matches
total mentions
nested ner mentions
ner mentions
npt
npt2
npt span
clustered mentions
plabel
parent ner chunk
den
corpus stats
sent cnt
token cnt
co nll2011document reader
named entity annotation
coref mention annotation
document iterator
corpus stats
cluster size
predicted m1
predicted m2
gold m1
gold m2
scorer pairwise
coref core annotations
coref annotation
coref dest annotation
coref graph annotation
coref cluster id annotation
coref cluster annotation
coref chain annotation
print raw doc
ace reader
file index
gold mention list
tree for sort gold mentions
parse id
parse coref id
all mentions
previous offset
mention count
start counts
end counts
end id
acemention extractor
entity comparator
filter predicted mentions
extract predicted mentions
assign mention ids
set bare plural
extract premarked entity mentions
extract named entity mentions
extract npor prp
extract enumerations
inside ne
find head
find syntactic head
find partial span
funky find leaf with approximate span
init core label
get parser
convert to core labels
safe head
find tree with smallest span
find tree with span
remove spurious mentions
in stop list
partitive rule
is pleonastic
get pleonastic patterns
check pleonastic
assign ids
parser processor
allow reparsing
mention span set
named entity span set
max id
dummy mention id
pre ne
np or prp mention pattern
m leaves
begin idx
end idx
enumerations mention pattern
span to mention sub tree
exact match
approximateness
extent tokens
added_words
extent head
real head
word match
last noun idx
end leaf
kid label
kid start
kid end
index integer
fallback
empty properties
head index integer
start leaf
my start
my end
head pos
head ne
pleonastic patterns
tgrep patterns
np1
rule based coref mention finder
set token indices
generate feature vectors
save to serialized
token_index
entities
gold_heads
gold_men
predicted_men
p dataset
singleton predictor
set pronouns
load state abbreviation
lookup canonical american state name
load demonym lists
get demonyms
is adjectival demonym
get words from file
load animacy lists
load gender lists
load number lists
load states lists
load countries lists
load gender number
load coref dict
load coref dict pmi
load signatures
pronominal
nominal
proper
list
representativeness
singular
plural
animate
inanimate
you
she
they
report verb
report noun
non words
copulas
female pronouns
male pronouns
neutral pronouns
possessive pronouns
other pronouns
third person pronouns
second person pronouns
first person pronouns
money percent number pronouns
date time pronouns
organization pronouns
location pronouns
inanimate pronouns
animate pronouns
indefinite pronouns
gpepronouns
plural pronouns
singular pronouns
facility vehicle weapon pronouns
misc pronouns
reflexive pronouns
transparent nouns
stop words
not organization prp
quantifiers2
determiners
negations
neg_relations
modals
person pronouns
all pronouns
states abbreviation
demonyms
demonym set
adjective nation
countries
states and provinces
neutral words
female words
male words
plural words
singular words
inanimate words
animate words
gender number
coref dict
coref dict pmi
ne_signatures
states file
demonym file
result set
lowercase
animate words file
inanimate words file
male words file
neutral words file
female words file
plural words file
singular words file
sigs
demonym words
states words
coref dict files
coref dict pmifile
signatures file
dictionaries
get ordered mentions
process discourse
initialize coref cluster
is incompatible
merge incompatibles
merge acronym cache
add incompatible
find twin mentions
find twin mentions strict
find twin mentions relaxed
set paragraph annotation
find doc type
assign original id
extract gold coref clusters
get gold links
extract gold links
mark quotations
find speakers
find speakers in article
find quotation speaker
find speaker
find speakers in conversation
find paragraph speaker
find next paragraph speaker
get speaker info
number of speakers
is speaker
print mention detection
conversation
article
gold ordered mentions by sentence
predicted ordered mentions by sentence
gold coref clusters
all positions
mentionhead positions
gold links
speakers
speaker pairs
max utter
num paragraph
incompatibles
incompatible clusters
acronym cache
speaker info map
speaker mention id
head position
cid1
cid2
replacements
mid1
mid2
predicts
gold mention positions
existing mentions
gold mention head positions
remains
paragraph index
speaker change
discourse with ior you
utter index
has original id
links
antecedents
src
dst
dst mention
missed
ants
normal quotation type
inside quotation
no speaker info
use marked discourse boolean
use marked discourse
begin quotation
end quotation
utter num
subject string
subject index
paragraph utter index
next paragraph speaker
paragraph offset
current utter
last sent
count quotation mark
found gold count
count str
male
female
neutral
convert gender file
init scorers
do score
dictionaries
sieve class name
initialize and run coref
run and score coref
run and score coref dist
wait for files
from sieve name to index
from sieve order constraint string
to sieve order constraint string
optimize sieve ordering
coref return hybrid output
coreference
post processing
get singleton predictor from serialized file
filter mentions with singleton clusters
run conll eval
get conll eval summary
print top k
print f1
print sieve score
print link
print list
print link with context
format penn tree
print logs
print discourse structure
print score summary
print final conll score
get final conll score
print conll output
get links
debug print mentions
check clusters
do post processing
max sent dist
use semantics
use singleton predictor
optimize sieves
sieves keep order
optimize score type
optimize conll score
optimize metric type
optimize sub score type
sieves
sieve class names
current sieve
links count in pass
score pairwise
score bcubed
score muc
score single doc
additional correct links count
additional links count
sieve passes
valid metric types
optimize metric type ok
valid metric type
keep sieve order
orderings
first sieve constraint
last sieve constraint
sieve index
time stamp
log file name
mention finder class
mention finder prop filename
mention finder
mention finder props
fis
end time stamp
writer predicted
conll output mention predicted file
conll mention eval file
conll mention eval err file
conll mention coref eval file
conll mention coref eval err file
conll output
scores file
run dist cmd
props file
cur env
pb env
out sos
err sos
out str
err str
how many
check files
minutes
sieve names
ordered sieve indices
timestamp
score files filter
score file pattern
run distributed cmd
main work dir path
orig sieves
orig sieve names
remaining sieve indices
optimized ordering
cur sieves number
selectable sieve indices
selected
work dir path
potential sieve index
sieve selection id
job dir path
job dir
new props
dist cmd
score files
mentions map
key pair
represents hybrid version
mention position
dcoref mention
hcoref mention
hybrid coref chain
sent i
mention i
sent j
remove id
remove set
remove cluster set
remove mentions
remove id
serialized file
predict file
eval file
tmp sieve
coref cluster
one recall error printed
one precision error printed
already choose
chosen
chosenness
correctness
m c
a c
print f1first
src mention
src sentence
dst sentence
m begin
m end
men dist
previous utter index
previous speaker id
after post processing
metric type
score type
sub score type
pass index
score desc
filter singletons
conll doc sentences
conll sentence
mention begin only
mention end only
mention begin end
end mentions
coref chain id
clusters ok
sieve coreference system
do_pronoun
use_incompatibles
use_iwithini
use_apposition
use_predicatenominatives
use_acronym
use_relativepronoun
use_roleapposition
use_exactstringmatch
use_name_match
use_inclusion_headmatch
use_relaxed_headmatch
use_incompatible_modifier
use_demonym
use_words_inclusion
use_role_skip
use_relaxed_exactstringmatch
use_attributes_agree
use_wn_hypernym
use_wn_synonym
use_different_location
use_number_in_mention
use_properhead_at_last
use_alias
use_slot_match
use_discoursematch
use_distance
use_number_animacy_ne_agree
use_coref_dict
sieve options
set mention finder
arrange
get head index
tree to key
merge labels
inside
find syntactic relations
find tree pattern
add found pair
find appositions
find predicate nominatives
find relative pronouns
mark list member relation
mark mention relation
find exact match
load stanford processor
initialize utterance
current document id
stanford processor
unordered mentions
unordered gold mentions
do merge labels
mentions to trees
head tree
mentions for tree
appos
pre nomi
relative pronoun pairs
found pairs
np2
np3
head1
head2
apposition pattern
apposition pattern2
apposition pattern3
apposition pattern4
predicate nominative pattern
predicate nominative pattern2
relative pronoun pattern
found pair
this first
this last
anno sb
anno str
mention extractor
wordnet
wordnet constructor
semantics
partitions
gold mention
predicted mention
scorer muc
get precision
get recall
get f1
calculate score
recall
precision
muc
bcubed
pairwise
precision num sum
precision den sum
recall num sum
recall den sum
nf2
f1f1
coref scorer
file contents
current offset
all sentences
doc anno
sentence pattern
doc matcher
sentence matcher
doc idpattern
doc idmatcher
sentence string
ner pattern
ner1
id pattern
ref pattern
text content
sent core map
id mention
annotated sent
unannotated sent
mention in sent
annotated word
unannotated word
mucmention extractor
get cluster id
get coref mentions
get first mention
merge clusters
print coref cluster
is single pronoun cluster
coref mentions
cluster id
genders
animacies
ner strings
heads
first mention
sorted mentions
to id
for sorted print
coref cluster
round
python mod
lgamma
is dangerous
is very dangerous
is close to
gamma
log add
n choose k
pow
int pow
hypergeometric
exact binomial
one tailed fishers exact
chi square2by2
sigmoid
acos
poisson
factorial
parse double
segment double
parse int
power
vals
modulus
cof
xxx
ser
logtolerance
logtolerance_f
neg diff
accum
curr pow
n choose m
cgr
cgc
acos cache
cos value
exps
to parse
mantissa
exponent
sign
multmax
ans chi
othrow
othcol
cell12
cell21
cell22
sloppy math
mult
mult const
divide
divide const
plus
plus const
minus
minus const
log sum
log inputs
to index
max idx
maxdot
have terms
intermediate
intermediate dot
cur exp
admath
is decimal integer
is double
decint pattern
digits
hex digits
exp
fp regex
fp pattern
number matching regex
getval
getdot
setval
setdot
plus equals const
plus equals
minus equals
minus equals const
double value
float value
int value
long value
dot
init val
init dot
val to compare
dot to compare
dot value
double ad
double array to float array
float array to double array
exp in place
log in place
softmax
add in place
add mult in place
multiply in place
divide in place
pow in place
multiply
pairwise add in place
pairwise subtract in place
pairwise scale add in place
pairwise add
pairwise scale add
pairwise subtract
dot product
pairwise multiply
pairwise divide in place
has na n
has infinite
count na n
filter na n
count infinite
count non zero
count close to zero
count positive
count negative
filter infinite
filter na nand infinite
diag
average
iterative average
norm_inf
norm_1
norm
argmax_tie last
argmin
safe min
safe max
inner product
load2dmatrix from file
box
unbox to int
unbox
index of
cast to int
l1normalize
l2normalize
standardize
l2norm
l1norm
log normalize
sample from distribution
kl divergence
jensen shannon divergence
set to log deterministic
median
safe mean
sum squared error
sum squared
stdev
safe stdev
standard error of mean
sample without replacement
shuffle
contains in subarray
pearson correlation
sig level by approx rand
abs diff of means
to binary string
add mult into
multiply into
assert finite
a_i
row
scales
new scales
from scale
b scale
an a
a v
squared sum
after index
stride
assignment
double counts
drow
log total
tot2
num arg classes
sum_sq_x
sum_sq_y
mean_x
mean_y
sum_coproduct
delta_x
delta_y
pop_sd_x
pop_sd_y
cov_x_y
iterations
test statistic
successes
randomize
a total
b total
a mean
b mean
row labels
col labels
label size
cell size
print totals
row totals
col totals
col total
row label size
print row totals
print column totals
top left
a avg
b avg
vector name
array math
invalid element exception
from props
classname
coref printer
init logger
run on conll
finish
doc maker
coref algorithm
remove singleton clusters
base name
gold output
before coref output
after coref output
writer before coref
writer after coref
filtered clusters
coref system
get sorted mentions
get mention pairs
get unlabeled mention pairs
get labeled mention pairs
merge coreference clusters
merge pronouns based on speaker
check for interrupt
heuristic filter
get content words
print human readable coref
get matching spans
get matching mentions spans
filter coref chain with mention spans
filter clusters with mention spans
filter xml tags from mentions
pairs
mention pairs
cluster mentions
cluster mention
cluster mention2
mention pair
grouped mentions
other speaker
max mention distance
max mention distance with string match
word to mentions
mention to candidate antecedents
candidate antecedents
with string match
coref mention
abstract pronouns
i token
include all mentions in chain
chain matched
filter customer abstract pronouns
smentions
coref utils
is conll
get static word embeddings
get tuned word embeddings
get naembedding
get document embedding
get mention embeddings for fast
get mention embeddings
get average embedding
get word embedding
normalize word
conll
static word embeddings
tuned word embeddings
na embedding
seen sentences
dep parent
doc embedding
dep iterator
dep relation
emb
embedding extractor
pretrained
tuned
anaphoricity
pairwise
saved language particle
pretrained filename
tuned filename
anaphoricity filename
pairwise filename
saved model filename
saved embedding filename
anaphoricity model
ana bias
ana scale
pairwise model
antecedent matrix
anaphor matrix
pair features matrix
pairwise first layer bias
ncf
model serializer
get anaphoricity score
get pairwise score
get anaphor embedding
get antecedent embedding
get word embeddings
get antecedent matrix
get anaphor matrix
get pair features matrix
get pairwise first layer bias
get anaphoricity model
get pairwise model
word embeddings
mention embedding
anaphoricity features
antecedent embedding
anaphor embedding
pair features
first layer output
neural coref model
get sentence array
export data
data writer
gold cluster writer
gold cluster path
clusters
mentions list
mentions by head index
with index
doc features
feature names
doc data
sentence builder
neural coref data exporter
run coref
greedyness
feature extractor
embedding extractor
document embedding
antecedent embeddings
anaphor embeddings
anaphoricity scores
neural coref algorithm
pretrained embeddings path
default path
neural coref properties
get pair features
pairwise features
get anaphoricity features
get mention features
encode distance
encode genre
genres
english
feature vals
speaker1
speaker2
has speakers
categorical feature extractor
entity person compatible
attribute set disagree
prune attributes
entity attributes agree chinese
entity different speaker
id pair
min size
unknown_ner
different speaker
coref rules
use constituency parse
remove xml mentions
md type
get mention detection model
is mention detection training
set mention detection training
remove nested mentions
set remove nested mentions
liberal md
use gold mentions
conll output path
get data path
get train data path
get dev data path
get test data path
get input path
get scorer path
get language str
get head finder
get coref mention filter
clustering
statistical
neural
fastneural
hybrid
custom
rule
dependency
output_path_prop
return path
train
dev
test
filter coref chain
coref properties
coref mentions annotation
coref mention indexes annotation
doc info
filter mention set
input doc
get document reader
make document
find gold mention heads
get stanford core nlp
conll file filter
sentence mentions
document maker
preprocess
extract gold clusters
assign mention numbers
mention reordering
mention reordering by span
fill syntactic info
initialize mentions
fill mention info
find syntactic relations from dependency
initialize clusters
set utterance and speaker annotation
find subject
mentions in sent
has gold
s idx
t idx
copula
speaker id
speaker conversion
outside quote utterance
quote start
quote end
document preprocessor
is list like by dependency
get head parent
get head children
get head siblings
get head path to root
basic dependency
enhanced dependency
mention num
has twin
antecedent ordering
conj
has conjunction
conj in mention
w size
head parent
head children
head siblings
head path to root
read word lists
load chinese gender number animacy
load semantics
interrogative pronouns
title words
remove words
remove chars
dim vector
str to entity
dict score
animate
inanimate
singular
wordvector file
word2vec file
is coref
predicted mentions by id
gold mentions by id
speaker info given
sent word lists
sent word list
is kbp pronominal mention
report verb en
report noun en
non words en
copulas en
quantifiers en
parts en
temporals en
female pronouns en
male pronouns en
neutral pronouns en
possessive pronouns en
other pronouns en
third person pronouns en
second person pronouns en
first person pronouns en
money percent number pronouns en
date time pronouns en
organization pronouns en
location pronouns en
inanimate pronouns en
animate pronouns en
indefinite pronouns en
relative pronouns en
gpepronouns en
plural pronouns en
singular pronouns en
facility vehicle weapon pronouns en
misc pronouns en
reflexive pronouns en
transparent nouns en
stop words en
not organization prpen
quantifiers2en
determiners en
negations en
neg_relations en
modals en
report verb zh
report noun zh
non words zh
copulas zh
quantifiers zh
parts zh
temporals zh
female pronouns zh
male pronouns zh
neutral pronouns zh
possessive pronouns zh
other pronouns zh
third person pronouns zh
second person pronouns zh
first person pronouns zh
money percent number pronouns zh
date time pronouns zh
organization pronouns zh
location pronouns zh
inanimate pronouns zh
animate pronouns zh
indefinite pronouns zh
relative pronouns zh
interrogative pronouns zh
gpepronouns zh
plural pronouns zh
singular pronouns zh
facility vehicle weapon pronouns zh
misc pronouns zh
reflexive pronouns zh
transparent nouns zh
stop words zh
not organization prpzh
quantifiers2zh
determiners zh
negations zh
neg_relations zh
modals zh
title words zh
remove words zh
remove chars zh
kbp pronominal mentions
word lists
make doc info
set dependency tree
chinese head finder
print con llloading message
co nlldocument reader
co nlldocument
to mention
filter coref mentions
print loading message
filter mention spans
mentions by sentence
core nlpdocument reader
run from scratch
find coreferent antecedent
extract datum
cosine
num entities in list
thres merge
sievename
m idx
sb log
mention dist
sent dist
prob true
ant id
m first
m last
m preceding
m following
a first
a last
a preceding
a following
min sent dist
clause count
ant role
m role
headnext
m tree
m head
a tree
a head
doc size
mc number
mc gender
mc animacy
mc ner
ac number
ac gender
ac animacy
ac ner
m type
nextword
m word
m v
aggre m
aggre a
mcl
acl
normalized vector1
normalized vector2
rfsieve
speaker match
use_speakermatch
use_chinese_head_match
dcoref sieve options
resolve mention
load sieve
load sieves
has that
has to verb
skip mention type
is really coref
skip for analysis
matched mention type
sort mentions by clause
oracle
a type
m type str
a type str
rfsieve
oracle sieve
sieve prop
current sieve for train
sievenames
m id
m gold cluster id
a gold cluster id
skip ant type
m position
chinese head match
m is pronoun
attr agree
oracle sieve
check time
check memory
get thread counts
print mdlog
use co nllauto
get path model
get classifier type
get merge threshold
set merge threshold
get num trees
get seed
get num features
get tree depth
calculate feature importance
get max sent dist for sieve
get mention type
get antecedent type
get mention types
get downsampling rate
get feature count threshold
use basic features
combine object roles
use mention detection features
use dcoref rules
use posfeatures
use lexical features
use word embedding
get mention type str
get antecedent type str
get sieves
get path serialized
do pmifeature selection
get pmithres
do analysis
get skip mention type
get skip antecedent type
get path serialized word vectors
get current sieve for train
load word embedding
get path word2vec
get gender number
store train data
use default pronoun agreement
add missing annotations
lang_prop
threads_prop
seed_prop
conll_auto_prop
use_semantics_prop
current_sieve_for_train_prop
store_traindata_prop
add_missing_annotations
debug_prop
timer_prop
memory_prop
print_mdlog_prop
calculate_importance_prop
do_analysis_prop
analysis_skip_mtype_prop
analysis_skip_atype_prop
load_word_embedding_prop
word2vec_prop
word2vec_serialized_prop
path_serialized_prop
path_model_prop
classifier_type_prop
num_tree_prop
num_features_prop
tree_depth_prop
max_sent_dist_prop
mtype_prop
atype_prop
downsample_rate_prop
thres_featurecount_prop
feature_selection_prop
thres_merge_prop
thres_feature_selection_prop
default_pronoun_agreement_prop
use_basic_features_prop
combine_objectrole_prop
use_md_features_prop
use_dcorefrule_features_prop
use_pos_features_prop
use_lexical_features_prop
use_word_embedding_features_prop
dcoref sieve names
prop key
which mention
hybrid coref properties
probability of true
feature index
decision tree
decision tree node
random forest
chinese hcoref demo
log output
make coref output
check memory usage
path output
runtime
memory
hybrid coref system
print error log
is first mention
sentence string with mention
print mention detection log
print error log dcoref
link distance analysis
dcoref speaker
dcoref discourse
dcoref exact string
dcoref relaxed exact string
dcoref precise constructs
dcoref head1
dcoref head2
dcoref head3
dcoref head4
dcoref relaxed head
dcoref pronoun sieve
print cluster id
ordered ants
orders
found coref ant
correct decision
bare plural
oracle str
dcoref str
prob str
twin gold
sent str
which resolver
proper
common
pronoun
predicted in sent
hybrid coref printer
get eval summary
get final conll score from output dir
eval script
coref output dir
scorer path
base folder
files in base folder
output file name
remove spurious mentions en
remove spurious mentions zh
mention contains remove chars
mention is demonym
mention is rangren
mention is interrogative pronoun
extract named entity modifiers
add named entity strings
add gold mentions
find head chinese
is pleonastic debug
span mention
prior word
interrogatives
mention span set list
t size
s token
e token
s join
e join
head pos
pattern idx
matched pattern
coref mention finder
find mentions
remove spurious mentions zh simple
stand alones
extract features
load mention detection classifier
probability of
classify mentions
shares
e idx
pre word
mdc
dummy label
head positions
h pos
true prob
mention detection classifier
md classifier
is ne
hybrid coref mention finder
extract npor prpfrom dependency
extract mention for headword
get npspan
get npspan old
extract pronoun for headword
find head in dependency
nouns or prp
shortname
headword
np span
conj child
end idx first element
headword idx
cop
start idx
inside np
first child left right
last child left right
left right
cop idx
basic dep
cur idx
dependency coref mention finder
compress
uncompress
get index
inverse
cvf
load documents
classification scores
ranking scores
gold clusters
mention to gold
mention types
positive pairs
mention indices
labeled pairs
mentions set
max docs
anaphoricity scores loaded
clusterer data loader
clusterer doc
anaphoricity classifier
pair conjunctions
single conjunctions
disallowed prefixes
use netype
new builder
anaphoricity mfe
filter out
identifiers
get conjunction
first
last
index
index_current
index_other
index_both
index_last
ne type conjuntion
allowed
mention features
compressor
features1
features2
ids1
ids2
id1
id2
new features
conjuction
meta feature extractor
builder
load vocabulary
add numeric
relaxed string match
get propers
get role
get dependency parent
add dependency features
maximal np
num embedded nps
head embedding level
head contained in
word indicator
nextnext word
prevprev word
min_word_count
bin_exact
bin_exponent
singleton_features
vocabulary
use doc source
word counts path
mentions to extract
singleton features
first pos
last pos
prev pos
prevprev pos
nextnext pos
dep path
full embedding level
mention embedding level
syntax path
singleton features1
singleton features2
head cl1
head cl2
head pos1
head pos2
head edit distance
ms1
ms2
utterance dist
first word1
m1embedded
m2embedded
propers
propers
bin exact
bin exponent
cap
parent pos
parent word
parent relation
maximal subtree
embedded nps
embedding level
cl1
cl2
feature extractor
train ranking
get anaphoricity examples
get examples
train classification
write scores
train documents
mention to potential antecedents
potential antecedents
ranker
no antecedent
max positive score
max scoring positive
max negative score
max scoring negative
max scoring et
documents
are anaphoric
is anaphoric
num training examples
all examples
stop training
predictions name
test documents
doc scores
pairwise model trainer
get cluster merges
do training
write model
train policy
evaluate policy
run policy
set clusters
do action
do best action
is complete
get final cost
update evaluator
get actions
get hash
get mention hash
earliest mention
add suffix
capped log
best action
learn
use_classification
use_ranking
left_to_right
exact_loss
muc_weight
expert_decay
learning_rate
buffer_size_multiplier
max_docs
retrain_iterations
num_epochs
eval_frequency
min_pairs
min_pairwise_score
early_stop_threshold
early_stop_val
current doc id
merges
current pair
progress writer
train docs
config writer
best train score
train score
time elapsed
ffhr
shr
fhr
train doc
flattened examples
total cost
training
beta
use expert
action1score
action2score
anaphor seen
s hits
s misses
ff hits
ff misses
hashed scores
hashed costs
mention to cluster
global features
hash
all pairs
seen anaphors
seen antecedents
is merge
do merge
merge features
merge score
merge b3
no merge
no merge b3
max b3
mention_hashes
features cache hits
features cache misses
features cache
min score
totals
totals log
mt1
mt2
earliest
cfv
earliest1
earliest2
with suffix
good action
bad action
clusterer
global features
merge key
cluster
clusterer classifier
candidate action
training path
get default model path
classification model path
ranking model path
anaphoricity model path
clustering model path
pairwise score thresholds
min class imbalance
max train examples per document
thresholds prop
statistical coref properties
set costs
multiplicative cost
fn_pron
losses
loss
meta
fn cost
fn pronoun cost
fa cost
wl cost
incorrect
error type
c features
i features
max margin mention ranker
max examples per document
min class imbalanced per document
num p
num n
candidate antecedent
dataset builder
compressed feature vector
get combined f1
muc weight
mention to system
combined
b3evaluator
muc evaluator
clusters as list
mention to system lists
dem
gold counts
gold cluster
predicted positive
linked
eval utils
combined evaluator
abstract evaluator
b3evaluator
mucevaluator
make thresholds
thresholds
word counts file
thresholds map
pairwise scores
statistical coref algorithm
make dir
set training path
set data path
field values
classification_model
ranking_model
anaphoricity_model
clustering_model_name
extracted_features_name
pairwise models path
clustering models path
dataset file
gold clusters file
mention types file
compressor file
extracted features file
extracted features path
is train set
classification model
ranking model
statistical coref trainer
weight feature product
get weight vector
print weight vector
write weights
quadratically smoothed svm
hinge
max margin
risk
get learning rate
constant
inv scaling
get counter increment
ada grad
default loss
learning rate schedule
regularization strength
access times
examples seen
dloss
dfeature
dreg
after reg
weight difference
sorted weights
mistake
gradient
eta
tau
simple linear classifier
count based learning rate
clusterer
clustering path
classification path
ranking path
anaphoricity path
clustering coref algorithm
word counts
count words
clp
metadata writer
feature extractor runner
document examples
is new link
mention id1
mention id2
mention type1
mention type2
training examples
singleton ratio
get default output path
get num training examples
get num epochs
pairwise model
to merge
saved link path
did
doc merges
from file coref algorithm
get path singleton predictor
correct system mentions
system mentions
mention detection evaluator
fast neural coref properties
antecedent cache
anaphor cache
anaphor id
anaphor
fast neural coref algorithm
get embedding extractor
get pair feature ids
get mention feature ids
get all weights
make feature vector
add distance features
load from text files
load map from text file
pair feature ids
mention feature ids
anaphor kernel
anaphor bias
antecedent kernel
antecedent bias
pair features kernel
pair features bias
narepresentation
network layers
antecedent features
anaphor features
antecedent vector
anaphor vector
pair features vector
pair vector
feature ids
feature vector
line split
fast neural coref model
write compressor
compressor path
compressor index
compressor writer
fast neural coref data exporter
train weights
set tune sigma cv
interpret always on feature as prior
folds
numc
n_c
n_f
n_fc
p_c
p_c_f
test min
test max
trial sigma
fold size
cvsigma to perplexity
sum score
nb cv
gsls
class of
feature of
create index
to3d
priors
no_prior
quadratic_prior
huber_prior
quartic_prior
num values
sums
priorc
x exp
thetha
sigma sq
wabs
sigma qu
log conditional eq constraint function
calculate rvf
data values
dataweights
prob correct
exp sum
derivative increment
biased logistic objective function
clear results
get regularizer param range
num l2parameters
thetas array
thetas
feature indices
feature values
shift params logistic objective function
set prior
to2d
weighted probs
observed label
weighted sums
true label
weighted total
tmp value
biased log conditional objective function
update derivative
value of feature
compute empirical statistics
smooth distribution
get model probs
labeled dataset
unlabeled data list
ge features
ge feature2empirical dist
ge feature2datum list
feature2class pair derivatives
model dist
active data
active datum
wt index
c prime
f id
ge feature map
active unlabeled examples
ge feature
label id
ge fnum
cond dist
prob counter
add instances
weighted votes
instances
class lookup
l2normalize
vec
feat vec
class scores
training instances
test vec
calculate scl
calculate cl
rvfcalculate
to1d
d v
new x
get label for internal positive class
get label for internal negative class
weights as counter
get feature index
get weights
class of rvfdatum
justification of
scores of rvfdatum
probability of rvfdatum
train weighted data
biased
f wts
data weights
lof
trim to size
add weight
train labels
train values
new i
new weights
train classifier
augment feature matrix
convert labels
objective
augmented thetas
new length
identity matrix
unflatten
initialize data values
indices of
convert to array
calculate sums
calculate sigmoids
indices
intercepts
flat weights
sigmoids
probability
gammas
zprobs
logistic utils
log probability of
weights as generic counter
feature values collection
my weights
my feature index
my label index
last slash
allweights
indexf
data dimension
calculate stochastic
calculate clbatch
calculate cliterable
calculate stochastic finite difference
calculate stochastic gradient local
value at
calculate stochastic update
calculate stochastic gradient
calculate stochastic algorithmic differentiation
data iterable
use summed conditional likelihood
derivative numerator
prior derivative
parallel gradient calculation
thread idx
latch
derivative size
features arr
labelindex
runnables
prior factor
sums v
probs v
total v
xscale
gain
examples per processor
derivative ad
x ad
use sum cond obj fun
log prior
int prior
l2normalize vectors
vec bag
train weights jl
train weights ucl
train weights cl
number values
ucl
alpha class
alpha feature
alpha c
alpha f
nb weights
weights counter
feature set
f no
fno
sum values
newdata
total features
code
set platt
platt
weight counter
set c
get c
set use sigmoid
get use sigma
get delete temp files on exit flag
set delete temp files on exit flag
read model
convert weights
convert svmlight weights
convert svmstruct weights
fit sigmoid
cross validate set c
held out set c
get held out percent
set held out percent
get folds
set folds
get tune minimizer
set tune minimizer
get scorer
set scorer
get tune cv
set tune cv
get tune held out
set tune held out
get svm light verbosity
set svm light verbosity
train classifier basic
svm light learn
svm struct learn
svm perf learn
svm light classify
svm struct classify
svm perf classify
use alpha file
alpha file
delete temp files on exit
svm light verbosity
do eval
use svmperf
multiclass
model line count
num lines to skip
stop token
support vectors
threshold line
sv line
support vector
piece
index num
platt dataset
old use sigmoid
cross validator
dev set
negative scorer
c to try
average score
percent held out
tune held out
tune cv
tune minimizer
held out percent
data file
new alpha file
weights and thresh
pw2
score of rvfdatum
log probability of rvfdatum
get label indices
get feature count label indices
get top features
get top features label indices
top features to string
to biggest weight features string
to distribution string
to histogram string
bucketize value
print hist counts
to all weights string
dump sorted
justification of rvfdatum
weights as map of counters
make weight counter
adapt weights
set weights
read classifier
write classifier
save to filename
max_feature_align_width
text_serialization_delimiter
i feature
i label
active features
as counter
as indexed counter
i labels
use magnitude
weight array
this weight
lab index
descending
lowest
top features
max leng
print descending
actual size
big array
big coll
weight counts
hist
hist eg
neg
zero
x2total
ave
stddev
int part
frac part
all features
feature length
label length
f str
l str
footer
distr
sorted by feature
feat coll
map of counters
possible labels
curr
tval
weight index
thresholds c
temp pair
tgt file
feat index
set tol
set minimizer creator
set epsilon
set sigma
get sigma
use quasi newton
use stochastic meta descent
use stochastic gradient descent
use in place stochastic gradient descent
use hybrid minimizer with in place sgd
use stochastic gradient descent to quasi newton
use hybrid minimizer
set mem
use conjugate gradient ascent
set use sum
get minimizer
train classifier semi sup
train weights semi sup
train semi sup ge
get high precision features
train classifier v
set tune sigma held out
reset weight
cross validate set sigma
set held out searcher
held out set sigma
apply as double
set retrain from scratch after sigma tuning
train classifier with initial weights
load from filename
set evaluators
get classifier creator
create linear classifier
create classifier
create probabilistic classifier
mem
tune sigma held out
tune sigma cv
retrain from scratch after sigma tuning
minimizer creator
eval iters
evaluators
qn minimizer
use robust
initial smdgain
sqn minimizer
passes
smd minimizer
sgd minimizer
first minimizer
second minimizer
sgdgain
sgd passes
qn passes
hess samples
qnmem
output to file
sgd to qnminimizer
cutoff iteration
orig weights
adapt dataset
bypass tune sigma
interim weights
biased data
biased objective
semi sup objective
gefeatures
convex combo coeff
ge objective
min precision
max num features
feature2label
feature2freq
max f
validation
accuracy
sigmas to try
kfold
score fn
weights2d
sigma to try
best sigma
held out searcher
initial weights2d
initial classifier
curr line
tuples
num thresholds
get labels array
get data array
get feature counts
retain features
apply feature max count threshold
num feature tokens
num feature types
split out fold
trim data
trim labels
shuffle with side information
sample dataset
label iterator
map dataset
map datum
print svmlight format
make svm label map
num datums per label
num datums
new feature index
feat map
feat list
fraction split
normal fold size
rand index
tmpl
side information
tmp e
sample frac
sample with replacement
sample size
subset
datum num
indiced sampled
new dataset
label mapping
new label index
print c
demonstrate serialization
demonstrate serialization column data classifier
cdc
performance
baos
bais
cdc2
classifier demo
x stream
y stream
o stream
p stream
x magic
y magic
x num images
y num labels
x rows
x columns
mnist converter
obj func
biased obj func
convex combo frac
semi supervised log conditional objective function
make stop lights
green
red
working
broken
working lights
broken lights
classifier example
make datum from line
make datum from strings
is real valued
make rvfdatum from strings
read training examples
read and return training examples
read test examples
make svmlight line infos
read dataset
split line to fields
write results summary
write answer
update performance statistics
finish ranking
format csv
make datum
make rvfdatum
add all interning and prefixing rvf
add all interning and prefixing
add feature value
ptb tokenize
make ngram features
new feature printer
close feature printer
make classifier adapt l1
make classifier
regexp tokenize
split tokenize
load word vectors
serialize classifier
cross validate
default_value
default_ignore_regexp
global flags
ptb factory
plain
comments
header
the features
data info
line infos
in test phase
line no
min columns
max columns
contingency
micro accuracy
macro f1
cor
rankacc
cov
coverr
covacc
crankacc
total sim
ranksim
num groups
last group
num in group
best prob
best sim
current highest prob correct
found answer in group
stored header
cl answer
printed text
sorted labels
sim
nfe
proto feat
c word
logit
sqrt
new feature
gold ans
cnts
bit
word to substrings
feat prefix
to ngrams
internal ngrams
prefix suffix ngrams
subs
str n
str b
str e
wleng
clique writer
l1regmax
l1regmin
limit feature labels
l1regtop
l1regbottom
limit feature tol
l1regminchange
feature count
classifier desc
tokenizer regexp
ignore regexp
in word
mig
split regexp
keep bits
num dimensions
warned
my flags
my uses real values
col
binned split word count strs
binned count strs
binned values strs
trim val
flags classifier pair
class string
test info
accuracy sum
macro f1sum
dev train
dev test
dev test line infos
average accuracy
average macro f1
use prefix suffix ngrams
use split ngrams
use split prefix suffix ngrams
min ngram leng
partial ngram regexp
partial ngram pattern
exit after training featurization
split words pattern
split words tokenizer pattern
split words ignore pattern
use split words
use split word pairs
use lowercase split word pairs
use split first last words
use lowercase split words
use lowercase split first last words
split word shape
use string
binned lengths counter
binned values
binned values counter
binned values na n
real valued feature prefix
logit transform
log transform
sqrt transform
count chars
count chars bins
biased hyperplane
feature format
significant column id
use classifier factory
classifier factory args
feature minimum support
displayed column
grouping column
ranking score column
ranking accuracy class
gold answer column
use split word ngrams
max word ngram leng
min word ngram leng
use binary
word ngram boundary regexp
word ngram boundary pattern
use adapt l1
limit features
limit features labels
print to
train from svmlight
test from svmlight
print svmlight format to
display all answers
uses real values
use all split word pairs
use all split word triples
show tokenization
cross validation folds
shuffle training data
shuffle seed
csv input
split words with ptbtokenizer
split word count
log split word count
binned split word counts
csv output
print cross validation decisions
verbose optimization
column data classifier
flags
init zeros
add zero valued
prior zero
rvf
add zero
example iterator
scale features gaussian
scale features
ensure real values
scale dataset
scale datum
scale dataset gaussian
scale datum gaussian
get datum
get rvfdatum
get rvfdatum with id
get rvfdatum source
get rvfdatum id
add all with sources and ids
add source and id
add features
summary statistics
print full feature matrix
print full feature matrix with values
read svmlight format
select features from set
svm light line to rvfdatum
write svmlight format
print sparse feature matrix
print sparse feature values
get values array
to summary string
min values
max values
means
stdevs
sources and ids
percent dev
dev size
dev data
dev values
dev labels
delta x
scaled features
new val
dev weights
new labels
new data
new values
n features
sep
old id
new id
value list
items
feature items
datum no
tmpv
evaluate precision and recall
evaluate accuracy
test data
target label
num correct and target
num target guess
num target gold
logistic objective function
read datum
arr
class column
attr no
feat key
val ind
nominal data reader
get adaptation prior
int to type
get sigma squared
get sigma squared m
get epsilon
set sigma squared
set sigma squared m
compute stochastic
quadratic
huber
quartic
cosh
adapt
multiple_quadratic
log2
other prior
sigma sq m
sigma qu m
fraction of data
sigma squared old
sigma squared temp
log prior
get random sub dataset
svm light line to datum
get feature counter
get l1normalized tfidfdatum
get l1normalized tfidfdataset
ensure size
add label index
add feature indices
to summary statistics
change label index
change feature index
select features binary information gain
select features
get information gains
update labels
new size
indices to keep
line1
feature counts
feature doc counts
tfidf features
l1norm
idf
tfidf
rvf datum
rvf dataset
add new features
int features
new d
scored features
new data trimmed
feature counter
label counter
cond counter
label count
not feature count
p feature
p not feature
sum feature
sum not feature
feature label count
not feature label count
p not
class no
optimal accuracy
init mc
fmeasure
log precision
opt fmeasure
op fmeasure
log likelihood
cwa
cwa array
optimal cwa array
optimal cwa
numpositive
numnegative
data scores
elems
svm
optimum
numleft
numright
totaltaken
totalcorrect
confr
confl
loglik
prcurve
tmp l
tmp w
compute average
original train data
k fold
saved states
fold it
add binary classifier
get binary classifier
pos_label
neg_label
binary index
pos index
binary classifiers
pos label map
bin datum
binary classifier
bin scores
binary dataset
tree tagged file reader
prime next
tag separator
this iteration
index und
text tagged file reader
word column
tag column
uses comments
default_word_column
default_tag_column
tsvtagged file reader
create records
create record
get encoding
get tag separator
tree normalizer
tree range
encoding
tree_transformer
tree_normalizer
tree_range
tree_filter
word_column
tag_column
tree_reader
comments
arg pieces
tagged file record
count sentences
add tagged words
count training tags
count test tags
report
closed tags
training words
default_training_ratio
training ratio
tag word map
successful tags
num training
num total
all set
test_file_property
train_file_property
closed_tags_property
training_ratio_property
print_words_property
known args
cct
count closed tags
no spaces
input filenames
convert trees to tags
full sentence
make prefix file
eos_tag
eos_word
tagger
init lexicon
get mapping
lexicon map
mapdigits
distsim
communicate with maxent tagger server
std in
user input
std out
maxent tagger server
session
tagger client
jb init
perform tag action
input box
output box
tag button
main frame1
scroll1
scroll2
tagged str
maxent tagger gui
get class
na word
ttags
very common word thresh
very common
ambiguity classes
get instance
read ctbunk dict
default filename
ctbunk dict singleton
ctbunk_dict
ctbunk detector reader
ctbunk detector line
ctbunk dict
init conds zlambda etc
f expected
check correctness
eps1
fnum arr
data stream
lambda p
t f
lambda solve tagger
set global holder
precondition
left context
right context
is dynamic
is local
extract lv
get parenthesized arg
get parenthesized num
zero st
empty_extractor_array
p h
lastverb
arg str
extractor
read ctb dict
get tag pre
get tag suf
getpre
getsuf
ctb dict singleton
ctb_pre_dict
ctb_suf_dict
ctb detector reader
ctb detector line
pres
sufs
ctb dict
inc that
get count part
get count that
get count in
get count rb
count part
count that
count in
count rb
count wrapper
get extractor frames
arch
extrs
l window
r window
left order
right order
pos w
pos t
tag2
pos2
pos3
wsc
word position
left position
right position
position1
position2
left word
right word
max position
position3
word shaper
extractor frames
extractor word tag
extractor word lower case
extractor cword cap case
extractor two words
extractor two tags
extractor two words tag
extractor continuous tag conjunction
extractor three tags
extractor word two tags
extractor word shape classifier
extractor word shape conjunction
extractor spanish auxiliary tag
extractor spanish semiauxiliary tag
set correct tags
tag sentence
revert
get tagged nice
get tagged sentence
to nice
calculate probs
write tags and errors
update confusion matrix
test tag inference
run tag inference
set history
initialize scorer
clean up scorer
get scores
get exact scores
get approximate scores
get histories
get exact histories
run exact extractor
get approximate histories
run approximate extractor
print unknown
print top
get top3
string tags at
na tag
na tag arr
dbg
k best size
min words lock tags
orig words
final tags
num right
num unknown
num wrong unknown
end size pairs
history
local context scores
reuse tags
prev size
has offset
probabilities
hyp
tagindex
verbose results
uee
best tags
histories
n default
log score inactive tags
full scores
rare
ex r
extractors size
all ex
all ex r
extractor vals
total s
col names
lc s
extractors
extractors rare
sz common
f associations
f num
num sent
pfu
rank
correct tag
top ids
prob tags
arr1
test sentence
release
get history
history table
default_num_threads
thread_flag
configs
taggers
tagger num
tagger name
baseline thread
baseline results
test threaded tagger
tagger thread
dictionary extractor
read asbcunk dict
asbcunk dict singleton
asbcunk_dict
asbcunk detector reader
asbcunk detector line
asbcunk dict
get size
num elements
total sentences
total words
word tag counts
min len
new word
dat
tag counts
read data tagged
get x
history
dist sim path
extractor distsim
get val
get y
get ytag
ftilde
y tag
tagger feature
get file
get output file
get output format
get output options
get output verbosity
get output lemmas
get output options contains
get search
get iterations
get rare word thresh
get min feature thresh
get cur word min feature thresh
get rare word min feature thresh
get very common word thresh
occurring tags only
possible tags only
get lang
get open class tags
get closed class tags
wsv string to string array
get learn closed class tags
get closed tag threshold
get arch
get word function
get debug
get debug prefix
get default tag separator
get tokenize
get reg l1
get xmlinput
get verbose
get verbose results
get sgml
get nthreads
get min words lock tags
get tag inside
get tokenizer options
get tokenizer invertible
get default score
get sentence delimiter
use stdin
print gen props
get mode
save config
read config
tag
dump
search
tokenize
iterations
arch
word_function
rare_word_thresh
min_feature_thresh
cur_word_min_feature_thresh
rare_word_min_feature_thresh
very_common_word_thresh
occurring_tags_only
possible_tags_only
sigma_squared
learn_closed_class
closed_class_threshold
verbose_results
sgml
lang
tokenizer_factory
xml_input
tag_inside
approximate
tokenizer_options
default_reg_l1
output_file
output_format
output_format_options
nthreads
min_words_lock_tags
encoding_property
tag_separator_property
default values
old
srch
sought
tagger config
sorted ids
single
s id
ambiguity class
get naacl extractors
get caseless naacl extractors
get extractor frames rare
naacl2003conjunctions
lc tag features
ctb pre features
ctb suf features
asbc unk features
ctb unk dict features
starts upper case
starts lower case
contains dash
contains number
all numeric
all symbols
contains letter
contains alphanumeric
contains upper case
all upper case
none lower case
company name end
plural acronym
extract feature
c word suff1
c word suff2
c word suff3
c word suff4
c word upp case
c word number
c word dash
c no lower
c all capitalized
c company
c caseless company
c letter digit dash
c upper digit dash
c cap dist
e frames_motley_naacl2003
e frames_motley_naacl2003_left
e frames_motley_caseless_naacl2003
c word french noun suffix
c word french adv suffix
c word french verb suffix
c word french adj suffix
c word french plural suffix
french_unknown_extractors
identifier
new w
c mid sentence
c word start ucase
c word mid ucase
new e
numeric pattern
symbols pattern
company_name_window
company name ends
seen letter
seen dash
seen number
extractor1
extractor2
ex1
cword
extractor frames rare
rare extractor
company name detector
caseless company name detector
extractor ucase
extractor letter digit dash
extractor upper digit dash
extractor letter dash digit
extractor cap dist lc
extractor cap lcseen
extractor mid sentence cap
extractor start sentence cap
extractor mid sentence cap c
extractor cap c
extractor all cap
extractor all capitalized
extractor cnumber
extractor dash
extractor word suff
extractor word pref
extractors conjunction
extractor non alphanumeric
extractor numeric
extractor symbols
plural acronym detector
ctb pre detector
ctb suf detector
asbcunk detector
ctbunk dict detector
cword boolean extractor
extractor french noun suffix
extractor french adv suffix
extractor french verb suffix
extractor french adj suffix
extractor french plural suffix
extractor spanish gender
extractor spanish conditional suffix
extractor spanish imperfect er ir suffix
x indexed
tagger features
multicore wrapper demo
t sentence
tagger demo
ptb tokenizer factory
tagged sent
tagger demo2
vbn tag
vbd tag
jj tag
ed suff
en suff
one st
stopper
vbn word
all count
v bncount
v bdcount
extractor verbal vbnzero
tag accuracy
print model and accuracy
get num words
set debug
file record
unknown words
num correct sentences
write unkn dict
write words
write top words
write confusion matrix
save root
test s
unkn dict file
top words file
pf1
pf3
test classifier
test sentence processor
init types
local context
dynamic
extrs rare
extractors
set size
wordtag
pairs holder
set amb class id
get amb class id
read tag count
calculate sum cache
get first tag
amb class id
get tags cache
sum cache
null_symbol
max tag
tag count
get tagger features
get fnum arr
get features new
hash histories
populated
is populated
init templates new
add templates new
add rare templates new
get history table
s templates
t histories
num feats general
num feats all
t feature
y s
ind x
ind y
h file
h f
num feats
f k
num f
x values
num evidence
x value
f value associations
f tag associations
current1
max gt
num zeros
num gt
f all
f general
f size
tagger experiments
get open tags
get open tags array
is closed
mark closed
set learn closed tags
set open class tags
set closed class tags
deterministically expand tags
closed
open tags
open tags arr
do deterministic tag expansion
open fixed
closed tag threshold
learn closed tags
open
tag tokens
in closed
open class tags
closed class tags
seen vbn
seen vbd
seen vb
seen vbp
new tags
ttags
get tag index
get lambda solve
init default scores
get inactive tag default score
has approximate scoring
choose tokenizer factory
save extractors
read extractors
set extractors global
remove dead rules
simplify lambda
read model and init
dump model
is rare
tag tokenized string
tag core labels
cast core labels
tokenize text
train and save model
print err words per sec
get xmlwords
get tsv words
write xmlsentence
tag from xml
run tagger
run tagger stdin
run tagger sgml
tag core labels or has words
tag and output sentence
output tagged sentence
base_tagger_home
tagger_home
default_nlp_group_model_path
default_jar_path
default_distribution_path
model stream
print loading
amb classes
alltags
default score
default scores
rare word thresh
min feature thresh
cur word min feature thresh
rare word min feature thresh
x size
y size
initted
invertible
left_u
right_u
f association
dead rules
condensed lambda
feature map
size assoc
association
feature value
model file or url
tagger config
num fa
pf vp
e name
val feats
to tag
test sentence
tagged sentences
core labels
runner
milli sec
words per sec
output verbosity
output lemmas
tagged results
has core labels
xml tags
txml
format pattern
xml input
total millis
doc processor
orig iter
tag inside
maxent tagger
tagger wrapper
sentence tagging processor
fill word tag counts
add vthat taking
get count
is unknown
read tags
read verbs
set amb classes
get amb class
part taking verbs
word tag count
wrap
arrverbs
i o
t c
max num tags
dictionary
add positions
get positions
add prev
get xvalues
inc
get instances
temp hash
n feat frame
general
template hash
list instances
inf
h num
h val
feature key
extractor distsim conjunction
get yind
y num
data word tag
tokens regex example
constituency parse
dependency parse
original entity mention
basic pipeline example
load gender names
annotate entity mention
male_first_names_path
female_first_names_path
male names
female names
gender set
name file entries
name csv
names for this line
first name
gender annotator
get backends
set timeout milliseconds
do annotation
check status
shell
shutdown
url_pattern
protocol
backends
state lock
enqueued
should shutdown
free annotators
newly free
do run
freed annotator
props as json
scheduler
fallback to local pipeline
timeout milliseconds
server properties
timeout
lock
annotation done
ann input
is finished callback
max_tries
tries
userpass
basic auth
input files
has h
has help
help value
default back
back str
stanford core nlpclient
backend
backend scheduler
entity idx
inline xmloutputter
wikidict path
wikidict caseless
previous link
reuse
mention surface form key
numeric value
canonical name
wikidict annotator
build_graphs
charniak parser annotator
cdc classifier
dummy_label_column
prop file
happy annotation
sad annotation
both annotation
column data classifier annotator
xml free text
count quotes
replace unicode
get quote comparator
get core map quotes
set quote indices
make quote
get quotes
recursive quotes
is aquote map starter
is single quote with use
matches prev quote
is single quote start
is single quote end
is double quote end
is whitespace or punct
is single quote
gather quotes
use_single
max_length
ascii_quotes
allow_embedded_same
smart_quotes
extract_unclosed
attribute_quotes
quote attribution annotator
directed_quotes
relevant properties
first token char index
cleaned text
in between start
in between end
in between token text
quotes from
overall
cm quotes unicode
cm unclosed unicode
num unicode
cm quotes ascii
cm unclosed ascii
num ascii single
cm quotes ascii no single
cm unclosed ascii no single
num ascii no single
cm quotes
cm quotes unclosed
unclosed
inner quotes
curr tok
quote comparator
cm quote
embedded quotes
cm quote comp
start comp
end comp
top level
next level
sentence begin index
sentence end index
quotes map
directed
warning
to pass
q kind
q kind to pass
punct or white
base requirements
attribution requirements
extended
quote annotator
to map
to nullable
to nullable list
to nullable map
to dependency parse
to coref mention
to coref chain
to section
to quotation
extract sub list
to relation triple
to entity mention
to token
has speaker annotations
json reader
keyf
valuef
pairf
tuple
coref chain
canonical speaker
tree parse
all tokens
jsonannotation reader
set named entity tag granularity
add obsolete coreference annotations
perform mention detection
mention annotator
old_format
source nertag class
finder
all unprocessed mentions
old result
src sent
src tok
dst sent
dst tok
coreferent tokens
deterministic coref annotator
default_nthreads
default_maxtime
extra dependencies
uncollapsed deps
enhanced deps
enhanced plus plus deps
dependency parse annotator
load multi word token mappings
multi word token mapping
use dictionary
preserve casing
statistical mwtannotator
statistical multi word token mapping
use statistical model
map file path
map entries
mwt words
final document tokens
new sentence tokens
token words
mwt tag key
mwtannotator
kill
live
ping
start server
ensure server
unmount
start command
stop command
ready
annotate impl
connect_timeout
stdout
stderr
shutdown hoook
out writer
ever live
server was active
initial test
uri
server started
web service annotator
should retry exception
permanently failed exception
running process
add token offsets
matched expressions annotation key
set token offsets
extract with tokens
matched expressions annotation key name
prop name
all matched
tokens regex annotator
acronym match
coref chain to kbpmentions
convert relation name to latest
kbp is pronominal mention
not_provided
kbp properties
semgrexdir
tokensregexdir
kbp language
spanish coref system
title person pattern
relation name conversion map
statistical extractor
text to mention
acronym cluster
coreferent cluster
new cluster
kbp mentions
ann sentences
kbp mentions for coref chain
cm sentence tokens
cm char begin
cm char end
kbp mention found
coref mention tokens
title person matcher
overall match
person within match
person begin offset
person end offset
person offsets
kbp mention lengths
best index
mention by start index
kbp mention
entity link
char offset to kbpmention
ner mention char begin
ner mention char end
mention to canonical mention
original mention
index coref chain pair
coref chain kbpmentions and best index
coref chain kbpmentions
best kbpmention for chain
acceptable link
kbp mention nertag
best kbpmention for chain nertag
token match found
kbp token
best kbptoken
acronym clusters
acronym instances
acronym mention
acronym nertag
acronym text
num coreferents checked
coreferent mention
coreferent text
coreferent token strings
best org
best loc
sentence i
relation strings to triples
final triples list
subj i
subj ner
obj i
obj ner
prediction
triple string
acceptable triple
kbpannotator
write triples
write time
build dependency tree
json print
route object
indent
newline
object to json
indent_char
tree str writer
tree printer
tree str
binary tree str writer
binary tree printer
binary tree str
sentiment tree
sentiment predictions
sentiment tree string writer
open ietriples
ner confidences
ner labels with confidences
ner label
chain writer
mention writer
triple writer
component type
first call
jsonoutputter
jsonwriter
entity type confidences
entity mention core map
core map entity mention
begin char offset
end char offset
my document
canonical entity mention index
core entity mention
exact requirements
stanford_tokenize
stanford_cdc_tokenize
stanford_clean_xml
stanford_ssplit
stanford_mwt
stanford_docdate
stanford_pos
stanford_lemma
stanford_ner
stanford_regexner
stanford_tokensregex
stanford_entity_mentions
stanford_gender
stanford_truecase
stanford_parse
stanford_deterministic_coref
stanford_coref
stanford_coref_mention
stanford_relation
stanford_sentiment
stanford_column_data_classifier
stanford_dependencies
stanford_natlog
stanford_openie
stanford_quote
stanford_quote_attribution
stanford_ud_features
stanford_link
stanford_kbp
default_requirements
get default aggregator
get aggregator
default_aggregator
default_numeric_tokens_aggregator
merged key
to interval func
core map aggregator
output quotes
n sentences
doc title
doc source type
s tree
ner confidence entry
ner confidence key
token char begin
token char end
codepoint
all quotes
text outputter
do one sentence new
nsc
background_symbol
background_symbol_property
new words
new fliter
orig word
number annotator
synch coref mention entity mention
get mention finder
md name
coref properties
mention annotator requirements
curr cmtoken index
token overlap count
curr emtoken index
em tokens
mention index
mentions for this sentence
coref mention token index
coref mention to entity mention mapping
entity mention to coref mention mapping
token entity mention index
token entity mention
candidate coref mention index
candidate token coref mention
coref mention annotator
register all extensions
get number
for number
internal get value map
find value by number
get value descriptor
get descriptor for type
get descriptor
get unknown fields
internal get field accessor table
has text
get text bytes
get sentence list
get sentence or builder list
get sentence count
get sentence
get sentence or builder
get coref chain list
get coref chain or builder list
get coref chain count
get coref chain
get coref chain or builder
has doc id
get doc id
get doc idbytes
has doc date
get doc date
get doc date bytes
has calendar
get calendar
get sentenceless token list
get sentenceless token or builder list
get sentenceless token count
get sentenceless token
get sentenceless token or builder
get character list
get character or builder list
get character count
get character
get character or builder
get quote list
get quote or builder list
get quote count
get quote
get quote or builder
get mentions list
get mentions or builder list
get mentions count
get mentions or builder
has has entity mentions annotation
get has entity mentions annotation
has xml doc
get xml doc
get sections list
get sections or builder list
get sections count
get sections
get sections or builder
get mentions for coref list
get mentions for coref or builder list
get mentions for coref count
get mentions for coref
get mentions for coref or builder
has has coref mention annotation
get has coref mention annotation
has has coref annotation
get has coref annotation
get coref mention to entity mention mappings list
get coref mention to entity mention mappings count
get coref mention to entity mention mappings
get entity mention to coref mention mappings list
get entity mention to coref mention mappings count
get entity mention to coref mention mappings
is initialized
write to
get serialized size
parse from
parse delimited from
new builder for type
to builder
maybe force builder initialization
get default instance for type
build partial
clear field
clear oneof
set repeated field
add repeated field
set extension
add extension
clear extension
merge from
set text
clear text
set text bytes
ensure sentence is mutable
set sentence
add all sentence
clear sentence
remove sentence
get sentence builder
add sentence builder
get sentence builder list
get sentence field builder
ensure coref chain is mutable
set coref chain
add coref chain
add all coref chain
clear coref chain
remove coref chain
get coref chain builder
add coref chain builder
get coref chain builder list
get coref chain field builder
clear doc id
set doc idbytes
set doc date
clear doc date
set doc date bytes
set calendar
clear calendar
ensure sentenceless token is mutable
set sentenceless token
add sentenceless token
add all sentenceless token
clear sentenceless token
remove sentenceless token
get sentenceless token builder
add sentenceless token builder
get sentenceless token builder list
get sentenceless token field builder
ensure character is mutable
set character
add character
add all character
clear character
remove character
get character builder
add character builder
get character builder list
get character field builder
ensure quote is mutable
set quote
add quote
add all quote
clear quote
remove quote
get quote builder
add quote builder
get quote builder list
get quote field builder
ensure mentions is mutable
set mentions
add mentions
add all mentions
clear mentions
get mentions builder
add mentions builder
get mentions builder list
get mentions field builder
set has entity mentions annotation
clear has entity mentions annotation
set xml doc
clear xml doc
ensure sections is mutable
set sections
add sections
add all sections
clear sections
remove sections
get sections builder
add sections builder
get sections builder list
get sections field builder
ensure mentions for coref is mutable
set mentions for coref
add mentions for coref
add all mentions for coref
clear mentions for coref
remove mentions for coref
get mentions for coref builder
add mentions for coref builder
get mentions for coref builder list
get mentions for coref field builder
set has coref mention annotation
clear has coref mention annotation
set has coref annotation
clear has coref annotation
ensure coref mention to entity mention mappings is mutable
set coref mention to entity mention mappings
add coref mention to entity mention mappings
add all coref mention to entity mention mappings
clear coref mention to entity mention mappings
ensure entity mention to coref mention mappings is mutable
set entity mention to coref mention mappings
add entity mention to coref mention mappings
add all entity mention to coref mention mappings
clear entity mention to coref mention mappings
set unknown fields
merge unknown fields
get default instance
parse partial from
get parser for type
get token list
get token or builder list
get token count
get token or builder
has token offset begin
get token offset begin
has token offset end
get token offset end
has sentence index
get sentence index
has character offset begin
get character offset begin
has character offset end
get character offset end
has parse tree
get parse tree
get parse tree or builder
has binarized parse tree
get binarized parse tree
get binarized parse tree or builder
has annotated parse tree
get annotated parse tree
get annotated parse tree or builder
has sentiment
get sentiment
get sentiment bytes
get kbest parse trees list
get kbest parse trees or builder list
get kbest parse trees count
get kbest parse trees
get kbest parse trees or builder
has basic dependencies
get basic dependencies
get basic dependencies or builder
has collapsed dependencies
get collapsed dependencies
get collapsed dependencies or builder
has collapsed ccprocessed dependencies
get collapsed ccprocessed dependencies
get collapsed ccprocessed dependencies or builder
has alternative dependencies
get alternative dependencies
get alternative dependencies or builder
get openie triple list
get openie triple or builder list
get openie triple count
get openie triple
get openie triple or builder
get kbp triple list
get kbp triple or builder list
get kbp triple count
get kbp triple
get kbp triple or builder
get entailed sentence list
get entailed sentence or builder list
get entailed sentence count
get entailed sentence
get entailed sentence or builder
get entailed clause list
get entailed clause or builder list
get entailed clause count
get entailed clause
get entailed clause or builder
has enhanced dependencies
get enhanced dependencies
get enhanced dependencies or builder
has enhanced plus plus dependencies
get enhanced plus plus dependencies
get enhanced plus plus dependencies or builder
has paragraph
get paragraph
has line number
get line number
has has relation annotations
get has relation annotations
get entity list
get entity or builder list
get entity count
get entity
get entity or builder
get relation list
get relation or builder list
get relation count
get relation or builder
has has numerized tokens annotation
get has numerized tokens annotation
has has coref mentions annotation
get has coref mentions annotation
has sentence id
get sentence id
get sentence idbytes
has section date
get section date
get section date bytes
has section index
get section index
has section name
get section name
get section name bytes
has section author
get section author
get section author bytes
has section quoted
get section quoted
has has kbptriples annotation
get has kbptriples annotation
has has openie triples annotation
get has openie triples annotation
has chapter index
get chapter index
has paragraph index
get paragraph index
has enhanced sentence
get enhanced sentence
get enhanced sentence or builder
has speaker
get speaker
get speaker bytes
has speaker type
get speaker type
get speaker type bytes
ensure token is mutable
set token
add token
add all token
clear token
remove token
get token builder
add token builder
get token builder list
get token field builder
set token offset begin
clear token offset begin
set token offset end
clear token offset end
set sentence index
clear sentence index
set character offset begin
clear character offset begin
set character offset end
clear character offset end
set parse tree
merge parse tree
clear parse tree
get parse tree builder
get parse tree field builder
set binarized parse tree
merge binarized parse tree
clear binarized parse tree
get binarized parse tree builder
get binarized parse tree field builder
set annotated parse tree
merge annotated parse tree
clear annotated parse tree
get annotated parse tree builder
get annotated parse tree field builder
set sentiment
clear sentiment
set sentiment bytes
ensure kbest parse trees is mutable
set kbest parse trees
add kbest parse trees
add all kbest parse trees
clear kbest parse trees
remove kbest parse trees
get kbest parse trees builder
add kbest parse trees builder
get kbest parse trees builder list
get kbest parse trees field builder
set basic dependencies
merge basic dependencies
clear basic dependencies
get basic dependencies builder
get basic dependencies field builder
set collapsed dependencies
merge collapsed dependencies
clear collapsed dependencies
get collapsed dependencies builder
get collapsed dependencies field builder
set collapsed ccprocessed dependencies
merge collapsed ccprocessed dependencies
clear collapsed ccprocessed dependencies
get collapsed ccprocessed dependencies builder
get collapsed ccprocessed dependencies field builder
set alternative dependencies
merge alternative dependencies
clear alternative dependencies
get alternative dependencies builder
get alternative dependencies field builder
ensure openie triple is mutable
set openie triple
add openie triple
add all openie triple
clear openie triple
remove openie triple
get openie triple builder
add openie triple builder
get openie triple builder list
get openie triple field builder
ensure kbp triple is mutable
set kbp triple
add kbp triple
add all kbp triple
clear kbp triple
remove kbp triple
get kbp triple builder
add kbp triple builder
get kbp triple builder list
get kbp triple field builder
ensure entailed sentence is mutable
set entailed sentence
add entailed sentence
add all entailed sentence
clear entailed sentence
remove entailed sentence
get entailed sentence builder
add entailed sentence builder
get entailed sentence builder list
get entailed sentence field builder
ensure entailed clause is mutable
set entailed clause
add entailed clause
add all entailed clause
clear entailed clause
remove entailed clause
get entailed clause builder
add entailed clause builder
get entailed clause builder list
get entailed clause field builder
set enhanced dependencies
merge enhanced dependencies
clear enhanced dependencies
get enhanced dependencies builder
get enhanced dependencies field builder
set enhanced plus plus dependencies
merge enhanced plus plus dependencies
clear enhanced plus plus dependencies
get enhanced plus plus dependencies builder
get enhanced plus plus dependencies field builder
set paragraph
clear paragraph
set line number
clear line number
set has relation annotations
clear has relation annotations
ensure entity is mutable
set entity
add entity
add all entity
clear entity
remove entity
get entity builder
add entity builder
get entity builder list
get entity field builder
ensure relation is mutable
set relation
add relation
add all relation
clear relation
remove relation
get relation builder
add relation builder
get relation builder list
get relation field builder
set has numerized tokens annotation
clear has numerized tokens annotation
set has coref mentions annotation
clear has coref mentions annotation
set sentence id
clear sentence id
set sentence idbytes
set section date
clear section date
set section date bytes
set section index
clear section index
set section name
clear section name
set section name bytes
set section author
clear section author
set section author bytes
set section quoted
clear section quoted
set has kbptriples annotation
clear has kbptriples annotation
set has openie triples annotation
clear has openie triples annotation
set chapter index
clear chapter index
set paragraph index
clear paragraph index
set enhanced sentence
merge enhanced sentence
clear enhanced sentence
get enhanced sentence builder
get enhanced sentence field builder
set speaker
clear speaker
set speaker bytes
set speaker type
clear speaker type
set speaker type bytes
has word
get word bytes
has pos
get pos
get pos bytes
get value bytes
has category
get category
get category bytes
has before
get before
get before bytes
has after
get after
get after bytes
has original text
get original text
get original text bytes
has ner
get ner
get ner bytes
has coarse ner
get coarse ner
get coarse nerbytes
has fine grained ner
get fine grained ner
get fine grained nerbytes
get ner label probs list
get ner label probs count
get ner label probs
get ner label probs bytes
has normalized ner
get normalized ner
get normalized nerbytes
has lemma
get lemma
get lemma bytes
has begin char
get begin char
has end char
get end char
has utterance
get utterance
has begin index
get begin index
has end index
has token begin index
get token begin index
has token end index
get token end index
has timex value
get timex value or builder
has has xml context
get has xml context
get xml context list
get xml context count
get xml context
get xml context bytes
has coref cluster id
get coref cluster id
has answer
get answer
get answer bytes
has head word index
get head word index
has operator
get operator
get operator or builder
has polarity
get polarity
get polarity or builder
has polarity dir
get polarity dir
get polarity dir bytes
has span
get span
get span or builder
has quotation index
get quotation index
has conll ufeatures
get conll ufeatures
get conll ufeatures or builder
has coarse tag
get coarse tag
get coarse tag bytes
has conll utoken span
get conll utoken span
get conll utoken span or builder
has conll umisc
get conll umisc
get conll umisc bytes
has conll usecondary deps
get conll usecondary deps
get conll usecondary deps or builder
has wikipedia entity
get wikipedia entity
get wikipedia entity bytes
has is newline
get is newline
has gender
get gender bytes
has true case
get true case
get true case bytes
has true case text
get true case text
get true case text bytes
has chinese char
get chinese char
get chinese char bytes
has chinese seg
get chinese seg
get chinese seg bytes
has chinese xmlchar
get chinese xmlchar
get chinese xmlchar bytes
has arabic seg
get arabic seg
get arabic seg bytes
has section end label
get section end label
get section end label bytes
has parent
get parent
get parent bytes
get coref mention index list
get coref mention index count
get coref mention index
has entity mention index
get entity mention index
has is mwt
get is mwt
has is first mwt
get is first mwt
has mwt text
get mwt text
get mwt text bytes
has numeric value
get numeric value
has numeric type
get numeric type
get numeric type bytes
has numeric composite value
get numeric composite value
has numeric composite type
get numeric composite type
get numeric composite type bytes
has codepoint offset begin
get codepoint offset begin
has codepoint offset end
get codepoint offset end
clear word
set word bytes
set pos
clear pos
set pos bytes
clear value
set value bytes
clear category
set category bytes
clear before
set before bytes
clear after
set after bytes
clear original text
set original text bytes
set ner
clear ner
set ner bytes
set coarse ner
clear coarse ner
set coarse nerbytes
set fine grained ner
clear fine grained ner
set fine grained nerbytes
ensure ner label probs is mutable
set ner label probs
add ner label probs
add all ner label probs
clear ner label probs
add ner label probs bytes
set normalized ner
clear normalized ner
set normalized nerbytes
clear lemma
set lemma bytes
set begin char
clear begin char
set end char
clear end char
set utterance
clear utterance
set begin index
clear begin index
set end index
clear end index
set token begin index
clear token begin index
set token end index
clear token end index
set timex value
merge timex value
clear timex value
get timex value builder
get timex value field builder
set has xml context
clear has xml context
ensure xml context is mutable
set xml context
add xml context
add all xml context
clear xml context
add xml context bytes
set coref cluster id
clear coref cluster id
set answer
clear answer
set answer bytes
set head word index
clear head word index
set operator
merge operator
clear operator
get operator builder
get operator field builder
set polarity
merge polarity
clear polarity
get polarity builder
get polarity field builder
set polarity dir
clear polarity dir
set polarity dir bytes
set span
merge span
clear span
get span builder
get span field builder
set quotation index
clear quotation index
set conll ufeatures
merge conll ufeatures
clear conll ufeatures
get conll ufeatures builder
get conll ufeatures field builder
set coarse tag
clear coarse tag
set coarse tag bytes
set conll utoken span
merge conll utoken span
clear conll utoken span
get conll utoken span builder
get conll utoken span field builder
set conll umisc
clear conll umisc
set conll umisc bytes
set conll usecondary deps
merge conll usecondary deps
clear conll usecondary deps
get conll usecondary deps builder
get conll usecondary deps field builder
set wikipedia entity
clear wikipedia entity
set wikipedia entity bytes
clear is newline
clear gender
set gender bytes
set true case
clear true case
set true case bytes
set true case text
clear true case text
set true case text bytes
set chinese char
clear chinese char
set chinese char bytes
set chinese seg
clear chinese seg
set chinese seg bytes
set chinese xmlchar
clear chinese xmlchar
set chinese xmlchar bytes
set arabic seg
clear arabic seg
set arabic seg bytes
set section end label
clear section end label
set section end label bytes
set parent
clear parent
set parent bytes
ensure coref mention index is mutable
set coref mention index
add coref mention index
add all coref mention index
clear coref mention index
set entity mention index
clear entity mention index
clear is mwt
set is first mwt
clear is first mwt
set mwt text
clear mwt text
set mwt text bytes
set numeric value
clear numeric value
set numeric type
clear numeric type
set numeric type bytes
set numeric composite value
clear numeric composite value
set numeric composite type
clear numeric composite type
set numeric composite type bytes
set codepoint offset begin
clear codepoint offset begin
set codepoint offset end
clear codepoint offset end
has begin
has sentence begin
get sentence begin
has sentence end
get sentence end
has token begin
has token end
has docid
get docid
get docid bytes
has index
has author
get author
get author bytes
has mention
get mention bytes
has mention begin
get mention begin
has mention end
get mention end
has mention type
get mention type bytes
has mention sieve
get mention sieve
get mention sieve bytes
has speaker sieve
get speaker sieve
get speaker sieve bytes
has canonical mention
get canonical mention
get canonical mention bytes
has canonical mention begin
get canonical mention begin
has canonical mention end
get canonical mention end
has attribution dependency graph
get attribution dependency graph
get attribution dependency graph or builder
set begin
clear begin
set end
clear end
set sentence begin
clear sentence begin
set sentence end
clear sentence end
set token begin
clear token begin
set token end
clear token end
clear docid
set docid bytes
clear index
set author
clear author
set author bytes
set mention
clear mention
set mention bytes
set mention begin
clear mention begin
set mention end
clear mention end
set mention type
clear mention type
set mention type bytes
set mention sieve
clear mention sieve
set mention sieve bytes
set speaker sieve
clear speaker sieve
set speaker sieve bytes
set canonical mention
clear canonical mention
set canonical mention bytes
set canonical mention begin
clear canonical mention begin
set canonical mention end
clear canonical mention end
set attribution dependency graph
merge attribution dependency graph
clear attribution dependency graph
get attribution dependency graph builder
get attribution dependency graph field builder
get child list
get child or builder list
get child count
get child
get child or builder
has yield begin index
get yield begin index
has yield end index
get yield end index
has score
ensure child is mutable
set child
add child
add all child
clear child
remove child
get child builder
add child builder
get child builder list
get child field builder
set yield begin index
clear yield begin index
set yield end index
clear yield end index
clear score
has copy annotation
get copy annotation
set copy annotation
clear copy annotation
has source
has target
has dep
get dep
get dep bytes
has is extra
get is extra
has source copy
get source copy
has target copy
get target copy
has language
set source
clear source
set target
clear target
set dep
clear dep
set dep bytes
set is extra
clear is extra
set source copy
clear source copy
set target copy
clear target copy
set language
clear language
get node list
get node or builder list
get node count
get node or builder
get edge list
get edge or builder list
get edge count
get edge
get edge or builder
get root list
get root count
ensure node is mutable
set node
add node
add all node
clear node
remove node
get node builder
add node builder
get node builder list
get node field builder
ensure edge is mutable
add all edge
clear edge
remove edge
get edge builder
add edge builder
get edge builder list
get edge field builder
ensure root is mutable
set root
add all root
clear root
has mention id
get mention id
has number
get number bytes
has animacy
get animacy
get animacy bytes
has head index
has position
set mention id
clear mention id
clear number
set number bytes
clear animacy
set animacy bytes
set head index
clear head index
set position
clear position
has chain id
get mention list
get mention or builder list
get mention count
get mention or builder
has representative
get representative
set chain id
clear chain id
ensure mention is mutable
add all mention
remove mention
get mention builder
add mention builder
get mention builder list
get mention field builder
set representative
clear representative
has person
get person
get person bytes
has start index
get start index
has head string
get head string
get head string bytes
has ner string
get ner string
get ner string bytes
has original ref
get original ref
has gold coref cluster id
get gold coref cluster id
has mention num
get mention num
has sent num
get sent num
has utter
get utter
has is subject
get is subject
has is direct object
get is direct object
has is indirect object
get is indirect object
has is preposition object
get is preposition object
has has twin
get has twin
has generic
get generic
has is singleton
get is singleton
has has basic dependency
get has basic dependency
has has enhanced depenedncy
get has enhanced depenedncy
has has context parse tree
get has context parse tree
has head indexed word
get head indexed word
get head indexed word or builder
has depending verb
get depending verb
get depending verb or builder
has head word
get head word
get head word or builder
has speaker info
get speaker info or builder
get sentence words list
get sentence words or builder list
get sentence words count
get sentence words
get sentence words or builder
get original span list
get original span or builder list
get original span count
get original span
get original span or builder
get dependents list
get dependents count
get dependents
get dependents bytes
get preprocessed terms list
get preprocessed terms count
get preprocessed terms
get preprocessed terms bytes
get appositions list
get appositions count
get appositions
get predicate nominatives list
get predicate nominatives count
get predicate nominatives
get relative pronouns list
get relative pronouns count
get relative pronouns
get list members list
get list members count
get list members
get belong to lists list
get belong to lists count
get belong to lists
clear person
set person bytes
set start index
clear start index
clear head string
set head string bytes
set ner string
clear ner string
set ner string bytes
set original ref
clear original ref
set gold coref cluster id
clear gold coref cluster id
set mention num
clear mention num
set sent num
clear sent num
set utter
clear utter
set is subject
clear is subject
set is direct object
clear is direct object
set is indirect object
clear is indirect object
set is preposition object
clear is preposition object
set has twin
clear has twin
set generic
clear generic
set is singleton
clear is singleton
set has basic dependency
clear has basic dependency
set has enhanced depenedncy
clear has enhanced depenedncy
set has context parse tree
clear has context parse tree
set head indexed word
merge head indexed word
clear head indexed word
get head indexed word builder
get head indexed word field builder
set depending verb
merge depending verb
clear depending verb
get depending verb builder
get depending verb field builder
set head word
merge head word
clear head word
get head word builder
get head word field builder
set speaker info
merge speaker info
clear speaker info
get speaker info builder
get speaker info field builder
ensure sentence words is mutable
set sentence words
add sentence words
add all sentence words
clear sentence words
remove sentence words
get sentence words builder
add sentence words builder
get sentence words builder list
get sentence words field builder
ensure original span is mutable
set original span
add original span
add all original span
clear original span
remove original span
get original span builder
add original span builder
get original span builder list
get original span field builder
ensure dependents is mutable
set dependents
add dependents
add all dependents
clear dependents
add dependents bytes
ensure preprocessed terms is mutable
set preprocessed terms
add preprocessed terms
add all preprocessed terms
clear preprocessed terms
add preprocessed terms bytes
ensure appositions is mutable
set appositions
add appositions
add all appositions
clear appositions
ensure predicate nominatives is mutable
set predicate nominatives
add all predicate nominatives
clear predicate nominatives
ensure relative pronouns is mutable
set relative pronouns
add relative pronouns
add all relative pronouns
clear relative pronouns
ensure list members is mutable
set list members
add list members
add all list members
clear list members
ensure belong to lists is mutable
set belong to lists
add belong to lists
add all belong to lists
clear belong to lists
has sentence num
get sentence num
has token index
get token index
has copy count
get copy count
set sentence num
clear sentence num
set token index
clear token index
clear copy count
has speaker name
get speaker name bytes
set speaker name
clear speaker name
set speaker name bytes
has alt value
get alt value
get alt value bytes
has type
get type bytes
has tid
get tid bytes
has begin point
get begin point
has end point
get end point
set alt value
clear alt value
set alt value bytes
clear type
set type bytes
set tid
clear tid
set tid bytes
set begin point
clear begin point
set end point
clear end point
has head start
get head start
has head end
get head end
has normalized name
get normalized name
get normalized name bytes
has head token index
get head token index
has coref id
get coref id
get coref idbytes
has object id
get object id
get object idbytes
has extent start
get extent start
has extent end
get extent end
has subtype
get subtype
get subtype bytes
set head start
clear head start
set head end
clear head end
set normalized name
clear normalized name
set normalized name bytes
set head token index
clear head token index
set coref id
clear coref id
set coref idbytes
set object id
clear object id
set object idbytes
set extent start
clear extent start
set extent end
clear extent end
set subtype
clear subtype
set subtype bytes
get arg name list
get arg name count
get arg name
get arg name bytes
get arg list
get arg or builder list
get arg count
get arg
get arg or builder
has signature
get signature bytes
ensure arg name is mutable
set arg name
add arg name
add all arg name
clear arg name
add arg name bytes
ensure arg is mutable
set arg
add arg
add all arg
clear arg
remove arg
get arg builder
add arg builder
get arg builder list
get arg field builder
set signature
clear signature
set signature bytes
has name
get name bytes
has quantifier span begin
get quantifier span begin
has quantifier span end
get quantifier span end
has subject span begin
get subject span begin
has subject span end
get subject span end
has object span begin
get object span begin
has object span end
get object span end
set name
clear name
set name bytes
set quantifier span begin
clear quantifier span begin
set quantifier span end
clear quantifier span end
set subject span begin
clear subject span begin
set subject span end
clear subject span end
set object span begin
clear object span begin
set object span end
clear object span end
has project equivalence
get project equivalence
has project forward entailment
get project forward entailment
has project reverse entailment
get project reverse entailment
has project negation
get project negation
has project alternation
get project alternation
has project cover
get project cover
has project independence
get project independence
set project equivalence
clear project equivalence
set project forward entailment
clear project forward entailment
set project reverse entailment
clear project reverse entailment
set project negation
clear project negation
set project alternation
clear project alternation
set project cover
clear project cover
set project independence
clear project independence
has token start in sentence inclusive
get token start in sentence inclusive
has token end in sentence exclusive
get token end in sentence exclusive
has entity type
get entity type
get entity type bytes
has timex
get timex
get timex or builder
has canonical entity mention index
get canonical entity mention index
has entity mention text
get entity mention text
get entity mention text bytes
set token start in sentence inclusive
clear token start in sentence inclusive
set token end in sentence exclusive
clear token end in sentence exclusive
set entity type
clear entity type
set entity type bytes
set timex
merge timex
clear timex
get timex builder
get timex field builder
set canonical entity mention index
clear canonical entity mention index
set entity mention text
clear entity mention text
set entity mention text bytes
get token index list
get token index count
has root
has assumed truth
get assumed truth
ensure token index is mutable
add token index
add all token index
set assumed truth
clear assumed truth
get subject
get subject bytes
has relation
get relation bytes
has object
get object
get object bytes
has confidence
get confidence
get subject tokens list
get subject tokens or builder list
get subject tokens count
get subject tokens
get subject tokens or builder
get relation tokens list
get relation tokens or builder list
get relation tokens count
get relation tokens
get relation tokens or builder
get object tokens list
get object tokens or builder list
get object tokens count
get object tokens
get object tokens or builder
has tree
get tree or builder
has istmod
get istmod
has prefix be
get prefix be
has suffix be
get suffix be
has suffix of
get suffix of
set subject
clear subject
set subject bytes
set relation bytes
set object
clear object
set object bytes
set confidence
clear confidence
ensure subject tokens is mutable
set subject tokens
add subject tokens
add all subject tokens
clear subject tokens
remove subject tokens
get subject tokens builder
add subject tokens builder
get subject tokens builder list
get subject tokens field builder
ensure relation tokens is mutable
set relation tokens
add relation tokens
add all relation tokens
clear relation tokens
remove relation tokens
get relation tokens builder
add relation tokens builder
get relation tokens builder list
get relation tokens field builder
ensure object tokens is mutable
set object tokens
add object tokens
add all object tokens
clear object tokens
remove object tokens
get object tokens builder
add object tokens builder
get object tokens builder list
get object tokens field builder
merge tree
clear tree
get tree builder
get tree field builder
set istmod
clear istmod
set prefix be
clear prefix be
set suffix be
clear suffix be
set suffix of
clear suffix of
get key list
get key count
get key bytes
get value list
get value count
ensure key is mutable
set key
add key
add all key
clear key
add key bytes
ensure value is mutable
add all value
add value bytes
has char begin
get char begin
has char end
get char end
get sentence indexes list
get sentence indexes count
get sentence indexes
has datetime
get datetime
get datetime bytes
get quotes list
get quotes or builder list
get quotes count
get quotes or builder
has author char begin
get author char begin
has author char end
get author char end
has xml tag
get xml tag
get xml tag or builder
set char begin
clear char begin
set char end
clear char end
ensure sentence indexes is mutable
set sentence indexes
add sentence indexes
add all sentence indexes
clear sentence indexes
set datetime
clear datetime
set datetime bytes
ensure quotes is mutable
set quotes
add quotes
add all quotes
clear quotes
remove quotes
get quotes builder
add quotes builder
get quotes builder list
get quotes field builder
set author char begin
clear author char begin
set author char end
clear author char end
set xml tag
merge xml tag
clear xml tag
get xml tag builder
get xml tag field builder
has graph
get graph or builder
set graph
merge graph
clear graph
get graph builder
get graph field builder
get semgrex list
get semgrex count
get semgrex
get semgrex bytes
get query list
get query or builder list
get query count
get query
get query or builder
ensure semgrex is mutable
set semgrex
add semgrex
add all semgrex
clear semgrex
add semgrex bytes
ensure query is mutable
set query
add query
add all query
clear query
remove query
get query builder
add query builder
get query builder list
get query field builder
has match index
set match index
clear match index
has reln
get reln
get reln bytes
set reln
clear reln
set reln bytes
get reln list
get reln or builder list
get reln count
get reln or builder
ensure reln is mutable
add reln
add all reln
remove reln
get reln builder
add reln builder
get reln builder list
get reln field builder
get match list
get match or builder list
get match count
get match
get match or builder
ensure match is mutable
set match
add match
add all match
clear match
remove match
get match builder
add match builder
get match builder list
get match field builder
get result list
get result or builder list
get result count
get result
get result or builder
ensure result is mutable
set result
add result
add all result
clear result
remove result
get result builder
add result builder
get result builder list
get result field builder
has doc
get doc
get doc or builder
get pattern list
get pattern count
get pattern bytes
set doc
merge doc
clear doc
get doc builder
get doc field builder
ensure pattern is mutable
set pattern
add pattern
add all pattern
clear pattern
add pattern bytes
has sentence
has match
get group list
get group or builder list
get group count
get group or builder
merge match
ensure group is mutable
set group
add group
add all group
clear group
remove group
get group builder
add group builder
get group builder list
get group field builder
get ref case
has document
get document
get document or builder
has relative pronouns
get relative pronouns bytes
clear ref
set document
merge document
clear document
get document builder
get document field builder
set relative pronouns bytes
get contents case
has open node
get open node
has close node
get close node
clear contents
set open node
clear open node
set close node
clear close node
get nodes list
get nodes or builder list
get nodes count
get nodes or builder
ensure nodes is mutable
set nodes
add nodes
add all nodes
clear nodes
remove nodes
get nodes builder
add nodes builder
get nodes builder list
get nodes field builder
get gold
get gold or builder
get predicted list
get predicted or builder list
get predicted count
get predicted
get predicted or builder
set gold
merge gold
clear gold
get gold builder
get gold field builder
ensure predicted is mutable
set predicted
add predicted
add all predicted
clear predicted
remove predicted
get predicted builder
add predicted builder
get predicted builder list
get predicted field builder
get treebank list
get treebank or builder list
get treebank count
get treebank
get treebank or builder
ensure treebank is mutable
set treebank
add treebank
add all treebank
clear treebank
remove treebank
get treebank builder
add treebank builder
get treebank builder list
get treebank field builder
has f1
set f1
clear f1
registry
unknown
any
arabic
chinese
english
german
french
hebrew
spanish
universal english
universal chinese
unknown_value
any_value
arabic_value
chinese_value
english_value
german_value
french_value
hebrew_value
spanish_value
universal english_value
universal chinese_value
internal value map
values
desc
strong_negative
weak_negative
weak_positive
strong_positive
strong_negative_value
weak_negative_value
neutral_value
weak_positive_value
strong_positive_value
equivalence
equivalence_value
forward_entailment_value
reverse_entailment_value
negation_value
alternation_value
cover_value
independence_value
unused
extension registry
mutable_bit field0_
unknown fields
bit field0_
text_field_number
text_
sentence_field_number
sentence_
corefchain_field_number
coref chain_
docid_field_number
doc id_
docdate_field_number
doc date_
calendar_field_number
calendar_
sentencelesstoken_field_number
sentenceless token_
character_field_number
character_
quote_field_number
quote_
mentions_field_number
mentions_
hasentitymentionsannotation_field_number
has entity mentions annotation_
xmldoc_field_number
xml doc_
sections_field_number
sections_
mentionsforcoref_field_number
mentions for coref_
hascorefmentionannotation_field_number
has coref mention annotation_
hascorefannotation_field_number
has coref annotation_
corefmentiontoentitymentionmappings_field_number
coref mention to entity mention mappings_
entitymentiontocorefmentionmappings_field_number
entity mention to coref mention mappings_
memoized is initialized
extension writer
data size
prototype
from_bit field0_
to_bit field0_
oneof
parsed message
sentence builder_
builder for value
coref chain builder_
sentenceless token builder_
character builder_
quote builder_
mentions builder_
sections builder_
mentions for coref builder_
default_instance
parser
mutable_bit field1_
sub builder
bit field1_
token_field_number
token_
tokenoffsetbegin_field_number
token offset begin_
tokenoffsetend_field_number
token offset end_
sentenceindex_field_number
sentence index_
characteroffsetbegin_field_number
character offset begin_
characteroffsetend_field_number
character offset end_
parsetree_field_number
parse tree_
binarizedparsetree_field_number
binarized parse tree_
annotatedparsetree_field_number
annotated parse tree_
sentiment_field_number
sentiment_
kbestparsetrees_field_number
k best parse trees_
basicdependencies_field_number
basic dependencies_
collapseddependencies_field_number
collapsed dependencies_
collapsedccprocesseddependencies_field_number
collapsed ccprocessed dependencies_
alternativedependencies_field_number
alternative dependencies_
openietriple_field_number
openie triple_
kbptriple_field_number
kbp triple_
entailedsentence_field_number
entailed sentence_
entailedclause_field_number
entailed clause_
enhanceddependencies_field_number
enhanced dependencies_
enhancedplusplusdependencies_field_number
enhanced plus plus dependencies_
paragraph_field_number
paragraph_
linenumber_field_number
line number_
hasrelationannotations_field_number
has relation annotations_
entity_field_number
entity_
relation_field_number
relation_
hasnumerizedtokensannotation_field_number
has numerized tokens annotation_
hascorefmentionsannotation_field_number
has coref mentions annotation_
sentenceid_field_number
sentence id_
sectiondate_field_number
section date_
sectionindex_field_number
section index_
sectionname_field_number
section name_
sectionauthor_field_number
section author_
sectionquoted_field_number
section quoted_
haskbptriplesannotation_field_number
has kbptriples annotation_
hasopenietriplesannotation_field_number
has openie triples annotation_
chapterindex_field_number
chapter index_
paragraphindex_field_number
paragraph index_
enhancedsentence_field_number
enhanced sentence_
speaker_field_number
speaker_
speakertype_field_number
speaker type_
from_bit field1_
to_bit field1_
token builder_
parse tree builder_
binarized parse tree builder_
annotated parse tree builder_
k best parse trees builder_
basic dependencies builder_
collapsed dependencies builder_
collapsed ccprocessed dependencies builder_
alternative dependencies builder_
openie triple builder_
kbp triple builder_
entailed sentence builder_
entailed clause builder_
enhanced dependencies builder_
enhanced plus plus dependencies builder_
entity builder_
relation builder_
enhanced sentence builder_
word_field_number
word_
pos_field_number
pos_
value_field_number
value_
category_field_number
category_
before_field_number
before_
after_field_number
after_
originaltext_field_number
original text_
ner_field_number
ner_
coarsener_field_number
coarse ner_
finegrainedner_field_number
fine grained ner_
nerlabelprobs_field_number
ner label probs_
normalizedner_field_number
normalized ner_
lemma_field_number
lemma_
beginchar_field_number
begin char_
endchar_field_number
end char_
utterance_field_number
utterance_
beginindex_field_number
begin index_
endindex_field_number
end index_
tokenbeginindex_field_number
token begin index_
tokenendindex_field_number
token end index_
timexvalue_field_number
timex value_
hasxmlcontext_field_number
has xml context_
xmlcontext_field_number
xml context_
corefclusterid_field_number
coref cluster id_
answer_field_number
answer_
headwordindex_field_number
head word index_
operator_field_number
operator_
polarity_field_number
polarity_
polarity_dir_field_number
polarity dir_
span_field_number
span_
quotationindex_field_number
quotation index_
conllufeatures_field_number
conll ufeatures_
coarsetag_field_number
coarse tag_
conllutokenspan_field_number
conll utoken span_
conllumisc_field_number
conll umisc_
conllusecondarydeps_field_number
conll usecondary deps_
wikipediaentity_field_number
wikipedia entity_
isnewline_field_number
is newline_
gender_field_number
gender_
truecase_field_number
true case_
truecasetext_field_number
true case text_
chinesechar_field_number
chinese char_
chineseseg_field_number
chinese seg_
chinesexmlchar_field_number
chinese xmlchar_
arabicseg_field_number
arabic seg_
sectionendlabel_field_number
section end label_
parent_field_number
parent_
corefmentionindex_field_number
coref mention index_
entitymentionindex_field_number
entity mention index_
ismwt_field_number
is mwt_
isfirstmwt_field_number
is first mwt_
mwttext_field_number
mwt text_
numericvalue_field_number
numeric value_
numerictype_field_number
numeric type_
numericcompositevalue_field_number
numeric composite value_
numericcompositetype_field_number
numeric composite type_
codepointoffsetbegin_field_number
codepoint offset begin_
codepointoffsetend_field_number
codepoint offset end_
timex value builder_
operator builder_
polarity builder_
span builder_
conll ufeatures builder_
conll utoken span builder_
conll usecondary deps builder_
begin_field_number
begin_
end_field_number
end_
sentencebegin_field_number
sentence begin_
sentenceend_field_number
sentence end_
tokenbegin_field_number
token begin_
tokenend_field_number
token end_
docid_
index_field_number
index_
author_field_number
author_
mention_field_number
mention_
mentionbegin_field_number
mention begin_
mentionend_field_number
mention end_
mentiontype_field_number
mention type_
mentionsieve_field_number
mention sieve_
speakersieve_field_number
speaker sieve_
canonicalmention_field_number
canonical mention_
canonicalmentionbegin_field_number
canonical mention begin_
canonicalmentionend_field_number
canonical mention end_
attributiondependencygraph_field_number
attribution dependency graph_
attribution dependency graph builder_
raw value
child_field_number
child_
yieldbeginindex_field_number
yield begin index_
yieldendindex_field_number
yield end index_
score_field_number
score_
child builder_
copyannotation_field_number
copy annotation_
source_field_number
source_
target_field_number
target_
dep_field_number
dep_
isextra_field_number
is extra_
sourcecopy_field_number
source copy_
targetcopy_field_number
target copy_
language_field_number
language_
node_field_number
node_
edge_field_number
edge_
root_field_number
root_
root memoized serialized size
node builder_
edge builder_
mentionid_field_number
mention id_
number_field_number
number_
animacy_field_number
animacy_
headindex_field_number
head index_
position_field_number
position_
chainid_field_number
chain id_
representative_field_number
representative_
mention builder_
person_field_number
person_
startindex_field_number
start index_
headstring_field_number
head string_
nerstring_field_number
ner string_
originalref_field_number
original ref_
goldcorefclusterid_field_number
gold coref cluster id_
mentionnum_field_number
mention num_
sentnum_field_number
sent num_
utter_field_number
utter_
issubject_field_number
is subject_
isdirectobject_field_number
is direct object_
isindirectobject_field_number
is indirect object_
isprepositionobject_field_number
is preposition object_
hastwin_field_number
has twin_
generic_field_number
generic_
issingleton_field_number
is singleton_
hasbasicdependency_field_number
has basic dependency_
hasenhanceddepenedncy_field_number
has enhanced depenedncy_
hascontextparsetree_field_number
has context parse tree_
headindexedword_field_number
head indexed word_
dependingverb_field_number
depending verb_
headword_field_number
head word_
speakerinfo_field_number
speaker info_
sentencewords_field_number
sentence words_
originalspan_field_number
original span_
dependents_field_number
dependents_
preprocessedterms_field_number
preprocessed terms_
appositions_field_number
appositions_
predicatenominatives_field_number
predicate nominatives_
relativepronouns_field_number
relative pronouns_
listmembers_field_number
list members_
belongtolists_field_number
belong to lists_
head indexed word builder_
depending verb builder_
head word builder_
speaker info builder_
sentence words builder_
original span builder_
sentencenum_field_number
sentence num_
tokenindex_field_number
token index_
copycount_field_number
copy count_
speakername_field_number
speaker name_
altvalue_field_number
alt value_
type_field_number
type_
tid_field_number
tid_
beginpoint_field_number
begin point_
endpoint_field_number
end point_
headstart_field_number
head start_
headend_field_number
head end_
normalizedname_field_number
normalized name_
headtokenindex_field_number
head token index_
corefid_field_number
coref id_
objectid_field_number
object id_
extentstart_field_number
extent start_
extentend_field_number
extent end_
subtype_field_number
subtype_
argname_field_number
arg name_
arg_field_number
arg_
signature_field_number
signature_
arg builder_
name_field_number
name_
quantifierspanbegin_field_number
quantifier span begin_
quantifierspanend_field_number
quantifier span end_
subjectspanbegin_field_number
subject span begin_
subjectspanend_field_number
subject span end_
objectspanbegin_field_number
object span begin_
objectspanend_field_number
object span end_
projectequivalence_field_number
project equivalence_
projectforwardentailment_field_number
project forward entailment_
projectreverseentailment_field_number
project reverse entailment_
projectnegation_field_number
project negation_
projectalternation_field_number
project alternation_
projectcover_field_number
project cover_
projectindependence_field_number
project independence_
tokenstartinsentenceinclusive_field_number
token start in sentence inclusive_
tokenendinsentenceexclusive_field_number
token end in sentence exclusive_
entitytype_field_number
entity type_
timex_field_number
timex_
canonicalentitymentionindex_field_number
canonical entity mention index_
entitymentiontext_field_number
entity mention text_
timex builder_
assumedtruth_field_number
assumed truth_
subject_field_number
subject_
object_field_number
object_
confidence_field_number
confidence_
subjecttokens_field_number
subject tokens_
relationtokens_field_number
relation tokens_
objecttokens_field_number
object tokens_
tree_field_number
tree_
istmod_field_number
istmod_
prefixbe_field_number
prefix be_
suffixbe_field_number
suffix be_
suffixof_field_number
suffix of_
subject tokens builder_
relation tokens builder_
object tokens builder_
tree builder_
key_field_number
key_
charbegin_field_number
char begin_
charend_field_number
char end_
sentenceindexes_field_number
sentence indexes_
datetime_field_number
datetime_
quotes_field_number
quotes_
authorcharbegin_field_number
author char begin_
authorcharend_field_number
author char end_
xmltag_field_number
xml tag_
quotes builder_
xml tag builder_
graph_field_number
graph_
graph builder_
semgrex_field_number
semgrex_
query_field_number
query_
query builder_
matchindex_field_number
match index_
reln_field_number
reln_
reln builder_
match_field_number
match_
match builder_
result_field_number
result_
result builder_
doc_field_number
doc_
pattern_field_number
pattern_
doc builder_
group_field_number
group_
group builder_
ref case_
ref_
relativepronouns
ref_not_set
document_field_number
document_
document builder_
contents case_
contents_
opennode
closenode
contents_not_set
opennode_field_number
closenode_field_number
nodes_field_number
nodes_
nodes builder_
gold_field_number
gold_
predicted_field_number
predicted_
gold builder_
predicted builder_
treebank_field_number
treebank_
treebank builder_
f1_field_number
f1_
internal_static_edu_stanford_nlp_pipeline_document_descriptor
internal_static_edu_stanford_nlp_pipeline_document_field accessor table
internal_static_edu_stanford_nlp_pipeline_sentence_descriptor
internal_static_edu_stanford_nlp_pipeline_sentence_field accessor table
internal_static_edu_stanford_nlp_pipeline_token_descriptor
internal_static_edu_stanford_nlp_pipeline_token_field accessor table
internal_static_edu_stanford_nlp_pipeline_quote_descriptor
internal_static_edu_stanford_nlp_pipeline_quote_field accessor table
internal_static_edu_stanford_nlp_pipeline_parse tree_descriptor
internal_static_edu_stanford_nlp_pipeline_parse tree_field accessor table
internal_static_edu_stanford_nlp_pipeline_dependency graph_descriptor
internal_static_edu_stanford_nlp_pipeline_dependency graph_field accessor table
internal_static_edu_stanford_nlp_pipeline_dependency graph_node_descriptor
internal_static_edu_stanford_nlp_pipeline_dependency graph_node_field accessor table
internal_static_edu_stanford_nlp_pipeline_dependency graph_edge_descriptor
internal_static_edu_stanford_nlp_pipeline_dependency graph_edge_field accessor table
internal_static_edu_stanford_nlp_pipeline_coref chain_descriptor
internal_static_edu_stanford_nlp_pipeline_coref chain_field accessor table
internal_static_edu_stanford_nlp_pipeline_coref chain_coref mention_descriptor
internal_static_edu_stanford_nlp_pipeline_coref chain_coref mention_field accessor table
internal_static_edu_stanford_nlp_pipeline_mention_descriptor
internal_static_edu_stanford_nlp_pipeline_mention_field accessor table
internal_static_edu_stanford_nlp_pipeline_indexed word_descriptor
internal_static_edu_stanford_nlp_pipeline_indexed word_field accessor table
internal_static_edu_stanford_nlp_pipeline_speaker info_descriptor
internal_static_edu_stanford_nlp_pipeline_speaker info_field accessor table
internal_static_edu_stanford_nlp_pipeline_span_descriptor
internal_static_edu_stanford_nlp_pipeline_span_field accessor table
internal_static_edu_stanford_nlp_pipeline_timex_descriptor
internal_static_edu_stanford_nlp_pipeline_timex_field accessor table
internal_static_edu_stanford_nlp_pipeline_entity_descriptor
internal_static_edu_stanford_nlp_pipeline_entity_field accessor table
internal_static_edu_stanford_nlp_pipeline_relation_descriptor
internal_static_edu_stanford_nlp_pipeline_relation_field accessor table
internal_static_edu_stanford_nlp_pipeline_operator_descriptor
internal_static_edu_stanford_nlp_pipeline_operator_field accessor table
internal_static_edu_stanford_nlp_pipeline_polarity_descriptor
internal_static_edu_stanford_nlp_pipeline_polarity_field accessor table
internal_static_edu_stanford_nlp_pipeline_nermention_descriptor
internal_static_edu_stanford_nlp_pipeline_nermention_field accessor table
internal_static_edu_stanford_nlp_pipeline_sentence fragment_descriptor
internal_static_edu_stanford_nlp_pipeline_sentence fragment_field accessor table
internal_static_edu_stanford_nlp_pipeline_token location_descriptor
internal_static_edu_stanford_nlp_pipeline_token location_field accessor table
internal_static_edu_stanford_nlp_pipeline_relation triple_descriptor
internal_static_edu_stanford_nlp_pipeline_relation triple_field accessor table
internal_static_edu_stanford_nlp_pipeline_map string string_descriptor
internal_static_edu_stanford_nlp_pipeline_map string string_field accessor table
internal_static_edu_stanford_nlp_pipeline_map int string_descriptor
internal_static_edu_stanford_nlp_pipeline_map int string_field accessor table
internal_static_edu_stanford_nlp_pipeline_section_descriptor
internal_static_edu_stanford_nlp_pipeline_section_field accessor table
internal_static_edu_stanford_nlp_pipeline_semgrex request_descriptor
internal_static_edu_stanford_nlp_pipeline_semgrex request_field accessor table
internal_static_edu_stanford_nlp_pipeline_semgrex request_dependencies_descriptor
internal_static_edu_stanford_nlp_pipeline_semgrex request_dependencies_field accessor table
internal_static_edu_stanford_nlp_pipeline_semgrex response_descriptor
internal_static_edu_stanford_nlp_pipeline_semgrex response_field accessor table
internal_static_edu_stanford_nlp_pipeline_semgrex response_named node_descriptor
internal_static_edu_stanford_nlp_pipeline_semgrex response_named node_field accessor table
internal_static_edu_stanford_nlp_pipeline_semgrex response_named relation_descriptor
internal_static_edu_stanford_nlp_pipeline_semgrex response_named relation_field accessor table
internal_static_edu_stanford_nlp_pipeline_semgrex response_match_descriptor
internal_static_edu_stanford_nlp_pipeline_semgrex response_match_field accessor table
internal_static_edu_stanford_nlp_pipeline_semgrex response_semgrex result_descriptor
internal_static_edu_stanford_nlp_pipeline_semgrex response_semgrex result_field accessor table
internal_static_edu_stanford_nlp_pipeline_semgrex response_graph result_descriptor
internal_static_edu_stanford_nlp_pipeline_semgrex response_graph result_field accessor table
internal_static_edu_stanford_nlp_pipeline_tokens regex request_descriptor
internal_static_edu_stanford_nlp_pipeline_tokens regex request_field accessor table
internal_static_edu_stanford_nlp_pipeline_tokens regex response_descriptor
internal_static_edu_stanford_nlp_pipeline_tokens regex response_field accessor table
internal_static_edu_stanford_nlp_pipeline_tokens regex response_match location_descriptor
internal_static_edu_stanford_nlp_pipeline_tokens regex response_match location_field accessor table
internal_static_edu_stanford_nlp_pipeline_tokens regex response_match_descriptor
internal_static_edu_stanford_nlp_pipeline_tokens regex response_match_field accessor table
internal_static_edu_stanford_nlp_pipeline_tokens regex response_pattern match_descriptor
internal_static_edu_stanford_nlp_pipeline_tokens regex response_pattern match_field accessor table
internal_static_edu_stanford_nlp_pipeline_dependency enhancer request_descriptor
internal_static_edu_stanford_nlp_pipeline_dependency enhancer request_field accessor table
internal_static_edu_stanford_nlp_pipeline_flattened parse tree_descriptor
internal_static_edu_stanford_nlp_pipeline_flattened parse tree_field accessor table
internal_static_edu_stanford_nlp_pipeline_flattened parse tree_node_descriptor
internal_static_edu_stanford_nlp_pipeline_flattened parse tree_node_field accessor table
internal_static_edu_stanford_nlp_pipeline_evaluate parser request_descriptor
internal_static_edu_stanford_nlp_pipeline_evaluate parser request_field accessor table
internal_static_edu_stanford_nlp_pipeline_evaluate parser request_parse result_descriptor
internal_static_edu_stanford_nlp_pipeline_evaluate parser request_parse result_field accessor table
internal_static_edu_stanford_nlp_pipeline_evaluate parser response_descriptor
internal_static_edu_stanford_nlp_pipeline_evaluate parser response_field accessor table
descriptor
descriptor data
core nlpprotos
quote
parse tree
dependency graph
span
entity
relation
operator
nermention
token location
relation triple
map string string
map int string
section
semgrex request
dependencies
semgrex response
named node
named relation
match
semgrex result
graph result
tokens regex request
tokens regex response
match location
pattern match
dependency enhancer request
flattened parse tree
evaluate parser request
parse result
evaluate parser response
get default extension
get annotator implementations
get required property
load properties from classpath
load properties or exception
load properties
get properties
ensure prerequisite annotators
is xmloutput present
clear annotator pool
get named annotators
get default annotator pool
register custom annotators
construct annotator pool
get existing annotator
uses binary trees
process to core document
xml print
conll print
print help
print required properties
timing information
read file list
load serializer
create outputter
output annotation
log timing info
process files
tagged
json
conll
inlinexml
serialized
global_annotator_cache
custom_annotator_prefix
props_suffix
newline_splitter_property
newline_is_sentence_break_property
default_newline_is_sentence_break
default_output_format
pipeline setup time
available processors
pool
enforce requirements
props file name prefix
annotator pool
from class path
anno names
already added anno names
all requirements
requirement
fmt
default requirements
valid names
loader
parse index
use parse for pos
unordered annotators
prereq
ordered annotators
something added
can add
ner index
input props
annotator implementation
custom name
custom class name
help topic
is tty
one document
serializer class
output options
outputter
output serializer class
output serializer name
output serializer
custom outputter
clear pool
base output dir
base input dir
exclude files param
exclude files
input serializer class
input serializer name
replace extension
continue on annotate error
no clobber
total processed
total skipped
total error annotating
rel dir
last dot
final output filename
input serializer
finished annotation
num threads string
stanford core nlp
annotator signature
read json document
get doc cnt
annotation iterator
annotate old format
test annoation
coref doc
hcoref
hybrid coref annotator
add annotator
get total time
accumulated time
beginning of document
satisfied
annotation pipeline
create from text
create from file
abstract input stream annotation creator
feature annotator
udfeature annotator
build wrapper
attempt
failed sentences
failed
sentence annotator
annotator processor
xml out
edge list
deprel
dep word
dep idx
stanford core nlp demo
stanford core nlp demo chinese
sentence to write
tagged text outputter
current date
add hyphens to date
doc_date_fixed_property
doc_date_mapping_file_property
doc_date_present_property
doc_date_regex_property
date_proper_format
date_no_hyphens_pattern
use fixed date
use mapping file
use present date
use regex
fixed date
doc idto doc date
file doc date pattern
mapping file path
mapping entries
file name and doc date
key and value
found doc date
proper date format
compact date string
yyyy
doc date annotator
get keys to print
default_constituency_tree_printer
default_dependency_tree_printer
default_keys
default_options
pretty
constituency tree printer
dependency tree printer
coreference context size
print singletons
relations beam
keys to print
print fake deps
constituency tree style
dependency tree style
key array
annotation outputter
write core document
convert intermediate graph
wrapped annotation
read pair
copy annotation
source copy
target copy
lock
annotation serializer
intermediate node
intermediate edge
intermediate semantic graph
set newline status
stat tok sent
multi word rules file
tokens list
text preproc
multiple line breaks
line break
one or more space
s tokens
s index
stat tok sent annotator
span sentiment
sen
sentiment annotator
annotation to doc
add sentiment
add triples
add constituent tree info
build dependency tree info
add dependency info
add entities
add relations
add coref graph info
add coref mention
add word info
set single element
to xml
make probabilities element
namespace_uri
stylesheet_name
sentences elem
sent count
word table
parse info
dep info
openie elem
kbp elem
mr elem
ent elem
rel elem
coref info
namespace uri
sentiment elem
predictions elem
pred elem
tree info
constituent tree printer
dependency type
cur ns
source word
target word
dep elem
gov elem
depend elem
found coref
chain elem
mention elem
context start
context end
token element
elem name
subtype
xmloutputter
newline splitter
non splitter
count line numbers
nl splitting
whitespace tokenization
wts1
is one sentence
boundary multi token regex
token patterns to discard prop
token regexes to discard
boundary token regex
boundary followers regex
boundaries to discard
bounds
html elements to discard
nlsb
boundary to discard
newline is sentence break
nl token
section annotations
curr section index
sections
sentence start token
sentence end token
section start
section end
curr section char begin
curr section char end
section quote
final tokens
prev newline token text
newline text
sentence token begin
sentence token end
words to sentences annotator
pos loc
postagger annotator
postagger processor
set up fine grained ner
set up additional rules ner
set up tokens regex rules
set up entity mention building
set up doc date annotator
merge tokens
annotation with nertokenization
transfer nerannotations to annotation
rules only
statistical only
use nerspecific tokenization
ner specific tokenization exceptions
spanish number regex rules
spanish number annotator
apply fine grained
fine grained nerannotator
apply additional rules
additional rules nerannotator
apply tokens regex rules
tokens regex annotator
build entity mentions
entity mentions annotator
doc date annotator
ner language
load paths
combiner properties
sutime props
ner combiner
spanish number regex ner properties
fine grained
ner properties
fine grained prefix
fine grained props
additional rules prefix
additional rules props
tokens regex rules prefix
tokens regex rules props
entity mentions prefix
entity mentions props
after is empty
original annotation
copy tokens
next token index
processed token
last processed token
copy sentence
global token index
ner tokenized annotation
ner keys
ner tokenized tokens
ner tokenized idx
merge count
original idx
orig token
ner tokenized token
ner annotation
fine grained tag
label to prob
ne tag
norm ne tag
ne tag prob map
ner requirements satisfied
nercombiner annotator
token merge count annotation
process line
add sentence data
add mwtdata
read co nllufile
read co nllufile create co nllxlines
read co nllufile create co nlludocuments
convert co nlludocument to annotation
convert co nllusentence to core map
co nllu_index field
co nllu_word field
co nllu_lemma field
co nllu_uposfield
co nllu_xposfield
co nllu_gov field
co nllu_reln field
co nllu_misc field
column count
comment_line
document_line
mwt_line
token_line
class shorthand to full
extra columns
extra column index
token lines
sentence data
mwt data
mwt tokens
mwt miscs
mwt last core labels
sentence data line
mwt data line
mwt fields
mwt text
mwt start
mwt end
conll xlines
final annotation
document idx
sentence token index
extra column idx
misc key values
misc info
misc kv
sentence char begin
processed mwttokens
last mwtchar begin
last mwtchar end
graph edges
reln
dep parse
sentence core map
co nllureader
co nlludocument
co nllusentence
wrap entity mentions
tokens as strings
tregex result trees
tregex results
noun phrase trees
noun phrases
verb phrase trees
verb phrases
noun phrase pattern
verb phrase pattern
pattern cache
compile pattern
tree to span string
core map sentence
core sentence
binarizer annotator
load dependency graph
save dependency graph
save coref chains
count mentions
save coref chain
escape space
unescape space
parse mention type
parse number
parse gender
parse animacy
load coref chains
load token
save token
have explicit antecedent
have ante
bbits
output header
int pair set entry
cluster count
pos len
pos elems
mentions with this head
coref graph
collapsed deps
interm collapsed deps
interm uncollapsed deps
interm cc deps
space_holder
norm ner
custom annotation serializer
wrap annotations
wrap sentences
build document entity mentions list
build document quotes list
annotation document
core map quote
core document
abstract text annotation creator
read undelimited
get and register
to proto
to proto builder
to proto section
create indexed word proto from iw
create indexed word proto from cl
to map string string proto
to map int string proto
to proto quote
to proto mention
from proto no tokens
load sentence mentions
to flattened tree
recover original text
global lock
enforce lossless serialization
delimited
undelimited
keys to register
keys to serialize
label with prob
label prob
coref mention index
entailed sentence
entailed clause
entity mention to coref mention
num entity mentions
entity mention index
coref mention to entity mention
num coref mentions
root set
node builder
mention to index
ent
pol
tree optional
semantic graph
ner label probs
ner label prob
label and prob
label prob double
lossy sentence
entailed sentences
entailed clauses
sentence characters
proto mention
has coref info
character begin
character end
entity mention tokens
em char offset begin
em char offset end
ner label confidences
mentions on annotation
sentence em
calendar
chain proto
id to proto mention
kbp triple
mention int
mention to update
head indexed word index
depending verb index
head word index
list of sections
section core map
quote token index
corresponding proto mention
speaker info mention id
coref mention for entity mention index
entity mention for coref mention index
tree builder
op name
projection fn
root i
fragment tree
kept indices
partial document
return mention
quoted tokens
annotation sentences
sentences list
quote char start
quote char end
quote author
quote core map
missing whitespace
protobuf annotation serializer
lossy serialization exception
speaker tokens
speaker char offsets
speaker entity mention
canonical speaker tokens
canonical speaker char offsets
canonical speaker entity mention
quote char offsets
has canonical speaker
first sentence index
last sentence index
curr sent index
first speaker token index
last speaker token index
speaker token index
speaker char offset begin
speaker char offset end
candidate entity mention
entity mention offsets
first canonical speaker token index
last canonical speaker token index
canonical speaker token index
canonical speaker char offset begin
canonical speaker char offset end
core quote
entity mentions to character map
get qmmapping
get msmapping
default_qmsieves
default_mssieves
default_model_path
family_word_list
animacy_word_list
gender_word_list
coref_path
model_path
characters_file
build character map per annotation
use coref
qm sieve list
ms sieve list
dependency_parser_model
depparse properties
entity mention string
new person
new person list
preprocessed
qm sieves
ms sieves
first speaker token
canonical entity mention tokens
canonical entity mention first token
canonical entity mention last token
quote attribution requirements
quote attribution annotator
mention annotation
mention begin annotation
mention end annotation
mention type annotation
mention sieve annotation
speaker sieve annotation
canonical mention annotation
canonical mention begin annotation
canonical mention end annotation
make newline core label
tokenize newline
sentence split on two newlines
default_seg_loc
seg loc
model props
desired key
model key
newline_regex
newline_pattern
string consumed
saw newline
saw two newlines
piece tokens
arabic segmenter annotator
default_pos_model
default_parser_model
default_dependency_parser_model
default_ner_threeclass_model
default_ner_conll_model
default_ner_muc_model
default_ner_gazette_mapping
default_regexner_rules
default_gender_first_names
default_truecase_model
default_truecase_disambiguation_list
default_dcoref_animate
default_dcoref_demonym
default_dcoref_inanimate
default_dcoref_states
default_dcoref_countries
default_dcoref_states_and_provinces
default_dcoref_gender_number
default_dcoref_singleton_model
default_dcoref_dict1
default_dcoref_dict2
default_dcoref_dict3
default_dcoref_dict4
default_dcoref_ne_signatures
default_nfl_entity_model
default_nfl_relation_model
default_nfl_gazetteer
default_sup_relation_ex_relation_model
default_naturalli_affinities
default_openie_clause_searcher
default_kbp_classifier
default_kbp_regexner_cased
default_kbp_regexner_caseless
default_kbp_semgrex_dir
default_kbp_tokensregex_dir
default_kbp_tokensregex_ner_settings
default_wikidict_tsv
default paths
pos tagger
tokens regex ner
true case
dcoref
for client
server annotator implementations
singleton annotator
serialized annotation creator
create pattern matcher
annotate matched
check pos tags
is location or gpe
check orig ner tags
get type description
read entries
get header index map
has no overwritable type
process list mapping files
process per file options
at least one valid pos pattern
pattern_field
overwrite_field
priority_field
weight_field
group_field
predefined header fields
default header
ignore case list
common words
pattern to entry
annotation fields
my labels
valid pos pattern
valid pos pattern list
header list
entry to mapping file number
no default overwrite labels
match_all_tokens
match_at_least_one_token
match_one_token_phrase_only
pos match type
default_pos_match_type
supported_properties
mapping
valid pos regex
comma_delimiters_pattern
semicolon_delimiters_pattern
equals_delimiters_pattern
background symbols
mapping files
mappings
common words file
header prop
read header from file
annotation fieldnames
header fields
mapping line
field classes
field class
no default overwrite labels prop
ignore case entry
pattern flags
pos tag pattern
overwrite original ner
special case pass
prev ner end index
next ner start index
start ner
end ner
tokens regex
overwritable types
seen regexes
mapping file index
mapping filename
orig entries size
is tokens regex
header index map
i pattern
i overwrite
i priority
i weight
i group
annotation cols
i last annotation field
expect
temp ots
new type
old entry
old type desc
new type desc
num mapping files
ignore case set
valid pos pattern set
header set
all options
num options
option and value
header items
header line
tokens regex nerannotator
entry
get annotated chunks
is end of chunk
is start of chunk
is chunk
type matches
get tag type
get default pos tag
set default pos tag
get default neg tag
set default neg tag
get neg label
set neg label
is ignore provided tag
set ignore provided tag
ignore provided tag
neg label
default pos tag
default neg tag
total tokens offset
label key
check tokens compatible
token chunk key
token label key
prev tag type
cur tag type
prev type
cur type
chunk end
chunk start
prev tag e
cur tag e
label pattern
labeled chunk identifier
label tag type
convert flags to array
finish sentence
tree map
max parse time
save binary trees
keep punct
no squash
default_max_height
max sent
parser loc
tree map class
build graphs property
punct filter
uses binary
parser flags
mapped trees
mapped tree
scored objects
parser annotator
get default aggregators
aggregate
first_non_nil
last_non_nil
concat self
added
concat_tokens
concat_coremap
concat
concat_text
count
sum
ignore set
most_freq
aggregator_lookup
default_aggregators
default_numeric_aggregators
default_numeric_tokens_aggregators
default aggr
default numeric aggr
default numeric tokens aggr
core map attribute aggregator
get model name
relation model
entity extractor
relation extractor
output sentences
orig sentences
out sent
orig sent
rls
relation extractor annotator
annotate tokens
collapse_property
quantifiable entity normalizing annotator
cdc tokenizer
clean xml
word to sentences
multi word token
tokensregex
column data
quoteattribution
udfeats
parser type
max len str
mention properties
all props for coref
annotator implementations
add lemma
phrasal verb
particles
morphology
particle
morpha annotator
parse classes
copy value
annotator endpoint
annotator requires
annotator provides
class list
ann_
conn
output stream
input stream
generic web service annotator
get node index
output_representation
vertex list
properties writer
epeoutputter
find best coreferent entity mention
length of optional entity mention
best coreferent entity mention
matching coref mention index
matching coref mention
matching coref chain
coref mentions in textual order
candidate coreferent entity mention index
candidate coreferent entity mention
fixed
coref annotator
get default options
initialize name map
initialize class map
get tokenizer type
compute extra options
init factory
get tokenizer
set token begin token end
adjust final token
unspecified
whitespace
abbreviation
default options
name to tokenizer map
class to tokenizer map
tok class
whitespace
eol_property
keep_nl_option
use segmenter
segmenter annotator
post processors
extra options
keep newline
nlsb string
post processor class
processors
eol is significant
final token
final token after
tokenizer annotator
write stream header
object output
object input
generic annotation serializer
appending object output stream
load mixed case map
true caser
mixed case map
overwrite text
default_model_bias
default_overwrite_text
default_verbose
model loc
mixed case file name
biases
cname
true case text
map file
els
true case annotator
split characters
advance pos
run segmentation
make xml token
default_model_name
default_ser_dictionary
default_sighan_corpora_dict
separator pattern
normalize space
ser dictionary
xml pattern
char tokens
xml start offset
xml end offset
first non newline offset
last non newline offset
cp char count
char string
is newline queue
next offset
next code point
skip character
is xmlcharacter
prev is newline
curr is newline
next is newline
is leading or trailing newline
is single newline in middle
sent chars
xml buffer
xml begin
xml char annotation
fl1
do normalization
char offset begin
char offset end
chinese segmenter annotator
get urlparams
mk stanford core nlp
respond error
respond bad input
respond unauthorized
set http exchange response headers
parse subnet
net match
on block list
handle
maybe alter stanford timeout
get timeout
get content type
set tregex offsets
send and get response
add sslcontext
configure
liveness server
get server
with auth
server id
server port
status port
uri context
ssl
password
preloaded annotators
server properties path
max char length
block list
server specific properties
shutdown key
server ioprops
server executor
last pipeline
corenlp executor
block list subnets
pipeline props from cl
default property keys
shutdown key file name
tmp dir
subnet
key value
url_encoded
http exchange
charset pair
cache key
url params
io key
url properties
language properties file
language specific properties
addr
ip int
ip int1
mask
exchange
server ready
do exit
file or classpath
uhe
authenticator
homepage
completed annotation future
completed annotation
future
filter str
doc writer
sent writer
match writer
group i
group writer
unique str
unique
dependencies type
graph result builder
core
named node writer
named node sub writer
kmf
ssl context
engine
req
credentials
context root
annotators to load
stanford core nlpserver
finished request
ping handler
ready handler
live handler
shutdown handler
file handler
core nlphandler
tokens regex handler
semgrex handler
tregex handler
or neg
or null
null_placeholder
dep tree
co nlloutputter
conll uprint
conll uwriter
co nlluoutputter
check offsets
fix token offsets
copy unset annotations
fix chunk token boundaries
get merged chunk
get chunk offsets using char offsets
merge chunks
get first non ws char
get first non ws char offset
get trimmed text
fix chunk sentence boundaries
annotate chunk
get token text
annotate chunk text
has character offsets
annotate chunk tokens
get annotated chunk
get annotated chunk using char offsets
get annotated chunks using sorted char offsets
annotate chunks
create core map
append core map
split core map
sent begin char
sent end char
sent begin token
sent end token
doc text span
doc token span
sent token str
doc token str
cur doc token
sent token first
sent token last
sent token end
dest
chunk char offsets
offset begin
chunk list
chunk index start
chunk index end
first chunk
last chunk
first char offset
last char offset
first token index
last token index
chunk text
new chunk
n chunks to remove
relative
offsets are not sorted
extended fix sentence
more extended fix sentence
start sent index
first non ws char offset
entity at sent end
sent char begin
offset end in sent text
sent trimmed text
next sent trimmed text
token start index
token end index
total token offset
chunk tokens
token text key
prev end index
include delimiter
orig annotation
anno text
anno begin char offset
chunk begin char offset
chunk end char offset
anno token begin
annotated text from char offsets
char offset start
char offset is relative
allow partial tokens
anno tokens
anno char begin
begin rel char offset
end rel char offset
new annotation key
aggr key
value of method
cm char start
scm
include matched
chunk annotation utils
fill in parse annotations
set missing tags
build graphs
extras
parser annotator utils
get language properties file
get language properties
get language from string
is stanford core nlpsupported lang
is segmenter language
arabic
chinese
english
french
german
hungarian
italian
spanish
arabic_properties
chinese_properties
english_properties
french_properties
german_properties
hungarian_properties
italian_properties
spanish_properties
language to properties file
language info
to case insensitive pattern
set ssplit discard tokens matcher
set single sentence tag matcher
set doc id tag matcher
set doc type tag matcher
set section tag matcher
set quote tag matcher
set discourse tags
set doc annotation patterns
set token annotation patterns
set section annotation patterns
add annotation patterns
tokens to string
annotate with tag
xml tag matcher
default_xml_tags
sentence ending tag matcher
default_sentence_enders
single sentence tag matcher
default_single_sentence_tags
date tag matcher
default_date_tags
doc id tag matcher
default_docid_tags
doc type tag matcher
default_doctype_tags
utterance turn tag matcher
default_utterance_turn_tags
speaker tag matcher
default_speaker_tags
doc annotation patterns
default_doc_annotations_patterns
token annotation patterns
default_token_annotations_patterns
section tag matcher
default_section_tags
quote tag matcher
default_quote_tags
quote author attribute names
default_quote_author_attributes
ssplit discard tokens matcher
section annotation patterns
default_section_annotations_patterns
allow flawed xml
default_allow_flaws
xml elements to process
sentence ending tags
single sentence tags
allow flawed string
allow flawed
date tags
doc id tags
doc type tags
utterance turn tags
speaker tags
doc annotations
section tags
quote tags
ssplit discard tokens
quote author attributes
xml tags to remove
conf
tag_attr_pattern
attr only
anno pattern strings
anno pattern string
anno key string
tag pattern
attr pattern
annotation text
first token
last token
saved tokens
to annotate
saved token annotations
found annotations
enclosing tags
current tag set
match depth
removed text
utterance index
in utterance
in speaker tag
current speaker
doc date tokens
doc type tokens
doc id tokens
section start tag
section start tag char begin
section start token
section start tag token
saved tokens for section
section quotes
quote start char offset
mark single sentence
current removal
quote end char offset
quote author attribute
curr section core map
found author
author mention start
author mention end
mention tag
mesg
clean xml annotator
text annotation creator
find end of answer annotation
find start of nerannotation
find end of nerannotation
overwrite my labels
nertype
answer end
nerstart
nerend
regex nerannotator
output visualise
output pretty
output by writer
output xml
output json
output co nll
corenlp transformer
default format
maximum_query_length
xsl path
stylesheet
visualiser div px width
name by abbrv
xml output
escaped xml
brat location
num spaces
core nlpservlet
register
cached annotators
new annotator
new sig
old annotator
singleton
annotator pool
cached annotator
tokens for characters
overlaps with mention
annotate pronominal mentions
determine entity mention confidences
add acronyms
chunk identifier
do acronyms
match token text
entity mentions language
ner core annotation class
ner normalized core annotation class
mentions core annotation class
is_tokens_compatible
timex1
timex2
tid1
tid2
needle
haystack
tokens_
pronoun gender
pronoun token
tag probs
labels with probs
entity label prob vals
label probs for token
entity mention text
all entity mentions
entity mention token
entity mention label prob vals
all mentions so far
organizations
org
entity mentions annotator
test1
test2
test3
para
run paragraph annotator
paragraph_break
paragraph split
full text
paragraph breaks
next paragraph start index
paragraph annotator
write to file
contains word
get word vectors
get embedding size
set word vectors
dim of words
unk str
embedding
load text matrix
load text matrices
convert text matrix
elementwise apply re lu
elementwise apply log
elementwise apply tanh
elementwise apply tanh derivative
concatenate with bias
concatenate
random gaussian
one hot
is zero
matrices
vector1
vector2
matrix iterator
neural utils
transform2dmap
from matrix
from tensor
to matrix
to tensor
transform map
write sentiment
read sentiment
write parser
read parser
read embedding
write coref
read coref
write fast coref
read fast coref
old
new
sentiment
dvparser
coref
embedding
fastcoref
map2d sm
map2d st
binary tensor
dvmodel
new vectors
vectors doubles
static embedding
has static
tuned embedding
model type
convert models
get num elements
element mult
element sum
set slice
get slice
bilinear products
iterator simple matrix
advance iterator
in t
tensors
current iterator
simple tensor
simple matrix iterator wrapper
simplify tree
count tree helper
get priority queue
score comparator
ngram count
maximum length
class to ngrams
inner map
tree size
score1
score2
top ngram record
get node vector
get predictions
get predictions as string list
get predicted class prob
get gold class
set gold class
get prediction error
set prediction error
list of predictions
rnncore annotations
node vector
predictions
predicted class
gold class
prediction error
read word2vec
same float
to float
from float
int8
int16
int32
gzip
data out
max key length
vector length
key int type
data in
strlen
other map
other value
abs diff
abs a
abs b
hbits
mant
fval
fbits
vector map
set children
percolate heads
head word node
set head word node
safe cast
highest node with same head
to pretty string
to one line string
zero_tgn_children
mlf
t kids
child trees list
hwn
tgnf
indent level
tgn
tree graph node
tree factory holder
makes copula head
rule changes
should skip
find previous head
post operation fix
determine non trivial head
is existential
is whq
is verbal auxiliary
has passive progressive auxiliary
vp contains participle
has verbal auxiliary
verb tags
unambiguous aux tags
verbal auxiliaries
copulars
passive auxiliaries
verbal tags
unambiguous auxiliary tags
no copula head
orig was interjection
head idx
daughter trees
seen separator
new head idx
prev lab
next head
head of copula tregex
head of conjp tregex
no verb over temp tregex
remove_tmp_and_adv
mother cat
tmp filtered children
pti
found another np
preterminal
verbal set
allow just tag match
lc word
found passive vp
found passive aux
found participle in vp
kidkid label
catcat
allow tag only match
semantic head finder
map tree
default_tsurgeon_file
operations
universal posmapper
clean up label
includes empty npsubj
normalize whole tree
add tmp9
new tree reader
temporal_none
temporal_acl03pcfg
temporal_any_tmp_percolated
temporal_all_terminals
temporal_all_np
temporal_all_np_and_pp
temporal_np_and_pp_with_np_head
temporal_all_np_even_under_pp
temporal_all_np_pp_advp
temporal_9
only tag annotate nstar
nptmp pattern
pptmp pattern
advptmp pattern
tmp pattern
npsbj pattern
npadv pattern
gapping pattern
temporal annotation
do sgapped stuff
do gapping stuff
do adverbial np
nptemp
pptemp
advptemp
anytemp
npadv
gapping
found null subj
transformer1
node filter
transformer2
old t
kidlets
kidlet
nptmp retaining tree normalizer
nptmp retaining tree reader factory
nptmp adv retaining tree reader factory
index nodes
index leaves
add node to index map
get node by index
throw dep format exception
from string reps
attach stranded nodes
analyze node
get extra deps
get deps
extra tree dep filter
post process dependencies
get extras
get tree deps
get grammatical relation
get grammatical relation common ancestor
remove grammatical relation ancestors
typed dependencies
all typed dependencies
typed dependencies collapsed
typed dependencies collapsed tree
typed dependencies ccprocessed
typed dependencies enhanced
typed dependencies enhanced plus plus
collapse dependencies
add enhancements
collapse dependencies tree
correct dependencies
is connected
get roots
read co nllxgrammatical structure collection
build co nllxgrammatical structure
print_debugging
ref_only_uncollapsed
ref_only_collapsed
subj_only
ref_uncollapsed_and_subj
ref_collapsed_and_subj
maximal
do ref
do subj
collapse ref
punc filter
tag filter
relations lock
tree graph
punc typed dep filter
basic graph
complete graph
tg word nodes
tg posnodes
node words
pos iter
pos string
child arr
tdeps
first bracket
arg sep
parent arg
child arg
parent dash
child dash
parent idx
child idx
grel
tdep
projective dependencies
attach
t high
egr
u high
parents
dependency root
root dep
root typed dep
new dep
npf
gov h
dep h
reln2
top tag
top word
bot cat
bot tag
bot word
descendant found
include extras
ccprocess
typed dep
govs
co nllx_word field
co nllx_posfield
co nllx_gov field
co nllx_reln field
co nllx_field count
short name to grel
gs list
token fields
inline
tg words
pos node
parent id str
grel string
parent id
grammatical structure
no punct filter
no punct typed dependency filter
to sets
remove heads assigned to punc
lang independent punc check
new instance string equality
convert string equality
normalize numbers
read deps co nllx
read deps
to string attachment score
to string fscore
gold deps unlabeled
ignore punc
dep collection
dep set
unlabeled dep set
sets
dep sets
is not word
co nllx
converted deps
gss
breader
first paren
comma space
dep name
gov name
child name
prepc
gov word
child word
parser cnt
gold cnt
parser unlabeled cnt
gold unlabeled cnt
correct attachment
correct unlabeled attachment
label cnt
label correct
unlabeled error counts
labeled error counts
errl
child correct with label
child correct with out label
gold dep
s child
prefix labeled
prefix unlabeled
labeled error
s gov
unlabeled error
sbuild
ulp
ulr
ulf
conllx
json output
system filename
gold scorer
system deps
strkey
dependency scoring
typed dependency string equality
score
graph less grammatical structure factory
graph less grammatical structure
fake short name to grel
new constituent
labeled scored constituent factory
tmp t
treebank2
my transformer2
my transformer3
tf1
tf2
tta
tt3
tf3
tx1
tx2
tx3
tree copy
category label
transforming treebank
transforming treebank iterator
my tree transformer
my tree transformer2
my tree transformer3
set start
constituent factory
simple constituent
simple constituent label factory
constituent factory holder
simple constituent factory
normalize terminal
middle
empty filter
a over afilter
bob chris tree normalizer
empty filter
aover afilter
num children
is unary rewrite
is pre terminal
is pre pre terminal
is phrasal
object index of
get children as list
last child
upper most unary
set spans
constituents nodes
to string builder
update brackets
make indent string
print local tree
indented list print
indented xmlprint
display children
penn string
head terminal
head pre terminal
percolate head annotations
make dependency label
map dependencies
yield words
yield has word
tagged yield
labeled yield
tagged labeled yield
pre terminal yield
get leaves
sub trees
sub tree list
tree skeleton copy
tree skeleton constituent copy
splice out
splice out helper
skip root
parent helper
ancestor
post order node list
post order recurse
pre order node list
pre order recurse
dominates
domination path
domination path helper
path node to node
join node
c commands
siblings
insert dtr
left char edge
right char edge
node number
node number helper
get node number
get node number helper
percolate head indices
index spans
empty_tree_array
my kids
their kids
hc2
constituents set
char level
initial print string builder size
lrb_pattern
rrb_pattern
label formatter
indent incr
print scores
new indent
tr children
parent label null
first sibling
left sib is pre term
current tree
left sibling pre terminal
suppress indent
terminal string
parent is null
cur depth
copy label
copy index
copy pos tag
word form
is concrete
seen head
dep label
hwt
dwt
root name
term idx
new leaf
pruned child
t1dom path
t2dom path
it1
it2
sibs
sib
over write
word annotation
child word annotation
afl
tree
tree iterator
read grammar
produce trees
produce tree
terminals
nonterminals
tsurgeon
non terminals
terminals
tsurgeons
new section
operation
productions
sublist
terminal
non terminal
generate trees
property to boolean
print tree
print tree internal
get sorted deps
get collocation processed tree
print header
print footer
mark head nodes
head mark
head mark children
to readable string
to xmlstring
root label only format
output tree formats
lexicalize
remove empty
ptb2text
trans chinese
collapsed dependencies
non collapsed dependencies
non collapsed dependencies separated
ccpropagated dependencies
tree dependencies
include tags
stemmer
dependency filter
dependency word filter
wnc
format string
typed dependency hf
ok outputs
form obj
include punctuation dependencies
in xml
sent unstemmed
output pstree
translation
psw
indexed tree
deps set
sorted deps
depi
govi
p head
p dep rel
dep rel
found root
new head
tlp name
hf name
extra sep
label format
extra deps
gov tag
gov idx
dep tag
gov copy
copy gov
dep copy
copy dep
gov tag attribute
dep tag attribute
extra attr
tree print
new grammatical structure
english grammatical structure factory
are equal
span2
word cat equality checker
string labeled scored tree reader factory
get governor index
get dependent index
dependency factory
new dependency
regent
regent index
dependent index
gov idx str
dep idx str
unnamed concrete dependency
dependency factory holder
unnamed concrete dependency factory
clean up root
strip tag
strip empty node
adv pattern
dependency tree transformer
length tree filter
read srlfile
last index of
list iterator
sub list
print_filenames
parse trees
srl file
srl map
cvm
srls
srl
verb index
bits1
locs
arg type
role map
tree trans
mtb
memory treebank
right head finder
filtering treebank
filtering treebank iterator
input
root_only
ignore_labels
remap_labels
assert_binary
output subtrees
get mangled tree
get collocations list
print collocation strings
tree as stemmed collocation
tree as non stemmed collocation
merge leaves into collocated string
get stemmed word tags from tree
get non stemmed word tags from tree
word net contains
q tree
collocation collector
wn connect
matching coll
all children
mutated string
str to append
this constituent
new node string
first child index
new collocation child
new collocation leaf
left most leaf
left sisters buffer
child constituents
curr window length
this subtree length
test string non stemmed
sister node
child constituents clone
a sent
stemmed word tags
word tags
parent node
indices of constituent children
collocation string
collocation finder
collocation
tree normalizer
new tree node
tree graph node factory
file regex
current file
find treebank tree
thread unsafe
synchronized tree transformer
gov to dep map
get gov max chains
get typed dependency chains
dependency index comparator
tag reject filter
word reject filter
wrf
dep1lab
dep2lab
dep1idx
dep2idx
dep lists
child node
child dep lists
child dep list
tdc
max chains
max chain
tag type
cat type
good word tag type
word cat constituent
equals ignore name
make start label
extract from tree
extract normalized from tree
norm poslabel
norm pos
must process root
head daughter
start label
daughter
head of daughter
rel parent
rel head
rel modifier
other dep
collins dependency
mod collins head finder
is from string
get related nodes
is applicable
is ancestor
get long name
get short name
get specific
strings to relations
governor
dependent
kill
read values lock
specific
underscore position
long name
source pattern
target patterns
tregex compiler
specific string
s to r
node list
this n
o n
grammatical relation
process tree
word stemmer
transform trees
continuing
be_have_get
modal_word
modal
modal_do_to
bare_vp_verb
say_verb
ops
tpc
tsp
macro str
edit str
english ptbtreebank corrector
bad labels pattern
weird root pattern
root matcher
onto notes udupdater
root patterns
null patterns
useless tree filter
delim
param name
param path
param output path
param split
param encode
param mapping
param distrib
param type
param flat
param dt
param tag delim
param file ext
param lex mapper
param lex map options
param no dash tags
param add root
param un escape
param pos mapper
param pos map options
param max len
param morph
param transform
param cctagset
match name
match split
match distrib
match flat
match dt
match tag delim
match file ext
match lex mapper
match no dash tags
match add root
match un escape
match lex map options
match pos mapper
match pos map options
match max len
match morph
match transform
match encode
match encode args
match cctagset
boolean args
match path
match output path
match mapping
set delim
skip line
dataset list
patterns map
config file
params for dataset
param template
param token
actual param
param value
num datasets
data set num
config parser
already seen
duplicate tree string filter
get dataset class
cmd line format
ds params
ds type
make_distrib
distrib name
distrib
name of dataset
should distribute
lacks required options
stop time
elapsed time
treebank preprocessor
can change encoding
setup
default mapper
add files
make
dist files
last created distribution
created dir
relative path
tar file name
tar file
distribution package
load mapper
load tree vistor
build split map
get filenames
output file list
pos mapper
pos map options
lex mapper
lex map options
paths to data
paths to mappings
add determiner
remove dash tags
remove escape tokens
morph delim
custom tree visitor
out file name
flat file name
make flat file
file name normalizer
configured options
required options
tree file extension
path matcher
map matcher
in this filename
file set
filter set
abstract dataset
buckwalter
utf8
count anywhere
count final
count node
total anywhere
total final
visitor
punct counting tree visitor
daughter trees list
labeled scored tree node
named dependency
named dependency factory
labeled scored tree factory
tree filters
has matching child
left edge unsafe
right edge unsafe
leaf labels
tagged leaf labels
set leaf tags if unset
set leaf labels
maximal projection
apply to projections
get terminal
get pre terminal
local tree as cat list
object equality index of
to structure debug string
to flat tree
tree to latex
tree to latex helper
tree to latex even
tree to latex even helper
tex tree
escape
normalize tree
get leaf
path from root
replace node
output tree labels
default tree factory
t cl
tf cl
l cl
lf cl
other classes
tag labels
phrase labels
st cl
stf cl
sl cl
slf cl
daughters
hierarchy
next n
t depth
common ancestor
quit
from path
to path
last node
total path
node1
t1path
t2path
ptr
trees
string value
labeled constituent
labeled constituent label factory
labeled constituent factory
labeled scored constituent
labeled scored constituent label factory
print dependencies
dependencies to co nllxstring
dependencies to string
to string index
parse class construct args
load alternate dependency reader
load alternate dependency printer
get original tree
prime gs
get converter options
convert trees
default_parser_file
convert to upos
indexed deps
c pos
index to pos
gs leaves
upos labels
upos tree
name plus args
alt dep reader name
alt dep reader class
dep reader args
alt dep reader
alt dep printer name
alt dep printer class
dep print args
dep printer
parser options
cnfe
orig trees
wrapped trees
tb iterator
tl ppclass name
stanford dependencies
default lang
gs bank
tree file name
sent file name
conll xfile name
alt dep reader filename
t lpp
parser opts
ccprocessed
collapsed tree
non collapsed
check connected
portray
alt dep printer
sgf
all connected
bung roots
gsb
gse
gscc
sem graph
m dag
is dag
sgu
m render
i reader
line reader
grammatical structure conversion utils
tree bank grammatical structure wrapper
gs iterator
lazy load trees by parsing
get vectors
descending_comparator
deep tree
rearrange now that
change sbar to pp
combine conjp
move rb
sqflatten
remove xover x
ucptransform
cctransform
get head tag
transform cc
not np
find ccparent
mwetransform
prep cctransform
gapping transform
dates
perform mwetransformation
rearrange now that tregex
rearrange now that tsurgeon
change sbar to pptregex
change sbar to pptsurgeon
find flat conjp tregex
add conjp tsurgeon
move rbtregex
move rbtsurgeon
flatten sqtregex
flatten sqtsurgeon
remove xover xtregex
remove xover xtsurgeon
ucp rename tregex
ucp rename tsurgeon
not done
cc index
cc siblings
cc positions
before sibling
comma
right tree
comma left
comma right
preconj
index begin
conj t
next cc
mwe_patterns
mwe_operation
according_to_pattern
according_to_operation
but_also_pattern
but_also_operation
at_rbs_pattern
at_rbs_operation
at_all_pattern
at_all_operation
flat_prep_cc_pattern
flat_prep_cc_operation
gapping_pattern
gapping_operation
coordination transformer
tree tokenizer factory
add tree normalizer
tns
ordered combination tree normalizer
simple tree
values lock
thread safe add relation
get conjs
get conj
get preps
get preps c
get prep
get prep c
predicate
aux_modifier
aux_passive_modifier
copula
conjunct
coordination
punctuation
argument
subject
nominal_subject
nominal_passive_subject
clausal_subject
clausal_passive_subject
complement
object
direct_object
indirect_object
prepositional_object
prepositional_complement
clausal_complement
xclausal_complement
relative
referent
expletive
adjectival_complement
modifier
adv_clause_modifier
relative_clause_modifier
marker
adjectival_modifier
numeric_modifier
number_modifier
quantifier_modifier
noun_compound_modifier
appositional_modifier
discourse_element
verbal_modifier
adverbial_modifier
negation_modifier
np_adverbial_modifier
temporal_modifier
multi_word_expression
determiner
predeterminer
preconjunct
possession_modifier
possessive_modifier
prepositional_modifier
phrasal_verb_particle
parataxis
goes_with
semantic_dependent
agent
synchronized values
unmodifiable synchronized values
conjs
conjunction string
preps
preps c
preposition string
english grammatical relations
weighted index
split_names
split_weights
seed
total weight
split weights
split training set
add macro
default_basic_cat_function
default_head_finder
basic cat function
macros
default compiler
macro
tme
tregex pattern compiler
local string
reset child iter
reset child
go to next tree node match
commit variable groups
decommit variable groups
remove named nodes
match child
pattern
strings
exact
anything
neg desc
description mode
desc pattern
string filter
max_string_matcher_size
string desc
linked name
is link
variable groups
single_word_pattern
multi_word_pattern
case_insensitive_pattern
prefix_pattern
use basic cat
new relation
old pattern
nodes to parents
names to nodes
variable strings
tree node match candidate iterator
my node
child matcher
next tree node match candidate
matched once
committed variables
other tree
my value
var group
this variable
this var string
description pattern
description matcher
open_bracket
exists
delete
prune
relabel
excise
insert
move
replace
create_subtree
adjoin
adjoin_to_head
adjoin_to_foot
coindex
close_bracket
selection
general_relabel
location_relation
quotex
hash_integer
tree_node_terminal_label
tree_node_nonterminal_label
close_paren
operation
conditional
new node names
coindexer
location matcher
node to move
old parent
move node
matcher
prune helper
pruned whole tree
node to prune
prune node
needs copy
node to insert
insert node
jjtroot
jjtoperation
jjtlocation
jjtnodeselectionlist
jjtnodeselection
jjtnodename
jjttreelist
jjttreeroot
jjttreenode
jjttreedtrs
jjt node name
set coindexes
coindexes
tsurgeon pattern root
hold tree node
fetch node
set last index
generate index
coindexation pattern
this index
coindexation generator
remove escape slashes
regex pattern string
regex pattern
node pattern string
variable pattern string
variable pattern
one general replacement
one general replacement pattern
subst pattern
fixed
replacement string
replacement pieces
general matcher
last position
unescaped label
last is backslash
node to relabel
relabel node
relabel matcher
copy helper
find foot node
find foot node helper
initialize names nodes maps
unescape
original tree string
foot
nodes to names
must have foot
new names to nodes
new foot
foot node character
foot node label pattern
escaped foot node character
foot node
new foot node
found dtr
this found dtr
name pattern
auxiliary tree
root
operation
location
node selection list
node selection
node name
tree list
tree root
tree node
tree dtrs
jj_3r_tree dtrs_271_3_15
jj_3r_node name_224_3_8
jj_3r_tree dtrs_269_3_14
jj_3r_tree dtrs_269_3_13
jj_3r_node selection_215_3_4
jj_3r_tree node_260_3_12
jj_3r_tree node_258_3_11
jj_3r_tree node_256_2_9
jj_3r_tree node_256_2_10
jj_3r_tree root_246_3_7
jj_3r_location_193_2_6
jj_3r_tree list_234_2_5
jjtree
jjtn000
jjtc000
jjte000
child1
child2
node selections
hash_int
requires foot
dtrs
tsurgeon parser
coindexation introduction string
coindex nodes
find foot
aux tree
start child
end child
inner children
inside span
create subtree node
tsurgeon runtime exception
empty_tsurgeon_pattern_array
result sb
tsurgeon pattern
adjoin to head node
invert
if exists node
node to delete
delete node
old node
new nodes
convert auxiliary to hold
replace node
jj move string literal dfa0_2
jj move string literal dfa1_2
jj move string literal dfa2_2
jj move string literal dfa3_2
jj move string literal dfa4_2
jj move string literal dfa5_2
jj move string literal dfa6_2
jj move string literal dfa7_2
jj move string literal dfa8_2
jj move string literal dfa9_2
jj move string literal dfa10_2
jj move string literal dfa11_2
jj move string literal dfa12_2
jj stop string literal dfa_1
jj start nfa_1
jj move string literal dfa0_1
jj start nfa with states_1
jj move nfa_1
tsurgeon parser token manager
jjt open
jjt close
jjt set parent
jjt get parent
jjt add child
jjt get child
jjt get num children
adjunction tree
adjoin node
tsurgeon matcher
daughter pattern
relative node
tree location
location matcher
bottom
top node
bottom node
excise node
parent of foot
adjoin to foot node
node created
push node
pop node
peek node
node arity
clear node scope
open node scope
close node scope
marks
node_created
condition
jjttsurgeon parser state
tsurgeon parse exception
display tree
get operation from reader
get tregex pattern from reader
get tsurgeon operations from reader
remove comments
get tsurgeon text from reader
get operations from file
get operations from reader
process pattern on trees
process pattern
process patterns on tree
parse operation
collect operations
empty line pattern
comment introducing character
comment pattern
escaped comment character pattern
head finder class name
head finder option
head finder args
head finder arg option
encoding option
tree print formats
single line option
verbose option
matched option
pattern operation option
tree file option
trf option
macro option
macro filename
trf class
pattern string
collected pattern
match string
this line
tsm
matched on tree
operation string
tsurgeon
relation
multi_relation
rel_w_str_arg
number
blank
varname
tregex parser token manager
read macros
add all macros
trimmed
macros
is conj
curr child
consider all
coordination pattern
coordination matcher
matches at
find at
find next matching node
get node names
fill nodes to parents
get variable string
find iterator
find current
last matching node
tregex matcher
tregex parse exception
get menu
set shortcut keys
set mac shortcut keys
set windows shortcut keys
init about box
set save enabled
set save history enabled
set tsurgeon enabled
set mac properties
is mac osx
set up top panels
mac osxregistration
create file chooser
load preferences
set arabic font
do load files
property change
do file filters
start file loading thread
get filters
get new filter
do save file
do save sentences file
do save history
load tsurgeon script
do preferences
do tdiff
is tdiff enabled
do clear file list
do quit
matches changed
about
preferences
load files
save matches
save sentences
save history
load tsurgeon
t diff
search menu item
prev match
next match
prev tree match
next tree match
clear file list
chooser
preference dialog
about box
transformer
mbar
edit
tools
enabled
file panel
input panel
matches panel
input and matches pane
full top panel
initial files
transformer class
display matches panel
input and matches panel
vertical split
screen size
beg x
beg y
display matches size
osx adapter
def args
register method
prefs enable method
chooser file
font size
trf name
approve text
selected files
have directory
focus owner
manager
c files
file filter panel
text panel
default filter
file filter dialog
arg0
filters
filter type
filter value
filter type options
filter types
filter input
none
has extension
has prefix
is in range
tregex pattern string
tsurgeon operations string
max_tdiff_treebanks
active treebanks
tregex gui
transfer action listener
render rows
does overlap
get preferred size
get matched parts
set matched parts
get matched part coordinates
get font size
set font size
get default color
set default color
get matched color
set matched color
get font name
set font name
set diff constituents
default color
matched color
tdiff color
preferred size
matched parts
matched part coordinates
default color2
row origin
row idx
row height
found overlap
leaf ctr
yield height
yield offsets
paint color
cur color
coord
layer buffer
diff constituents
scrollable tree jpanel
set tree reader factory
clear all
get active treebanks
set active treebanks from parent
get tree cell renderer component
tree model
n active treebanks
can activate
scroller
old trf
has focus
file panel
file tree cell renderer
handle about
handle preferences
register mac osxapplication
enable prefs
adapter
app
main app
in app
osxadapter
get font
get tree color
set tree color
get highlight color
set highlight color
get history size
set history size
get max matches
set max matches
get enable tsurgeon
set enable tsurgeon
get match portion only
set match portion only
set encoding
lookup head finder
get tree reader factory
lookup tree reader factory
prefs
pref_font
pref_font_size
pref_tree_color
pref_matched_color
pref_highlight_color
pref_history_size
pref_max_matches
pref_enable_tsurgeon
pref_match_portion_only
pref_head_finder
pref_tree_reader_factory
pref_encoding
default_font
default_font_size
default_tree_color
default_matched_color
default_highlight_color
default_history_size
default_max_matches
default_enable_tsurgeon
default_match_portion_only
default_tree_reader_factory
tree color
highlight color
history size
max matches
enable tsurgeon
match portion only
headfinder name
headfinder
preferences
get display
is active
set active
add listener
send to listeners
get filename
listeners
file tree node
mouse pressed
add highlight
get char offset
remove all matches
get treebank as list
set matches
get selected match
get matches
get matched sentences
select previous match
select next match
get list cell renderer component
export string
create transferable
get source actions
is show only matched portion
set show only matched portion
value changed
focus on list
show only matched portion
last selected
first mouse event
drag ndrop
selected value
mouse event1
mouse event2
highlight successful
first xpos
last xpos
first offset
last offset
cur visible
x pos
s array
ref treebank
ref file name
filtered matched parts
tree t2
in t1not t2
selected tree
is selected
cell has focus
highlights
highlight
cur font
new font
cur selected
matches panel
match cell renderer
tree transfer handler
mark diff
t1labels
tree1path
tree2path
t r1
t r2
t1diff
tdiff
set filename
get sentence id
get diff constituents
set diff decorated tree
get diff decorated tree
diff set
marked tree
less constituents
decorated tree
tree from file
make found stats box
make tsurgeon buttons
make tsurgeon script area
make tregex pattern area
make tregex button box
make browse button box
enable tsurgeon helper
get history list
get history string
add to history list
update found stats
update browse stats
use progress bar
use progress bar helper
state changed
is cell editable
show history
do recent
run browse
run search
set tregex state
set tsurgeon state
run script
return to valid state
set script and pattern
add recent tregex pattern
set num recent patterns
get match tree visitor
do error
update progress bar
column names array
num unique matches
display help
display tsurgeon help
found stats
recent tregex patterns
recent tregex patterns model
num recent patterns
tsurgeon script
history list
history frame
script label
tsurgeon enabled
tsurgeon help
cancel tsurgeon
search thread
history button
browse button
help frame
tsurgeon help frame
tregex input
button box
browse button box
tsurgeon box
tsurgeon button box
found stats box
big empty label
label box
script scroller
recent label
pattern label
pattern scroller
empty label
button constraints
size label
font slider
enable
num trees matched
num matches
tree matches
total matches
dad
column names
table model
stat table
dtcr
recent
browse thread
cur tree
running
script
modified trees
tff
modified tree
tsurgeon script string
existing index
vis
treebank num
extra data
matched trees
matched part list
cur match
cur filename
help text
html tsurgeon help
html help
input panel
tregex guitable model
history entry
tregex guitree visitor
is in highlight
hls
highlight utils
add tree model listener
fire tree structure changed
get index of child
remove tree model listener
tree node changed
make tree path array
add file folder
find loadable files
add to map
check file
is likely invisible
get trf
set trf
get cur encoding
set cur encoding
tree structure
default_chinese_encoding
default_negra_encoding
cur encoding
parent path
new files
file node
new parent
new file
file tree model
check number format
align left
sync from pref panel
check encoding and display
do encoding prompt
alternate encoding prompt
is negra
is arabic
make color button
get icon height
get icon width
set color
get color
paint icon
font_error
history_error
max_match_error
gui
highlight button
pref panel
display prefs
display options
history label
history size field
max matches label
max matches size field
highlight label
tree display prefs
tree display options
font picker
default color label
default color button
matched label
matched button
adv options
headfinder picker
tree reader factory name
trf picker
encoding label
tsurgeon check
match portion
pref pane
max match size
text size
component
old encoding
encoding panel
use new encoding
use old encoding
use another encoding
new default encoding
prompt text
icon color
icon
new color
icon height
icon width
color
old color
preferences panel
color icon
clear matches
show prev matched part
show next matched part
show matched part
do export tree
show dependencies
show universal dependencies
get tree jpanel
maybe show popup
mouse released
set font size repaint
matched part coordinate idx
spaceholder
text field
tree display
horizontal
vertical
horizontal length
vertical length
tree jp
tree popup
export tree
imap
first mouse event1
handler
new match
display matches panel
display transfer handler
filename mouse input adapter
display mouse motion adapter
sub node
mod description
description
children disj
children conj
mod child
child
jj_3r_relation_277_3_25
jj_3r_sub node_128_5_9
jj_3r_child_265_7_24
jj_3r_child_264_7_23
jj_3r_description_170_5_20
jj_3r_child_263_5_22
jj_3r_mod description_142_31_16
jj_3r_child_263_3_18
jj_3r_sub node_119_3_8
jj_3r_sub node_119_3_6
jj_3r_mod child_256_7_14
jj_3r_relation_305_3_27
jj_3r_description_157_5_19
jj_3r_mod child_249_7_13
jj_3r_description_157_3_17
jj_3r_mod child_248_5_12
jj_3r_mod child_248_3_10
jj_3r_mod description_142_6_15
jj_3r_relation_278_9_29
jj_3r_relation_277_9_28
jj_3r_mod description_142_3_11
jj_3r_description_184_5_21
jj_3r_children conj_233_3_7
jj_3r_relation_277_5_26
under negation
known variables
negate desc
group num
var groups
original known variables
all known variables
start under neg
str arg
num arg
negation
neg str
cat str
tregex parser
negate
make optional
is negated
safe compile
set pattern string
extract subtrees
code pattern
code strings
tree file
codes
print non matching trees option
subtree code option
extract subtrees option
extract subtrees file option
input file option
extension option
tree reader factory class name
print handle option
mark handle option
yield only
print all trees
quiet mode
whole tree mode
filename option
one match per root node mode
report tree numbers
root label only
one line
unique trees
err pw
sub tree strings
hf arg classes
handles
print num matches to std out
print non matching trees
print subtree code
print whole tree
print matches
print filename
one match per root node
print only unique trees
tree number
last matching root node
dtb
labeled node
tregex pattern
tregex tree visitor
tregex tree reader factory
is set
set var
unset var
vars to strings
num vars set
old string
appended
variable strings
construct multi relation
satisfies
search node iterator
path matches node
initialize helper
parent of last child
last child of parent
old child
no extra children
equals
pattern_splitter
dominates
search stack
dominated_by
parent_of
next num
child_of
precedes
immediately_precedes
follows
immediately_follows
has_leftmost_descendant
has_rightmost_descendant
last kid
leftmost_descendant_of
rightmost_descendant_of
sister_of
left_sister_of
right_sister_of
immediate_left_sister_of
immediate_right_sister_of
only_child_of
has_only_child
unary_path_ancestor_of
only dtr
unary_path_descendant_of
parent_equals
used parent
simple_relations
simple_relations_map
headed by
immediately heads
immediately headed by
ith child of
has ith child
negated pattern
unbroken category dominates
unbroken category is dominated by
nodes to search
following node
preceding node
search node iterator
heads
headed by
immediately heads
immediately headed by
ith child of
has ith child
unbroken category dominates
unbroken category is dominated by
unbroken category precedes
unbroken category follows
decimate
textual summary
default_tree_file_suffix
path name
train w
dev w
test w
train pw
dev pw
test pw
num trees le40
num non unary roots
non unary eg
non unaries
root egs
starts
puncts
num unenclosed leaves
num leaves
num non phrasal
num pre terminal with multiple children
shortest sentence
longest sentence
num null label
leaf eg
pre terminal multiple children eg
null label eg
root rewrites as tagged word eg
has leaf child
empties
known empties
empties intersection
joint
treebank
counter tree processor
transform nonterminal label
basic category tree transformer
penn treebank tokenizer
english treebank stream tokenizer
gf character
print list sorted
add stranded pobj
correct whattachment
convert rel
filter kill
conj value
treat cc
is definitely active
collapse conj
collapse referent
add ref
add extra nsubj
correct subj pass
in conj deps
collapse prep and poss
determine prep relation
is conj with no prep
collapse2wp
collapse multi word prep
collapse2wpbis
collapse3wp
collapse flat mwp
erase multi conj
remove dep
remove exact duplicates
dep nodes
new deps
rcmod
xcomp_pattern
sg copy
embedded verb
dobj
reattach
found prep
has comp parent
prep2
found pobj
new conj
subject map
with passive auxiliary
rcmod heads
prepc dep
new typed deps
gov_relations
new gov
new rel
tdsubj
found one
td2
refs
left grandchild
xcomp
has subject daughter
has aux
subjects
objects
list_auxpass
vmod
found aux
aux dep
td1dep
possibles
prep dep
cc dep
other dtrs
same preposition in each conjunct
conj index
td2dep
td2dep pos
possibles2
prep other dep
td3
td3dep
td3dep pos
td1dep pos
td new
conj dep
td new2
otd
copy number
td new3
top prep
agent
preposition
aux_pass_poss
td_pass
multiword_preps
threeword_preps
td dep pos
mwp
str_mwp0
str_mwp1
w_mwp0
w_mwp1
mwp0
mwp1
newtd
mwp2
prep rels
english grammatical structure
extra tree dep filter
from dependencies factory
labeled scored tree reader factory
copular verbs
be get verbs
auxiliaries
time word regex
time word lot regex
copular word regex
clausal complement regex
passive aux word regex
be auxiliary regex
have regex
self regex
xcomp verb regex
xcomp no obj verb regex
ccomp verb regex
ccomp obj verb regex
say verb regex
relativizing_word_regex
relativizing_word_pattern
np_v_s_inf_verbs_regex
not_pat_word
etc_pat
etc_pat_target
fw_etc_pat
fw_etc_pat_target
western_smiley
asian_smiley
english patterns
left head finder
semantic graph to grammatical structure
convert basic to enhanced
convert basic to enhanced plus plus
convert tree to basic
get current tree
add lemmata
setup nertagger
add nertags
ner_combiner_name
use_name
morph
ner_tagger
ner_classify_method
ner_tagger_class
create method
conllu file name
output representation
sg iterator
sgs
upos tag
universal dependencies converter
tree to semantic graph iterator
parse features
to feature string
parse extra deps
to extra deps string
feature string
feat val pairs
feat val pair
extra deps string
extra dep parts
extra dep string
sep pos
feature name1
feature name2
dep index1
dep index2
co nlluutils
feature name comparator
dep index comparator
process multi word prepositions
enhance prepositional modifiers
enhance conjuncts
propagate dependents
add referent
add copy nodes
demote quant mod
add xsubj
enhance only nmods
enhancement options
is empty node
copy empty nodes
enhance graph
original enhanced
keep empty nodes
relative pronouns pattern
relative pronouns pattern str
embeddings filename
universal enhancer
propagate conjuncts
add case marker information
add case marker for conjunctions
add case markers to reln
get case marked relation
add conj information
add conj to reln
relcl_edge_weight
control_edge_weight
conjprop_edge_weight
relativizing word pattern
left child edge
child edge
left grandchild edge
grandchild edge
core arguments
expl map
edge1
arg edge
prep_patterns
old case marker
case marker
reln name
conj parents
conj parent
conj parent incoming edges
case markers
new reln
conjunction_pattern
old gov
old cc dep
conj deps
cc parts
universal grammatical structure
get gov and reln
comment_pos
ifrf
by index
by type
line number counter
gov pseudo index
pseudo index
token length
original token
basic gov idx
basic gov reln
basic gov
basic reln
extra gov idx str
extra gov idx
gov reln
basic sg
enhanced sg
co nlludocument reader
sentence processor
word processor
enhance dependencies
enhance english dependencies
plusplus
process universal enhancer request
get average embeddings
coarsen upostag
align
get conj gov orphan gov pair
is argument
is clausal argument
get argument subsequences
get full conjunct arguments helper
build all argument sequences
get full conjunct arguments
is modifier
get orphan gov sequence
get gapped conjunct arguments
do enhancement
gap_penalty
pos_mismatch_penalty
edge_weight
total vector
coarser uposmap
u pos
full arguments
gapped arguments
print semantic graph
print span
print posannotations
unescape parenthesis
token sg
secondary deps
additional deps string
features string
upos
misc
fake deps
headrel
co nlludocument writer
load feature map
get posfeatures
is ordinal
is multiplicative
get graph features
pronoun case
was person
get rel and int pron features
treebank iterator
get imperatives
has to
has be aux
feature_map_file
pos feature map
word pos feature map
ordinal_expression
multiplicative_expression
self_regex
is rel
parent parent
imperative_pattern
imps
verbs
be_regex
aux
add upos
imperatives
word features
u postags
u postag
co nllufile
escape parens
dep reader
dep writer
tree it
sentence sb
universal dependencies feature annotator
get nmod
get obl
get acl
get advcl
get specific reln
oblique_modifier
vocative
dislocated
nominal_modifier
clausal_modifier
classifier
case_marker
flat
compound_modifier
orphan
reparandum
relative_clause
possessor
controlling_nominal_subject
controlling_nominal_passive_subject
relative_nominal_subject
relative_nominal_passive_subject
relative_object
nmod relations
obl relations
acl relations
advcl relations
conj relations
existing relations
universal grammatical relations
print usage
print punct
count taggings
run timing
sentence lengths
max l
min l
penn print trees
one line print
print tagged words
annotation options
punct
remove code trees
decimate prefix
t prime
treebank str
punct tag filter
tws
wtc
ctr
maxleng
length counts
longest seen
long sent
found median
running total
treebanks
tree lemmatizer
filtering tree reader
all brackets
common word tag type brackets
brackets
root1
root2
first pre terms
pre term
tree to bracket processor
transform helper
transform terminal
transform nonterminal
transform terminal label
transform label
recursive tree transformer
universal semantic head finder
month_regex
tregex month year
tregex month day year
date tree transformer
find marked head
traverse locate
find left head
find left dis head
find left except head
find right head
find right dis head
find right except head
non terminal info
default rule
default left rule
default right rule
categories to avoid
the head
last resort
child cat
abstract collins head finder
crosses
to sentence string
lab1
lab2
lv1
lv2
const coll
word num
constituent
get current filename
get current paths
print file names
prime next path
prime next tree
file paths
file filters
current filename
stored tree
local path list
local filter list
file list ptr
cur line id
cur file list
cur path iter
next path
next filter
path listing
disk treebank
disk treebank iterator
composite treebank
composite treebank iterator
span factory
qptransform
universal dependencies
flatten npover qptregex
flatten npover qptsurgeon
multiword xstregex
multiword xstsurgeon
split cctregex
split cctsurgeon
split money tregex
split money tsurgeon
qptree transformer
tree length comparator
simple tree factory
left
right
direction
default padding
other rel
collins relation
replace postag
normalize preterminal
cc tagset
morph str
sub cat
pos str
french tree normalizer
french aover afilter
chf
dybro french head finder
get morph
get subcat
get word string
get tree from xml
post process mwe
node_sent
node_word
attr_number
attr_pos
attr_pos_mwe
attr_lemma
attr_morph
attr_ee
attr_subcat
mwe_phrasal
empty_leaf
missing_phrasal
missing_pos
sent root
ftb id
attr pos
attr posmwe
subcat
no whitespace str
e root
leaf toks
leaf list
leaf node
leaf str
is mwe
t yield
morph analyses
canonical file name
ftb id
french xmltree reader
french head finder
punctuation words
sentence final punctuation tags
sentence final punctuation words
label annotation introducing characters
treebank file extension
morph feature spec
ftb_encoding
french punct tags
french sfpunct tags
french punct words
french sfpunct words
french start symbols
french treebank language pack
abishek french head finder
french xmltree reader factory
french tree reader factory
strip gf
contains kept gf
is leave gf
set leave gf
is limited gf
set limited gf
limited gf
gf to keep array
tuebadz punct tags
tuebadz sfpunct tags
tuebadz punct words
tuebadz sfpunct words
use limited gf
gf length
tue ba dzlanguage pack
tn1
tn2
tue ba dztree reader factory
root symbol
under root
tue ba dzpenn tree normalizer
is label annotation introducing character
coord switch
excluded
head marked pattern
head marked pattern2
deflt
tue ba dzhead finder
nonsensical clause rewrite
erase clause
expand elisions
expand conmigo
spanish split tree normalizer
is word node
is elliptic node
build word node
build elliptic node
build constituent node
should print tree
arg option defs
simplified tagset
detailed annotations
attr_word
attr_func
attr_named_entity
attr_postype
attr_elliptic
attr_punct
attr_gender
attr_coordinating
attr_clause_type
aggressive normalization
retain ner
this sentence id
named attribute
tag name
pos type
gen code
num code
constituent str
tpos
tword
plain print
pos pattern
num trees retained
remaining arg
spanish xmltree reader
insert verbs
all verbs
root rules
adjective phrase rules
to left
to right
spanish head finder
sentence final punct tags
punct words
sentence final punct words
spanish treebank language pack
spanish xmltree reader factory
spanish tree reader factory
simplify postag
expand clitic pronouns
expand clitic pronouns inner
mark simple named entities
is multi word candidate
normalize for multi word
prepare for multi word extraction
get multi words
should drop word
compile patterns
mw_tag
mw_phrase_tag
empty_leaf_value
spelling fixes
constituent renamer
cleanup strs
cleanup
merge with constituent when possible
verb_leaf_with_pronouns_tregex
verb with clitic pronouns
verb with clitic pronouns and siblings
clauseless verb with clitic pronouns
clausify verb with clitic pronouns
verb node
clause yield builder
clause yield
new tree str
insert pattern
relabel operation
mark simple nes
pattern templates
named entity types
named entity type
tsurgeon
leaf value
word1
phrase value
should merge
p quoted
p punct
word_separators
word_separators_drop
hyphen bound morphemes
punct matcher
quote matcher
splitter
remaining tokens
hyphen
free morpheme
prev index
elision expansion strs
elision expansions
conmigo pattern
conmigo node
new pronoun
spanish tree normalizer
default path2
env_variable
cedict
lexer
chtbtokenizer
comma_pattern
modal_pattern
location_nouns
parenthetical_modifier
noun_modifier
range
ordinal_modifier
adv_clausal_modifier
dvpm_modifier
modal_verb
aspect_marker
mark
compound
noun_compound
verb_compound
case
associative_modifier
nominal_topic_modifier
localizer_complement
clausal_localizer_complement
resultative_complement
classifier_modifier
part_verb
etc
controlled_subject
discourse
chinese only
raw values
universal values
universal chinese grammatical relations
bikel chinese head finder
chinese semantic head finder
chinese grammatical structure factory
chinese collinizer
ctbtree reader factory
no empties ctbtree reader factory
chinese escaper
is number
normalize bmp
normalize unicode
is mid dot
is ascii low high
only_bmp
onewhite
white
whiteplus
mid_dot_regex_str
leave
ascii
fullwidth
delete_except_between_ascii
max_legal
ascii
space char
cub
delete
cpp
cpn
chinese utils
three node pattern
one node pattern
automatic initial pattern
manually segmented pattern
ontheway pattern
single punc frag pattern
single punc pattern
meta pattern
bracket pattern
fragment tree filter
sun jurafsky chinese head finder
is punctuation tag
is punctuation word
is sentence final punctuation tag
is eval bignored punctuation tag
chinese comma accept filter
chinese end sentence accept filter
chinese dou hao accept filter
chinese quote mark accept filter
chinese parenthesis accept filter
chinese colon accept filter
chinese dash accept filter
chinese other accept filter
chinese left parenthesis accept filter
chinese right parenthesis accept filter
chinese left quote mark accept filter
chinese right quote mark accept filter
grammatical structure factory
supports grammatical structures
dou hao
quote mark
parenthesis
dash
left quote mark
right quote mark
left parenthesis
right parenthesis
punc filt
chinese treebank language pack
untransform tree
test trans and untrans
use two char tags
new preterms
single char label
old tree
character level tag extender
left except punct
right except punct
rightdis
chinese head finder
zz unpackcmap_top
zz unpackcmap_blocks
zz unpack action
zz unpack row map
zz unpack trans
zz unpack attribute
report error
zz cmap
zz refill
yyclose
yyreset
yy reset position
yyat eof
yystate
yybegin
yytext
yycharat
yylength
zz scan error
yypushback
yylex
yyeof
zz_buffersize
yyinitial
universal chinese grammatical structure factory
universal chinese semantic head finder
tag extender
chinese empty filter
fixup tregex
fixup tsurgeon
new tree
subsubtree
pre processed
ctberror correcting tree normalizer
chinese empty filter
ctberror correcting tree reader factory
top_subject
time_postposition
attributive
complementizer
lc_complement
res_verb
odnumeric_modifier
ip_modifier
prn_modifier
dvp_modifier
associativem_modifier
cl_modifier
prepositional_loc_modifier
predicate_aspect
chinese grammatical relations
shf
td3reln
frag discarding penn tree reader
get radical
get chars
chars to rads
rads to chars
character
rad lists
rad list
rad
r leng
enc args
rebuild args
dict file
infile args
other args
radical map
translate lines
translate file
hardcoded
isr
hardcoded set
traditional
translated
mapper
traditional simplified character map
get all translations
get first translation
read cedict
is digits
get reverse map
add map
default pattern
default delimiter
default charset
sfpunct words
hungarian treebank language pack
pw dev
pw train
pw test
split maker
eval bignored punctuation tags
penn punct tags
penn sfpunct tags
collins punct tags
penn start symbols
hebrew treebank language pack
hebrew empty filter
hebrew tree normalizer
hebrew empty filter
hebrew tree reader factory
negra penn tree reader factory
negra penn tokenizer
negra_encoding
eval bignored tags
negra sfpunct tags
negra sfpunct words
negra punct tags
negra punct words
negra penn language pack
non unary root symbol
set insert npin pp
get insert npin pp
fix non unary root
insert npin ppall
insert npin pp
non unary root
junk cpp
grand kids
preposition tags
postposition tags
np kids length
np kids
new ppkids
negra penn tree normalizer
negra semantic head finder
cut chars
cut char
negra head finder
push back
get yyeof
set feature value
feature_sep
negra label
negra label factory
sfpunct tags
italian treebank language pack
escaped
atbescaper
filter x
no normalization
arabic tree reader factory
xfilter
arabic raw tree reader factory
mark prdverb
prd pattern
prd verb pattern
np sbj pattern
normalized string
morph analysis
new lemma
new morph analysis
prd
arabic tree normalizer
arabic empty filter
penn punct words
penn sfpunct words
arabic treebank language pack
pres to logical map
get arabic ibmnormalizer map
rule iter
this rule
arabic utils
un escape
flatten tree
tagged string from tree
seg marker
morph boundary
reserved word list
reserved words
flat string
remove escaping
atbtree utils
noun
det plus noun
lang pack
bies_collapsed
original
pred pattern
arabic head finder
att
arabic treebank tokenizer
tag tree
get tagged leaves
tags and words
tree file path
updater
treebank tag updater
grammatical function tree normalizer
tree leaf label transformer
collins head finder
universal english grammatical structure factory
get nmods
get acls
get advcls
get obls
preposition
name_modifier
qmod
controlling_clausal_subject
controlling_clausal_passive_subject
clause relations
nmods
obls
acls
advcls
advcl string
acl string
universal english grammatical relations
equivalence class
word cat equivalence classer
penn treebank language pack
add passive agent to reln
expand prep conjunctions
expand prep conjunction
expand ppconjunctions
expand ppconjunction
fix ccattachment
process multiword preps
process simple2wp
process complex2wp
process3wp
create multi word expression
demote quantificational modifiers
demote qmod mwehelper
demote qmod parent helper
process names
process names helper
enhanced_options
enhanced_plus_plus_options
collapsed_options
passive_agent_pattern
prep_mw3_patterns
prep_mw2_patterns
old case markers
last case marker index
prep_conjp_pattern
case gov
case gov gov
conj gov
new conj deps
case gov gov copy
pp_conjp_pattern
nmod gov
nmod gov copy
new heads
conjuncts
conjunct
new governor
changed prep
nmod
second iword
third iword
third word
correct_subjpass_pattern
two_word_preps_regular
two_word_preps_complex
three_word_preps
two_word_preps_regular_pattern
two_word_preps_complex_pattern
three_word_preps_pattern
trigrams
trigram
gov2
edge2
marker reln
mwe head
word gov
quant_mod_3w_pattern
quant_mod_2w_patterns
other deps
old head
name_patterns
punct_tag_filter
root token
name parts
old edge
universal english grammatical structure
tree core annotations
tree annotation
binarized tree annotation
head word label annotation
head tag label annotation
kbest trees annotation
add transformer
transformers
composite tree transformer
punctuation tag accept filter
punctuation tag reject filter
punctuation word accept filter
punctuation word reject filter
sentence final punctuation tag accept filter
eval bignored punctuation tag accept filter
eval bignored punctuation tag reject filter
get basic category function
category and function
last index of numeric tag
get category and function function
is start symbol
start symbol accept filter
get gf character
set gf character
default_gf_char
empty_char_array
cat func
only digits follow
ssyms
punct tag string accept filter
punct word string accept filter
s fpunct tag string accept filter
e ipunct tag string accept filter
abstract treebank language pack
basic category string function
category and function string function
get tree from input stream
left paren
right paren
found count
star_pattern
slash_pattern
penn tree reader
penn tree reader factory
set gov
set extra
td arg
dep arg
dep this
index arg
index this
gov index arg
gov index this
typed dependency
regent text
dependent text
this head word
this dep word
unnamed dependency
unnamed dependency factory
get labeled tree to string labeled tree function
get labeled tree to category word tag tree function
get labeled to descriptive core label tree function
stringy tree
adapty tree
string label tree
tree functions
labeled tree to string labeled tree function
labeled tree to category word tag tree function
labeled to descriptive core label tree function
highest
output lowercase
lctok
maxstr
maxcount
mix disambiguation
create and show gui
add menu bar
key pressed
key released
key typed
save untagged contents
save file
get url
display error
load default classifier
open file
open url
redraw
remove tags
get attribute set
exit
build content panel
color to html
build extract button
build tag panel
make tag maps
make tag to color map
get ncolors
editor pane
tag panel
height
width
tag to color map
file chooser
default attr set
actor
loaded file
untagged contents
tagged contents
html contents
save untagged
save tagged as
menubar
file menu
edit menu
classifier menu
menu mask
load url
save untagged as
load crf
load default crf
load cmm
load default cmm
com
return val
labeled text
start pattern
end pattern
final text
att set
init text
scroll pane
extract button
num colors
colors
basic colors
nergui
input listener
action performer
embedding feature factory
plausibly has relation
get subject span
get subject text
get object span
get object text
precision micro
precision macro
recall micro
recall macro
f1micro
f1macro
dump per relation stats
compute accuracy
no_relation
cause_of_death
city
country
criminal_charge
ideology
location
misc
nationality
organization
person
religion
state_or_province
title
url
gpe
is regex nertype
slot
per_alternate_names
per_children
per_cities_of_residence
per_city_of_birth
per_city_of_death
per_countries_of_residence
per_country_of_birth
per_country_of_death
per_employee_of
per_loc_of_birth
per_loc_of_death
per_loc_of_residence
per_member_of
per_origin
per_other_family
per_parents
per_schools_attended
per_siblings
per_spouse
per_state_or_provinces_of_birth
per_state_or_provinces_of_death
per_state_or_provinces_of_residence
per_age
per_date_of_birth
per_date_of_death
per_cause_of_death
per_charges
per_religion
per_title
org_alternate_names
org_city_of_headquarters
org_country_of_headquarters
org_founded_by
org_loc_of_headquarters
org_member_of
org_members
org_parents
org_political_religious_affiliation
org_shareholders
org_state_or_provinces_of_headquarters
org_subsidiaries
org_top_members_slash_employees
org_dissolved
org_founded
org_number_of_employees_slash_members
org_website
org_employees
gpe_employees
org_students
gpe_births_in_city
gpe_births_in_state_or_province
gpe_births_in_country
gpe_residents_in_city
gpe_residents_in_state_or_province
gpe_residents_in_country
gpe_deaths_in_city
gpe_deaths_in_state_or_province
gpe_deaths_in_country
per_holds_shares_in
gpe_holds_shares_in
org_holds_shares_in
per_organizations_founded
gpe_organizations_founded
org_organizations_founded
per_top_employee_of
gpe_member_of
gpe_subsidiaries
gpe_headquarters_in_city
gpe_headquarters_in_state_or_province
gpe_headquarters_in_country
single
is original relation
query limit
cardinality
valid named entity labels
valid posprefixes
prior probability
cached from string
original name
slot value type
subject type
object type
conll input file
subject ner
object ner
predicted count
gold count
correct count
predicted relations raw
gold relations raw
predicted relations
gold relations
pred
all relations
sum precision
sum recall
stat
predict out
test i
confidence format
kbpinput
accuracy
per relation stat
get affix features
add typed feature
affix features
dir1
prefix
suffix
single feat name
feat type
single feat index string
typed double feat pattern
typed single feat pattern
single feat pattern
typed double feat matcher
feat index string
prefix char
suffix char
typed single feat matcher
single feat matcher
feat char
is prefix
chinese morph feature sets
entity matrices
whomepage
wacronym
wname
chomepage
cacronym
tally
info template
load default
insert hyph pattern
get matching patterns
label word break points
find break points
linechars
linechar
shortchars
shortpattern
an i
a char
curchar
starting idx
matching patterns
break points
break score
lcphrase
word start
hyphenator
break point
te xhyphenator
hyphen data
default te xhyphen data
stem acronym
merge clique templates
get field index
write to field value counter
unpack to clique templates
field indices
acronym pattern
stemmed acronym index
stem1
stem2
stemmed
values2
field value counter
pascal template
index fields
matrix size
matrix idx
present fields
prior
long form
short form
pointers
pstrings
spaces
alignment
subdate
noadate
crcdate
workdate
date template
increment year
increment month
increment day
make string day change
make string month change
make string year change
from date string
get date string
extract fields
get range dates
add extra ranges
is range
is unparseable
get start date
get end date
is after
check wildcard after compatibility
is date format
is year compatible
is month compatible
is day compatible
check wildcard compatibility
is compatible date
tokenize date
extract yyyymmdd
extract mmddyy
extract year
found misc year pattern
extract month
extract day
extract weekday
open_range_after
open_range_before
bounded_range
no_range
day_of_half_month
last_day_of_month
month_of_half_year
last_month_of_year
unparseable
open range marker
start string
end string
reference date
relative date
orig date string
year string
month string
month num
decreasing
new month num
num years to increment
day string
day num
num days in month
new date num
orig date
new day
new day string
new month
new month string
new year
new year string
relative date map
days per month
input date
date endpoints
date1
date2
passed
weekday
range indicators
cur indicator
first date
second date
year other
month other
day other
txt2
number value
start other
end other
month value
day value
year int
re1
re2
end date
extractor array
found month
weekday array
date property
isodate instance
inverse acronym map
urls
date clique counter
location clique counter
workshop info clique counter
clique templates
parse number part
word to number
word to number recurse
find numbers
find number ranges
find and merge numbers
find and annotate numeric expressions
find and annotate numeric expressions with ranges
num unit pattern
num end unit pattern
num not standalone unit pattern
number term pattern
number term pattern2
ordinal unit pattern
digits pattern
digits pattern extended
num pattern
num range pattern
word2num map
ord word2num map
alpha pattern
ws pattern
whitespace chars regex
original string
num part
magnitude part
magnitude
num fields
cur part
cur num
highest num
highest num index
before num
after num
evaluated number
number pattern
matched tokens
num start
possible num end
last unit pos
possible num start
possible num end unit
last unit
prev num
num type
prev num type
range pattern
numerized tokens
range matcher
number ranges
annotation raw
number aggregator
saved token begins
saved token ends
new begin
merged numbers with ranges
number normalizer
classify no seq
loglikelihood
get sequence model
classify seq
retrain
get features above threshold
get dataset
get biased dataset
adapt max ent
train svm
train max ent
train semi sup
get default classifier
get classifier no exceptions
make answer arrays and tag index
add other classes
get thresholds
classify with global information
build tag array
print probs document
answer arrays
default_classifier
list size
lsize
line info
cll
ng tag
bg tag
d size
win start
win end
bg score
prev scores
ng score
train dataset
reader writer
feature labels
new f
new fs
new ls
newi
findex
lindex
word infos
features above threshold
smallest
orig feat index
dsize
new feats
orig dataset
old data
good features
old data array
old label array
old feature index
old to new feature map
new data array
old f
fact
cmm
p info
p answer
p2answer
p3answer
p4answer
p5answer
n answer
new feat
biased filename
biased dataset
token seq
tag array
background tags
legal tags
score cache
last window
secs
hit
secs2
abs pos
t a
last pos
output highlighting
spacing
default classifier
ners
spacing str
preserve spacing str
last end offset
string color entry
nerservlet
dir
test_file
predictions
tokensregex dir
rel file name component
list files
extr
sentence as map
kbptokensregex extractor
subject
object
statistical_model
semgrex_dir
tokensregex_dir
classifier prediction
kbpensemble extractor
get one substitution match
is one substitution match
single entity to string
collapse nerlabels
normalized date string
normalized duration string
is year
detect date range modifier
detect two sided range modifier
concatenate numeric string
normalized time string
convert to american
normalized money string
normalized number string
normalized number string quiet
normalized ordinal string
normalized ordinal string quiet
normalized percent string
fetch number from sutime
fetch timex from sutime
process entity
time entity to string
normalize classifier output
detect quantity modifier
detect time of day modifier
add normalized quantities to entities
fixup ner before normalization
apply specialized ner
debug2
money pattern
score pattern
quantifiable
collapse before parsing
time unit words
money multipliers
money multipliers2
currency words
words to values
ordinals to values
last entity
entity string collector
timex from sutime
date range after one word
date range before one word
date range before paired one word
date preposition after word
before index
next2
next3
cur ner
ner next2
range string
number words
new text
found entity
ampm
place
number from sutime
currency sign
string character entry
all spaces
orig sclean
orig ssplit
found multiplier
string double entry
money tag
string integer entry
part
part match
comp modifier
less equal three words
greater equal three words
greater than two words
less than two words
less equal two words
greater equal two words
approx two words
greater than one word
less than one word
less equal one word
approx one word
prev2
prev3
long prev
long next
early one word
early two words
early three words
late one word
late two words
late three words
middle two words
middle three words
am one word
pm one word
am three words
pm two words
pm three words
uses sutime
prev ner tag
time modifier
curr ner tag
wprev
more removes
prev numeric type
prev timex
numeric type
next ner
sides
copy l
nsc answer
quantifiable entity normalizer
sub entity matrix
orgindex
locindex
other occurrence
other entity
o length
o other
add bias feature
set bias weight
adjust bias
bias
cindex
eval function
devel data
optimizer
opt val
cut document
copy document
paste document
shortcut mask
shift shortcut mask
cut
paste
load resource crf
resource
clique size
clique features
feature val
pos in sent
compute clique potential
doc labels
observed
dot prod
clique feature
noisy label linear clique potential function
to prob string
to non log string
indices end
indices front
window size
unnormalized log prob
conditional log prob given previous
conditional log probs given previous
conditional log prob given first
unnormalized conditional log prob given first
conditional log prob given next
unnormalized log prob front
log prob front
unnormalized log prob end
log prob end
increment value
log increment value
multiply in front
multiply in end
sum out end
sum out front
table
front
given
prob all
prob given
masses
num cells to sum
divisor
ft2
ft3
ft4
ft5
factor table
f weights
d weights
linear clique potential function
create partial data for lop
get feature boundary indices
feature indices set array
feature indices list array
lop iter
new feature list
feature indices set
old features
f index
prune feature itr
lop expert weights
list of weights
partial data
new lop expert weights
initial scales
dis
learned params
raw scales
lop scales
learned lop expert weights
hidden layer output
input layer weights4edge
output layer weights4edge
input layer weights
output layer weights
layer one cache
hidden layer cache
layer one cache4edge
hidden layer cache4edge
node clique features
a flag
layer cache
hl cache
layer one size
l one w
input weights
output weights
hidden layer
output layer size
output ws
non linear second order clique potential function
monitor
weights array
linear weights
non linear clique potential function
ub prefix feature string
get feature string
eol
sorted features
export file
docs data
feature exporter
get clique potential function
empty2d
empirical counts
get float factor table
get calibrated clique tree
calculate weird1
label indices
ehat
a map
data doc
labels doc
clique label
crf label
factor table
factor tables
messages
summed out
llabels
ddata
index1
crflog conditional objective float function
is constrained
get constrained set
default_capacity
observation counts
observed labels
observation index
label dictionary
observation
constrained observations
allowed labels
label dictionary
get num weights
get feature type index
scale weights
combine weights
drop features below threshold
document to data and labels
print label information
documents to data and labels
documents to data and labels list
all labels
make datum using embedding
dump features
classify and write answers
get clique potential function for test
update weights for test
classify max ent
classify gibbs
zero order probabilities
print first order probs documents
print factor table documents
get clique trees
get clique tree
print factor table document
print first order probs document
load auxiliary data
prune node feature indices
get objective function
extract datum sequence
add processed data
save processed data
serialize text classifier
serialize class index
load class index from file
serialize weights
load weights from file
serialize feature index
load feature index from file
load tag index
parse matrix
read entity matrices
top weights
read embeddings data
choose crfclassifier
clique potential function
clique potential function helper
node feature indices map
edge feature indices map
suffix patt
template group index
feature index to template index
old num features
crf label map
new label indices
feature type index
old num features1
old num features2
old num weights1
old num weights2
elapsed ms
data_j
feature vals_j
feature val list
data_jk
column headers
row headers
doc triple
feature val arr
doc list
enc
use feature count thresh
feature count indices
seen background features
word count
f count index
feature index map
group suffix
group index
li size
fi size
embedding list
concat embedding len
curr loc
num of capital features
curr len
concat embedding
curr pos
document data and labels
print writer
results counted
tag inference
guess prob
clique tree
pmf
sampler
test sequence model
calibration
correct by bin
calibrated tokens
max prob
best class
binned prob
cts
iter1
object bank wrapper
docs to shuffle
total docs
data and labels and feature vals
evaluator list
crf evaluator
train data and labels
test obj bank
test data and labels
feat index file
processed data
all data
all feature vals
one dim weights
arr length
total num of feature slices
num of node features
node feature original indices
edge feature original indices
new node feature index
new edge feature index
edge findex
feature sets
p index
clique type
num clique type output class
clique out class
a set
tester
feature prune iteration
qn mem
labeled word infos
begin context
pd size
data index
crf datum
csize
label indices idx
label index size
crflabelstr
crflabel
crf l
class index size
feature index size
feature factory name
window size name
weights length
weights2length
weights value
arr unboxed
index array
temp weights
lc words
use log prob
subparts
subsubparts
tag index1
tag index2
matrix lines
sub matrix lines
sub matrix
vector size
load text path
known lcwords limit
get func
expected and empirical counts and value for adoc
regular gradient and value
doc index
feature val3darr
clique tree noisy label
crflog conditional objective function noisy label
set test data
set eval cmd
set values
get cmd
interpret cmd output
output to cmd
cmd str
featurized data
f score index
transform doc data
train weights using non linear crf
trans data
trans feature index
all weights
node feature indices map size
edge feature indices map size
get factor tables
get num classes
background index
log prob table
log prob start pos
probs to double arr
log probs to double arr
object array to int array
int array to list e
cond log prob given previous
cond prob given previous
cond log probs given previous
cond log prob given next
cond prob given next
cond log probs given next
get factor table
get conditional distribution
get num values
possible values
prob this given prev
prob next given this
prev length
next length
next factor table
labels list
prev labels
prevlabels
next labels
nextlabels
clique potential func
feature val by clique size
wscale
weight indices
w scale
clique potential
read error matrix
get prior type
empty u4edge
empty w4edge
empty u
empty w
separate weights
empty full2d
uhat
what
doc window labels
input layer size
input layer size4edge
output layer size4edge
edge param count
num node features
num edge features
before output weights
original feature count
prior type str
two epsilon
interval4edge
upper
inner size
outer size
all params
w4edge
u4edge
y4edge
what4edge
uhat4edge
e w4edge
e u4edge
e w
e u
window labels
new doc labels
f deriv
y times a
sum of ytimes a
output size
f d
hidden unit no
given label index
uhat k
y times ak
sum of ytimes ak
delta k
what k
uk2
e uk
yk2
delta q
e wq
e wk
reg size
crfnon linear second order log conditional objective function
conditional log prob
an array
an entry
a front
float factor table
background tag
all tags
allowed tags at position
real pos
allowed tags
test sequence model
as feature vals
unsup docs
unsup obj bank
unsup dropout data
unsup data and labels
empirical counts for adoc
value for adoc
expected counts and value for adoc
expected counts for adoc
document expected counts
document log probability
multi thread gradient
get feature grouping
set feature grouping
apply prior
get cond probs
combine2darr
to2dfloat
clear2d
get weight indices
get labels
dropout_prior
debug3
timed
condense
parallel e
parallel ehat
feature grouping
small const
rand to use
rand gen
calc empirical
my domain dimension
e hat
doc data_i
doc data_ij
feature val arr_ij
do expected count calc
do value calc
start pos log prob
doc ids
expected thread processor
expected and empirical thread processor
part e
prob sum
part ehat
doc ids
calculate empirical
total len
part len
t id
e_i
ehat_i
batch scale
x scale
g scale
ehati
wlambda
batch scale sigma sq
weps
sigmasq
batch scale sigma qu
c tree
prev given curr
next given curr
prev given curr i
next given curr im1
label pair
combine into
to be combined
src row
weights1d
arr2d
weight vector
crflog conditional objective function
task part
task result
expectation threadsafe processor
expectation threadsafe processor with empirical
initialize2dweights
compute ehat
log potential
combine and scale lop weights
combine and scale lop weights2d
separate lop expert weights2d
separate lop expert weights
separate lop scales
sum of observed log potential
sum of expected log potential
lop expert weights2d
learned params mapping
backprop training
feature indices list
expert weights2d
doc data i
doc data ij
observed label index
ehat of iter
indices set
feature idx
learned lop expert weights2d
sum of elpm
sum of elpmi
sum of elpmij
sum of elpmij iter
temp weight
inner dim
inner weights
learned weights2d
param index
learned weights
combined weights2d
e scales
inner lop iter
e of iter
d index
e of expert
ehat of expert
crflog conditional objective function for lop
init edge labels
sparse e
incre score
incre score allow null
initialize data feature hash
get dropout prior
dropout prior grad total
weight square
total data
unsup dropout start index
data feature hash
condensed map
data feature hash by doc
edge label index size
node label index size
edge labels
curr prev labels map
curr next labels map
dropout prior thread processor
doc index unsup
edge label index
node label index
skip expected count calc
skip val calc
doc data hash
condensed features map
efor adoc
efor adoc pos
f val
doc data hash i
efor adoc pos at i
a list
to copy into
target arr
dropout prior grad
macro active feature total count
macro condensed total count
macro doc pos count
occur pos
set of features
data i
data j
represent features
condensed count
arr of index
dropout prior grad first half
prior value
cond probs
falpha
fbeta
prev feature present
doc data hash iminus one
f index pos
y prime
prev label
doc data len
doc data hash iplus one
next feature present
delta div by one minus delta
inner timer
e timing
dropout timing
contains feature
y p
pt yyp
pt yyp times one minus pt yyp
one minus2pt yyp
usum
jjj
val index
var up
var u
var utimes one minus2pt yyp
f label index
f count
cond e
pt yyp prime
weights_i
submit is unsup
is unsup
partial dropout
partial e
crflog conditional objective function with dropout
l1_prior
gradients only
fan in
two fan in
linear weights2d
two sigma sq
value sum
softmax lambda
one divided by two sigma sq
a u
param range
label indices size
node feature index
output class index
hidden unit index
first layer index
one dindex
crfnon linear log conditional objective function
get smaller label
get one smaller label
max num classes
a label
crflabel
rules_dir
default_prefix_file
default_units_file
prefix filename
prefix rules filename
units filename
units rules filename
text2unit mapping
generate prefix defs
generate units stage0rules
amount
unit name
prefixes
units files
units
quantifiable entity extractor
format in default unit
set symbol
get default unit
set default unit
get default unit scale
set default unit scale
prefix system
default unit
default unit scale
unit
get amount
set amount
get unit
set unit
simple quantifiable entity
get scale
set scale
register prefixes
register prefix
load prefixes
comma pattern
header string
header index
i name
i prefix
i base
i exp
i system
unit prefix
unit prefix
register derived unit
register unit
register units
load units
derived type
symbol suffix
is static
is unit
derived unit
type
dollar
cent
pound
penny
euro
yen
yuan
won
i symbol
i type
i default unit
i default unit scale
units by name
unit to default units
units
money unit
currencies
serialized classifier
lcl
nerdemo
create datum
create test datum
sent to string
add dependency path features
using feature
generalize relation
dependency path as list
dependency path
generalized dependency path
dependency features
label string
positive label
rel sentence
arg0sentence
arg1sentence
checklist
arg0preterm
arg1preterm
path string builder
path up
path string
other arg
surface distance
left window pos
right window pos
argn
winnum
windex
word0
pos0
rel args
type counts
sb pos
sb selective
sw start
sw end
arg0male
arg0female
arg1male
arg1female
temp dep features
node0
edge path
path nodes
dep low level
path lemmas
no arg path lemmas
indeces to skip
node1path
node0path
edge0
edge0str
edge1str
right relation
left relation
governs left
governs right
elt
sb rels hi
sb rels lo
general_relations
general gr
generalize
next node
singleton
basic relation feature factory
set processor
set use new head finder
set logger level
get logger level
modify using core nlpner
sentence to string
assign syntactic head
pre process sentences
original find syntactic head
calculate head span
force generation of index spans
use new head finder
ret val
iox
all nertagfor span
entity nertag
set head span
generic data set reader
dataset reader class
dataset aux reader class
reader log level
serialize corpora
serialized entity extractor path
serialized entity extraction results
entity gazetteer path
entity classifier
entity results printers
serialized relation extractor path
serialized relation extraction results
relation feature factory class
relation mention factory class
relation features
relation results printers
train relations using predicted entities
test relations using predicted entities
create unrelated relations
do not lexicalize first arg
use relation extraction model merging
relations to skip during training
relation extraction post processor class
relation classifier
serialized event extractor path
serialized event extraction results
event results printers
train events using predicted entities
test events using predicted entities
consistency check
aux data path
serialized training sentences path
serialized aux training sentences path
train use pipeline ner
train only
serialized test sentences path
extract entities
extract relations
extract events
percentage of train
feature similarity threshold
compute feat similarity
feature selection num features ratio
l1reg
l2reg
l1reg lambda
machine reading properties
set validator
set relation extractor classifier type
set feature count threshold
set create unrelated relations
train multiclass
report weights
compatible label
extract all relations
annotate multiclass
create dataset
relation extractor classifier type
validator
relation mention factory
feature fac
modelpath
lc factory
svm factory
labels to feature weights
feat weights
sorted probs
nr prob
choice
test datum
cands
test datums
predicted labels
basic relation extractor
set console level
make machine reading for annotation
make machine reading
print task
remove skippable relations
change gold relation args to predicted
assign syntactic head to entities
make extractor
make data sets
keep percentage
serialized model exists
make results printers
make reader
make aux reader
make entity extractor
make relation extractor
make relation feature factory
make relation mention factory
load or make serialized sentences
set extract entities
set extract relations
set extract events
set force parse sentences
set datasets
get datasets
set predictions
set aux reader
get aux reader
set entity results printer set
get entity results printer set
set relation results printer set
get relation results printer set
aux reader
relation extraction post processor
event extractor
consistency checker
force retraining
force parse sentences
datasets
entity results printer set
relation results printer set
event results printer set
entity_level
relation_level
event_level
top logger
console handler
relation post processor
log level
ret msg
have serialized entity extractor
have serialized relation extractor
have serialized event extractor
testing
serialized test sentences
merged predictions
task level
task name
printers
rff
relations to skip
backed up relations
relation mentions
mst loader
mst constructor
new relation mentions
new rels
partition index
extractor class
aux dataset
training enhanced
partition train
partition test
percentage
smaller
full sents
small size
printer class names
printer class name
entity extractor class
gazetteer path
relation extractor class
relation feature list
rmf
sentences path
serialized sentences
corpus sentences
machine reading
build relation extractor merger
all relation mentions
unique relation mentions
extractor index
extractor model names
relation extractor components
extractor merger
set do not lexicalize first argument
collapsed
collapsed_ccprocessed
dependency_path_lowlevel
dependency_path_words
relation feature factory
print results
make label
print results using labels
excluded classes
use sub types
verbose instances
formatter
gold standard
extractor output
sys sent
sys text
gold text
matched golds
gold entities
sys entities
total correct
total predicted
num predicted
true count
entity extractor results printer
count mention types
count name relations
count adjacent mentions
print counter
convert ace event mention
convert ace relation mention
convert ace entity mention
entity counts
adjacent entity mentions
relation counts
name relation counts
event counts
mention type counts
ace version
version
ace file
ace filename
sentences from file
ace document
entity mention map
event mentions
ace entity mention
coref id
entity id
converted mention
ace relation mention
ace event mention
entity map
roles
role
converted args
anchor
anchor object
arg names
ext start
ext end
head start
head end
ace reader
ace event mention argument
get args
get roles
set anchor
get anchor
get min token start
get max token end
m roles to arguments
m parent
m anchor
extent
earliest token start
latest token start
ace event mention
match exception
zero or one
zero or more
one or more
range not
has apostrophe block
count new lines
is url
is email
is sgml
is slash date
is digit seq
tokenize to words
tokenize to word tokens
postprocess
normalize case
get start
get new line count
set new line count
m abbreviations
max_multi_word_size
dot
dotdot
apostrophe
slash
underscore
comma
dotcomma
quotes
double_quotes
lrb
rrb
lcb
rcb
greater
lower
ampersand
http
white_space
upper
sign
fullnum
decnum
punc
letters
block
acronym
loose_acronym
paren
htmlcode
email
domain_email
small_url
underscoreseq
list_bullet
phone_part
digitseq
recognised_pattern
sgml pattern
slash date pattern
url pattern
email pattern
digit seq pattern
s10
previous end match
crt match
end match
start match
token1
token2
result with abs
conc
token list
m abbrev set
norm words
m start
m new line count
cached tokens
cached position
tokenize and segment sentences
word token to ace token
sentence final punc
sentence final punc set
a sentence final punc
filename prefix
current sentence
quote count
converted token
quote token
word token
ace sentence segmenter
to xml
m subtype
m modality
m tense
m mentions
nil_label
modality
which
ace relation
get extent
get head token position
set ldctype
get ldctype
add relation mention
get relation mentions
add event mention
get event mentions
detect head token
m ldctype
m head token position
m relation mentions
m event mentions
ldctype
ace entity mention
load gazetteers
is location
is first name
is last name
is trigger word
load proximity classes
get literal
get case
get suffixes
get chunk
get nerc
get byte offset
get byte start
get byte end
get raw byte offset
get raw byte start
get raw byte end
set massi class
get massi class
set massi bbn
get massi bbn
set massi wnss
get massi wnss
remove spaces
detect case
extract suffixes
adjust phrase positions
m literal
m case
m suffixes
m lemma
m pos
m chunk
m nerc
m byte offset
m raw byte offset
m sentence
m massi class
m massi bbn
m massi wnss
words
lemmas
others
prox_classes
proximity_class_size
loc_gaz
first_gaz
last_gaz
trigger_gaz
sgml_pattern
prox file name
case_other
case_allcaps
case_allcapsordots
case_capini
case_incap
case_alldigits
case_alldigitsordots
is all caps
is all caps or dots
is initial cap
is in cap
is all digits
is all digits or dots
suffixes
suf
nerc
offset to subtract
ace token
set prefix
get prefix
get entity mentions
get all entity mentions
get all relation mentions
get all event mentions
get key set entities
get entity mention
add entity mention
get relation mention
get event
add event
get event mention
get sentences
set sentences
tokens with byte span
match char seqs
parse document
construct sentence relation mentions
same chunk
is chunk head
find chunk end
find chunk start
count verbs
count commas
read raw bytes
read predicted entity boundaries
make char seq
make entity
m prefix
m source
m entities
m entity mentions
m sentence entity mentions
m relations
m sentence relation mentions
m events
m sentence event mentions
m tokens
m sentences
m raw buffer
m log
ent keys
rel keys
do print
m token
event keys
xml_ext
orig_ext
use predicted boundaries
true cased file name
entity keys
sent ents
crt
sent rels
sent events
ace version
left chunk
left end
right start
entity id
eid
cseq
emid
entm
ace document
get modality
set modality
getm polarity
setm polarity
get genericity
set genericity
get tense
set tense
m polarity
m genericity
genericity
ace event
get content
to xml short
m content
ace mention argument
m extent
ace mention
parse char seq
parse entity mention
parse relation mention
parse event mention
refid
doc element
ace doc
entity count
mention1
argv
ace dom reader
ace relation mention argument
get first arg
get last arg
get lexical condition
m lexical condition
m arguments
ace relation mention
get token start
get token offset
m text
m token offset
ace char seq
get id
append offset
m id
ace element
set class
get classs
m class
ace entity
get entity type for tag
use_sub_types
entity tag for ner
roth entity extractor
get normalized nertag
read sentence
get index by object equality
line iterator
warned ner
num blank lines seen
index to entity mention
current line
entity1
entity2
relation mention
extent span
arg root
arg words
arg tree
roth conll04reader
mention factory
path counts
singleton correct
singleton predicted
singleton actual
rel1
rel2
prediction1
prediction2
ent comp
type comp
prediction comp
path count1
path count2
rel comp
type1
type2
roth results by relation
rel comp
get head token start
get head token end
set head token span
set head token position
get syntactic head token position
get syntactic head token
get syntactic head tree
head includes
label equals
text equals
sort by head span
make unique id
head token span
syntactic head token position
object id
head span
other ent
use sub type
mention_counter
entity mention
comp by head
shuffle sentences
entity mentions to core labels
sentence entity mentions to core labels
add sentences
deep mention copy
sentence deep mention copy
get relations
get all relations
get all unrelated relations
add entity mentions
add relation mentions
add event mentions
prettify
get text content
tokens and nelabels to string
dataset to string
update offsets
update offsets in core labels
excelify
read sentences from file
annotations to skip
use bio
labeled sentence
add answer annotation
mention types to use
new sents
ents
rels
evs
matching relation mentions
check existing
non relations
sent entities
sent relations
annotation utils
args match
set args
get entity mention args
get arg names
set arg names
is negative relation
get first syntactic head position
get last syntactic head position
replace gold args with predicted
remove argument
remove arguments
printable object
filter unrelated relations
create unrelated relation
is unrelated label
unrelated
input args
argpos
gold ent
new arg
arg to remove
remove parent
this event
args to remove
new arg names
relation mention
event to event mentions
event
construct entity mention
entity mention factory
reset arguments
remove from parents
get modification
set modification
get single parent
add parent
add args
merge event
event modification
discard same arg different name
my arg
my arg name
old type
event mention
machine reading annotations
entity mentions annotation
relation mentions annotation
all relation mentions annotation
event mentions annotation
document id annotation
document directory annotation
dependency annotation
trigger annotation
construct relation mention
relation mention factory
entity to entity mentions
from values
expand to include
to inclusive
to exclusive
overlaps
overlap
from pair
from pair one indexed
union
val1
other span
span a
span b
get object id
get document id
get extent token start
get extent token end
set extent
get extent string
get sub type
sort by extent
get full value
concatenate types
attribute map
set type probabilities
get type probabilities
probs to string
sub type
extent token span
type probabilities
type_sep
t1toks
t2toks
unique types
nil label
extraction object
comp by extent
relation to relation mentions
sent copy
extraction data set
set relation mentions
set event mentions
set text content
set entity mentions
document id
nonrel
extraction sentence
mutable gold
mutable output
list1
alignable
sent1
results printer
compare sentences
set mode
get index and count
m index
m count
m name
m create
m dict
m inverse
should throw
nil_value
string dictionary
index and count
get child by name
get children by name
get child by attribute
get child by name and attribute
attribute name
attribute value
attribs
attribute
sxe
pce
dom reader
is punctuation label
no punctuation head finder
find non whitespace
find whitespace
normalize quotes
tokenize with quotes
quotify
simple tokenize
postprocess sentence
make annotation from given nertag
make annotation from all nertags
not bio
make entity mention
make entity mention identifier
run test set
set annotations to skip
save co nllfiles
save co nll
labeled sentence to string
annotation for word
save_conll_2003
gazetteer location
entity mention factory
use nertags
extracted entities
last type
lastne tag
ent id
unannotated labels
annotated labels
expected label
expected answer
already bio
my docid
prefer default gazetteer
print ner
basic entity extractor
print results internal
max_label_length
gold sentence index
extractor sentence
extractor relations
extractor relation
prediction count
count gold labels
predicted actual
numcorrect
relation extractor results printer
valid label
nil label validator
indicator
span between mentions
with mentions positioned
dense features
surface features
relation specific features
train multinomial classifier
train_file
model_file
sgd
feature_threshold
sigma
top_employee_triggers
feature template
subj before obj
simple sentence
lemma span
pos span
distance bucket
num commas in span
num quotes in span
paren parity
interceding nertags
subject head
object head
depparse path
appos chunks
num as int
minimizer factory
train accuracy
train examples
kbpstatistical extractor
rulesforrel
rules for rel
kbpsemgrex extractor
strip corporate titles
no special chars
more canonical mention
first name match
same entity without linking
near exact entity match
approximate entity match score
cluster entity mentions
best entity mention
create canonical mention map
canonical mention map from entity mentions
ner_person
ner_organization
corporate_suffixes
is all lower case
potential canonical mention
potential canonical mention text
entity mention start
potential canonical mention start
first name one
first name two
em one
em two
match score
higher gloss
lower gloss
higher toks
lower toks
matched higher toks
matched lower toks
higher tok
higher tok no special chars
does match
lower tok
lower tok no special cars
wrapped entity mentions
entity mention clusters
new em
cluster match
em cluster
cluster em
core map entity mention clusters
core map cluster
core em
entity mention cluster
cluster entity mention
kbpbasic spanish coref system
add entity to entities array
extract entity
other occurrences
word doc
orig class
raw tag
old raw tag
old parts
old entity
start position
preset answer
create nerclassifier combiner
applies numeric classifiers
copy answer fields to nerfield
recognize number sequences
finalize annotation
read regexner gazette
apply_numeric_classifiers_default
apply_numeric_classifiers_property
apply_numeric_classifiers_property_base
ner_language_default
ner_language_property
ner_language_property_base
use_preset_ner_property
default value
nsc props
disk use sutime
disk apply numeric classifiers
default_pass_down_properties
pass down properties
return ncc
ncc
nerclassifier combiner
subject gloss
subject link
subject lemma gloss
object gloss
object link
object lemma gloss
relation lemma gloss
relation head
confidence gloss
subject token span
relation token span
object token span
is prefix be
is suffix be
is suffix of
as dependency tree
as sentence
to qa srl string
to reverb string
canonical subject
canonical object
prefix be
suffix be
suffix of
to min
to max
longest chunk
longest chunk start
this chunk
this chunk start
ordered sentence
default index
subj index
relation index
obj index
subj index end
relation index end
obj index end
source tree
with tree
with link
read file
cols
fix location
uni prior
set suffix
set domain
describe distsim lexicon
dist sim annotate
dehyphenate
greekify
is name case
no upper case
read gazette
make generic key cache
generate slash hyphen features
features cp2c
features cp3c
features cp4c
features cp5c
features cp cp2cp3cp4c
features cp cn c
occurrence patterns
init gazette
collection
terry koo
word class
ret str
ordinal pattern
ordinal end pattern
word to gazette entries
word to gazette infos
infos
generic annotation keys
gen key
last names
title pattern
title pattern2
split slash hyphen words pattern
frag suffix
word suffix
p word
n word
c shape
p shape
n shape
lem
plem
nlem
beg
p gaz annotation
n gaz annotation
c gaz annotation
prev vb
next vb
len m1
g info
g loc
c ds
p ds
p2shape
p2word
p3word
p4word
p5word
jump
gazette file
communicate with nerserver
env_debug
asc
close on blank
load jar file
nerserver
nerclient
right scan finds money word
use_sutime_default
use_sutime_property
use_sutime_property_base
sutime_property
number_tag
date_tag
time_tag
money_tag
ordinal_tag
percent_tag
currency_word_pattern
percent_word_pattern1
percent_word_pattern2
date_pattern1
date_pattern2
date_pattern3
date_pattern4
date_pattern5
time_pattern1
chinese_and_arabic_numerals_pattern
date_age_localizer
currency_words_values
date_words_values
date_words
time_words_values
time_words
token sequence
chinese number sequence classifier
finalize classification
classify with sutime
align sentence
build sentence from tokens
build text
run sutime
money and percent recognizer
ordinal recognizer
change left to right
change right to left
transfer annotations
copy core label
classify old
left scan finds weight word
time sentence
character offset start
adjust character offsets
token char start
text annotation
src list
force copy
dst list
adjustment
orig length
src tokens
start offset
month_pattern
year_pattern
day_pattern
date_pattern
time_pattern
time_pattern2
am_pm
currency_symbol_pattern
ordinal_pattern
army_time_morning
generic_time_words
percent_word_pattern
percent_symbol_pattern
number sequence classifier
contains valid pos
find start index
default_valid_pos
search start
current type
regex nersequence classifier
joining two entities
splitting two entities
appending entity
prepending entity
adding singleton entity
removing end of entity
removing beginning of entity
no change
new entity
org
per
loc
dem1
dem2
dem3
p10
p11
p13
dem4
p14
p15
p16
p17
dem5
p18
p19
p20
p21
dem6
p23
p24
p25
dem7
p26
p27
p28
p29
dem8
p30
p31
p32
p33
extract combination mode
extract combination mode safe
load classifiers
load classifier from path
merge documents
merge two documents
examine crf
base classifiers
normal
high_recall
default_combination_mode
combination_mode_property
init props
init load paths
load path1
load path2
new cm
num classifiers
new crf
new cmm
preset asc
labs
base documents
base labels
seen labels
base classifier
main document
aux document
aux labels
inside aux tag
aux tag valid
prev answer prob
aux iterator
w main
main answer
w aux
aux answer
aux answer prob
inside main tag
base outputs
combination mode string
return cc
crf name or index
default reader and writer
plain text reader and writer
reinit
get known lcwords
make reader and writer
make plain text reader and writer
classify sentence
preprocess tokens
classify sentence with global information
get sampler
draw sample
classify kbest
get viterbi search graph
classify raw
classify file
classify object bank
classify to string
classify with inline xml
classify to character offsets
segment string
make object bank from string
make object bank from file
make object bank from files
make object bank from reader
print probs documents
output calibration info
classify stdin
classify files and write answers
classify and write answers kbest
classify and write viterbi search graph
write answers
count results
count results segmenter
print prline
load classifier no exceptions
print feature lists
print feature lists helper
ind feature factory
reader class name
sample array
answer field
best sequences
kth
new fl
out format
text document reader and writer
doc output
prev entity type
prev entity
guessed answer
string print writer
file as array
orig files
output scores
thread completion counter
thread processor
completed no
lattice writer
vsg writer
cut_label
written num
feats list
sorted feat list
recur normalize literal integer string
composite at unit if exists
normalize literal decimal string
normalize month or day
normalize year
normalize date string
pretty number
quantity unit to values
multi char currency words
one char currency words
full digit to half digit
year modifiers
month day modifiers
literal_decimal_point
arabic_numbers_pattern
chinese_literal_number_sequence_pattern
chinese_literal_decimal_pattern
chinese_date_numerals_pattern
chinese_and_arabic_numerals_pattern_wo_ten
year_modifier_pattern
month_day_modifier_pattern
basic_dd_pattern
basic_mmdd_pattern
basic_yyyymmdd_pattern
english_mmddyyyy_pattern
relative_time_pattern
birth_decade_pattern
docdate
not matched
currency word
decimal index
decimal value
integer value
ctx
context year
yearcandidate
ctxdate
ctxyear
ctxmonth
ctxday
chinese quantifiable entity normalizer
output freq
dos
result storing float monitor
norm2
derivative at
last x
a x
abstract caching diff float function
shut up
get objective
try eta
get norm
rescale
sayln
xnorm
default_num_passes
num passes
b size
default_tuning_samples
tuning samples
wnorm
sample batch
sample index
seta
sobj
besteta
bestobj
totest
phase2
function tolerance
total samples
have_max
pass
total value
last value
iteration cutoff
minimizer one
minimizer two
hybrid minimizer
increment random
scale up
clear cache
decrement batch
increment batch
get batch
stochastic ensure
get hdot vfinite difference
hdot vat
last derivative
has new vals
recalculate prev batch
return previous values
last batch size
last batch
this batch
last xbatch
last vbatch
last element
hdot v
grad perturbed
x perturbed
cur element
all indices
rand generator
shuffled array
none specified
random with replacement
random without replacement
ordered
shuffled
num times
to scale up
sample method
finite difference step size
ratio
cur derivative
h inv
prev value
abstract stochastic caching diff function
set batch size
take step
value pow
lam
c pos def
print min max
gains
init gain
smd
ms per test
dfunction
max var
grads
tune fixed gain
set max time
update diag
update diag bfgs
update diag min err
get diag
y list
s list
fixed gain
pair mem
a max
fixed start
xtest
f opt
to continue
this gain
s ds
new diag
lam star
skew
say
hess sample size
sgd
qn info
sgdto qnminimizer
set hess sample size
suppress test prompt
set terminate on eval improvement num of epoch
get prior
pospart
compute learning rate
update x
use eval improvement
use avg improvement
best eval so far
x best
no improve itr count
rho
prev grad
prev delta x
sum delta xsquare
hess size
to terminate
curr eval
lasso
ridge
gaussian
ae lasso
g lasso
sg lasso
a score
current rate
prev g
grad diff
delta xt
real update
test update cache
current rate cache
b cache
g value
w value
test update
old obj val
eval score
obj delta
num of non zero
num of non zero group
g size str
gradients
test update squared sum
current lambda
test update norm
g feature indices
test update abs sum
group has non zero
non zero count
b squared sum
b norm
previous val
average improvement
selected data
prime factors
get test batch size
test sum of batches
test derivatives
test condition number
get variance
list to file
array to file
eps
test batch size
this func
approx grad
full grad
hv fd
cur grad
grad fd
diff norm
diff value
full value
approx value
diff grad
max grad diff
max hv diff
generator
fctr
fctr index
dvsr
factors
factor count
tmp sample method
tmp method
compare hess
diff hv
max seen
min seen
this v
this x
this vhv
is neg
is pos
is semi
full hx
this hx
this grad
hx list
full norm
hess scale
sim delta
rat delta
sim mean
rat mean
sim s
rat s
this norm
rat
sim var
rat var
batch sizes
var result
this list
this array
stochastic diff function tester
gradient check
random initial
get derivative
f evaluations
num of checks
num of random checks
diff threshold
diff pct threshold
x len
saved deriv
indices to check
bad indices
old x
plus val
minus val
app deriv
calc deriv
pct
abstract caching diff function
copy array
array to string
fabs
fmax
vector of
mnbrak
dbrent
line minimize
set iteration callback function
iteration callback function
silent
num to print
simple gd
check simple gdconvergence
itmax
reset frequency
temp vector
glimit
tiny
abc
ulim
db verbose
tol1
tol2
ok1
ok2
olde
one dim
bracketing
xmin
d function
dimension
simple gdstep
fp2
monitor return
dgg
gam
xixi
cgminimizer
one dim diff function
triple
gain schedule
tune double
copy pair
tune gain
tune batch
output frequency
new grad
grad list
info file
to smooth
smoothed
info name
b start
x test
b opt
g opt
cur val
mem monitor
mem string
memory evaluator
set m
plus and const mult
compute dir
clear stuff
ro list
mmm
y dot y
set old options
set robust options
terminate on relative norm
terminate on numerical zero
terminate on average improvement
terminate on max itr
use min pack search
use backtracking
use diagonal scaling
use scalar scaling
was successful
set eps
set tol
monitor x
how long
get best
get rho
get s
remove first
free
apply initial hessian
new qninfo
evaluate function
project owl
l1norm owl
constrain search dir
pseudo gradient owl
line search backtrack owl
line search backtrack
line search min pack
get step
fevals
max fevals
its
nfsec
ftol
gtol
a min
p66
bracketed
preset info
no history
lambda owl
use ave improvement
use relative norm
use numerical zero
use max itr
max itr
iter callback function
terminate_maxevals
terminate_relativenorm
terminate_gradnorm
terminate_averageimprove
continue
terminate_evalimprove
terminate_maxitr
backtrack
minpack
scalar
ls opt
scale opt
use robust options
g norms
func evals
g norm init
relative tol
g norm last
x last
mon
memory conscious
g norm
rel norm
newest val
evals size
best ind
new s
new y
n si
n yi
new si
new yi
min d
max d
max function evaluations
raw grad
has na ndir
has na ngrad
new point
completion time
dfunc
use
orthant
dgtest
norm grad in dir
xtrapf
infoc
stage1
g test
new pt
best pt
end pt
stp min
stp max
f test
stpc
stpq
stpf
sign g
theta_s
qnminimizer
surprise convergence
max evaluations exceeded
record
qninfo
scalar qninfo
diagonal qninfo
calculates hessian vector product
parse method
gradient only
algorithmic differentiation
incorporated finite difference
external finite difference
obj func calculates hdot v
objective function calculates hdot v
result storing monitor
gain low
gain high
dump memory
discretize compute
golden mean
golden_ratio
golden_section
geometric
flow
fhigh
old y
search right
best point
best val
incr
num points
golden section line search
get sample
lambda l1
lambda l2
soften
last updated
time step
total obj value
prevrate
sgs value
currentrate
testupdate
last update time step
idleinterval
trunc
trunc2
realupdate
abstract stochastic caching diff update function
get error
evaluate cmd
cmd split pattern
err string
out sw
err sw
cmd evaluator
add vertex
get outgoing edges map
get incoming edges map
remove edges
remove vertex
remove vertices
get num vertices
get outgoing edges
get incoming edges
get neighbors
contains vertex
is neighbor
get all vertices
get all edges
remove zero degree nodes
get shortest path
get shortest path edges
convert path
get in degree
get out degree
get connected components
delete duplicate edges
incoming edge iterator
incoming edge iterable
outgoing edge iterator
outgoing edge iterable
edge iterator
edge iterable
prime iterator
topological sort
topological sort helper
outer map factory
inner map factory
edges copy
outgoing map
incoming map
outgoing list
incoming list
found out
vertices
source entry
dest entry
parent map
child map
children map
node2
direction sensitive
node iterator
outgoing
vertex2
deduplicated data
reverse edges
vertex iterator
connection iterator
current source
current target
current edge
start vertex
next connection
next vertex
temporary
permanent
neighbor map
get tail
bfs
ccs
vertices left
unsettled nodes
alt
dijkstra shortest path
scene graph image bounding box
from jsonobject
to jsonobject
bounding box
img
label arrays
bounding box obj
scene graph image
bbox
lemmata list
scene graph image object
attribute gloss
attribute lemma gloss
predicate
region id
subject id
text list
attribute gloss list
subject gloss list
other obj
scene graph image attribute
label from string
label to string
contains lemma
find word
find lemma
get semantic graph
grammatical structure to json
separator_pattern
dep triplets
idx2node
dep triplet
predicate gloss
predicate lemma gloss
subject gloss strings
object gloss strings
predicate gloss strings
scene graph image relationship
read from json
to json
add attribute
add relationship
remove region
regions
relationships
cleaner
images
scene graph image
get basic semantic graph
get enhanced semantic graph
token strings
scene graph image region
entity classifier path
eval file prefix
embeddings path
pred writer
pred eval file path
gold eval file path
object scene graph parser
find words in between
lemma_bow
word_bow
tree_feat
idx1
idx2
shortest path
bo wexample
load images
train images
id parts
img id
get predicate
count double num mods
subj_pred_obj_triplet_pattern
subj_pred_pair_pattern
copular_pattern
adj_mod_pattern
adj_pred_pattern
pp_mod_pattern
poss_pattern
agent_pattern
acl_pattern
main pred
subj pred patterns
additional case marker
nummod_pattern
double matches
load pipeline
bfs npsearch
resolve pronouns
dep_model
get training examples
entity classifer
enforce subtree
include all objects
none_relation
is_relation
default_entity_model_path
reg_strength
entity model
training file
sample neg
neg dataset
entity pairs
relation triples
iw1
iw2
entity pair
entity model path
interactive
f1sum
bo wscene graph parser
scene graph data extractor
print most discriminative syntactic patterns
path to model
linear classifier
positive patterns
negative patterns
count all
filter regions
attribute counter
relation counter
entity counter
region count
filter count
img count
removed entire img count
removed partial img count
scene graph image filter
predict entity
compound word
compound lemma
entity classifier
pron pairs
first ref
resolver
dcoref pronoun resolver
o reln
scene graph relation
scene graph core annotations
indices annotation
gold entity annotation
predicted entity annotation
scene graph entitiy annotation
compound word annotation
compound lemma annotation
open ieparser
has attribute
remove attribute
to jsonstring
other node
scene graph node
word_pos_idx_pattern
pron
pron idx
sent score
coref pairs
tagged tokens
tagged token
c pairs
c pair
c pair parts
mention idx
abstract pronoun resolver
to smatch string
gold triplets
predicted triplets
numerator
pred string
gold string
node1idx
node2idx
predicted objects
subject lemma
object lemma
pred subj
pred obj
scene graph evaluation
scene graph relation triplet
init pipeline
abstract scene graph parser
extract attributes
entity_pattern
attribute_patterns
entity extractor
crfdata extractor
graphs file
tokenized sentence
generate alignment data
contains null
find closest pair
get relation triples
tags compatible
min distance
subj indices
obj indices
obj idx
attr contains null
subj result
attr result
reln contains null
obj result
lemma gloss
is attr
e min idx
e min score
e dist
vec1
min idx
min dist
vec2
lbl1
lbl2
scene graph sentence matcher
get common ancestor
in same sub tree
get closest indices
reject
idcs1
idcs2
scene graph utils
get tokenizer pipeline
extract all attributes
cleanup image
remove final punctuation
remove determiners and numbers
split attribute conjunctions
trim function words
final_punct_regex
initial_det_regex
final_det_regex
trailing_number_regex
all_attributes
tokenizer pipeline
new attrs
should split
attr2
sentence ann
scene graph image cleaner
process quanftification modifiers
resolve plurals
copy node
collapse compounds
collapse particles
enhance
quant_mod_pattern
quant_mod_pattern2
quant_mod_pattern3
pronoun resolver
plural_subject_object_pattern
plural_subject_pattern
plural_other_pattern
nummod
qmod
pred copy
subj copy
obj copy
subj edge
obj edge
compound
resolved pronouns
other attr
scene graph attribute
relation list sorted
node list sorted
get or add node
pcfg_model
predicted img
object ids
new region
attr copy
reln copy
ground truth converter
compose
identity function
unapply
functions
regex string filter
dereference
report nano
to seconds string
to milli seconds string
restart
stop
doing
start doing
end doing
milliseconds_to_seconds
second_divisor
millisecond_divisor
timing
adjust upwards
adjust
is alpha balanced
balance
rotate up
right rotate
left rotate
get leftmost node
get rightmost node
add non overlapping
add non nested
get overlapping
contains interval
get non overlapping max score
get non nested
default alpha
threshold depth
cur iter
left size
right size
orig right
rightmost
stop at
tree node
left max
right max
median at
old root
old left right
old right left
overlapping
contains target function
add ok
last match key
best non overlapping
item interval
bestk
item score
bestj
with match score
runtime interrupted exception
cross
symmetric diff
intersection
intersects
power set
assert equals
old set
pow1
second name
output shared
error message
first extras
second extras
shared
sets
get four dimensional map
first key set
second key set
third key set
fourth key set
fifth key set
key3
key4
key5
to interval
to valid interval
get relation flags
restrict flags
has unknown
comp11
comp22
comp12
comp21
f11
f22
f12
f21
remove mapping
all values
delta copy
treat collections as immutable
empty value
current collection
new collection
need to add
delta map
escape string
exists table
get counts
populate tables in sql
get total count
get1gram rank
close connection
set dbname
populate tables
ngrams to populate
google ngram_hostname
google ngram_dbname
google ngram_username
tablename prefix
escapetag
existing tablenames
dbname
tablename
ngram
stmt
isresult
types of phrases
google ngrams sqlbacked
load by reflection
reflection loading
reflection loading exception
third
fourth
set first
set second
set third
set fourth
make quadruple
as list
pretty log
quadruple
another
channels
read name
read java identifier
read left paren
read right paren
read dot
read white space
unread
is eof
is white space
is punct
is left paren
is right paren
is dot
get three dimensional map
original map
removed value
delta result
delta c
original c
filter1
filter2
iter2
contains ignore case
looking at
map string to array
map string to map
regexes to patterns
regex groups
string to set
join words
join fields
join multiple fields
join with original white space
split keep delimiter
split lines keep newlines
split on char
split fields fast
value split
pad or trim
pad left or trim
pad left
trim
trim with ellipsis
repeat
file name clean
nth index
truncate
args to map
args to properties
prop file to properties
string to properties
check required properties
print to file
print to file ln
parse command line arguments
strip non alpha numerics
strip sgml
print string one char per line
split on char with quoting
longest common substring
longest common contiguous substring
penn posto wordnet pos
get short class name
column string to object
object to column string
capitalize
is capitalized
to title case
is title case
is all upper case
search and replace
make htmltable
make text table
make ascii table cell
to ascii
to csvstring
chomp
get base name
is alpha
is numeric
is alphanumeric
get not null string
is null or empty
resolve vars
args to properties with resolve
prop file to linked hash map
get ngrams
get ngrams from tokens
get ngrams string
get character ngrams
levenshtein distance
unescape html3
decode array
decode map
expand environment variables
log invocation string
contains json escape
escape json string
index of regex
prop
props
properties
args
arguments
s prime
map arr
to string func
default_tostring
default field value
field glue
new pieces
token chars
trimmed out
current field
last split
out i
value regex
v pat
s pat
total chars
slen
max width
smallest digit
biggest digit
num digits
num flag args
flag args
new flag arg
old num args
max flag args
props str
div loc
required props
required
print ln
parse numbers
sgml matcher
char to escape
s_i
t_j
pad right
fld
l_1
l_2
elts
last elt
vr value
existing args
flag arg
words str
ngram size
diacritical marks pattern
radix
first char
entity value
chrs
html_escapes
html unescape lookup map
encoded
quote close char
on key
env value
subexpr
escape letters
string utils
append to buffer
result buffer
command line
inside quotes
command line tokenizer
output file handle
should run
stream gobbler
fill field
file path to class
is ignored
get visible classes
scrape fields
thread root class
buffer string
fill options impl
fill options
update properties with options
list options
ignored_jars
bootstrap_classes
option classes
access state
to set
cp entry
path sep
jar
jar entry
ensure all options
is bootstrap
all classes
class2object
my super
can fill
some option filled
some option found
raw key str
last dot index
all properties
bootstrap map
visible classes
subcomponent
subcomponent name
without prefix
prefix string
anns
arg opt
options classes
main class
longest option name
longest option type
option pair
options class
argument parser
as map
dump core map
dump core map to string builder
to be merged
coremaps
value key
references
raw key
core maps
remaining capacity
compared
get copy
get middle
get target2
trgt
trgt2
n t
int quadruple
get two dimensional collection valued map
short value
byte value
inc value
another mutable integer
this val
another val
mutable integer
get max size
set max size
for each
remove if
spliterator
parallel stream
worst
insert cost
delete cost
substitute cost
transpose cost
allow transpose
source length
target length
s pos
t pos
bscore
source str
target str
edit distance
get collection valued map
collection of values
backer
new array list
new linked list
new stack
new binary heap priority queue
new tree set
get hash set class
get hash set size constructor
get hash set collection constructor
new hash set
get hash map class
get hash map size constructor
get hash map from map constructor
new hash map
new identity hash map
new identity hash set
new weak hash map
new concurrent hash map
new tree map
new concurrent hash set
new pair
new triple
new interner
new synchronized interner
new weak reference
hash_set_property
hash_set_classname
hash_set_class
hash_set_size_constructor
hash_set_collection_constructor
hash_map_property
hash_map_classname
hash_map_class
hash_map_size_constructor
hash_map_from_map_constructor
load factor
concurrency level
mutex
generics
null value
kv entry
first hash code
second hash code
this1
this2
this c
other1
other2
unchecked cast
noop
mk tarray
mk t2darray
sorted if possible
klass
erasure utils
as int array
as double array
make list
as set
union as set
diff as set
load collection
get map from string
contains object
remove object
is sub list
to vertical string
compare lists
get list comparator
get ngrams
get prefixes and suffixes
merge list
merge list with sorted matched
merge list with sorted matched pre aggregated
unique nonhashable objects
contains any
partition into folds
train test folds for cv
modes
transform as set
transform as list
filter as list
get all
concat iterators
iterator from enumerator
iterable from enumerator
item class
item constructor
key c
value c
size1
size2
padding symbol
include prefixes
include suffixes
prefixes and suffixes
ioobe
matched intervals
nested list
custom hasher
hashes to objects
fold num
train test pairs
split num
sorted counts
highest count
iterators
last iter
lst_
collection utils
hash map factory
identity hash map factory
weak hash map factory
tree map factory
hash_map_factory
identity_hash_map_factory
weak_hash_map_factory
tree_map_factory
linked_hash_map_factory
array_map_factory
concurrent_map_factory
null safe natural comparator
null safe compare
get string representation comparator
get boolean array comparator
get array comparator
two
comparators
remove last entry
get entry
make entry
heapify up
heapify down
heapify
get first
remove entry
get last entry
relax priority
decrease priority
change priority
index to entry
key to entry
entry a
entry b
index a
index b
parent entry
best entry
left entry
right entry
e key
last entry
sorted list
max keys to print
key i
gap encode
gap encode list
gap decode
gap decode list
delta encode
delta encode list
delta decode
delta decode list
bit set to byte array
byte array to bit set
remove at
equal contents
as immutable set
fill
to double
as primitive double array
as primitive int array
to primitive
to double array
compare arrays
get sub list index
sub array
compare boolean arrays
encoded list
curr byte
gap encoded
ints
getting size
gap
delta encoded
getting size1
getting size2
bit set
new array
dim1size
dim2size
new arr
value for null
first as list
second as list
tofind
matching function
last unmatched index
ar2
startindex inclusive
endindex exclusive
array utils
length_gt_comparator
length_lt_comparator
endpoints_comparator
nested_first_endpoints_comparator
contains_first_endpoints_comparator
length_endpoints_comparator
int triple
as character array
unicode block string of
is punctuation
is symbol
is control
c type
characters
make triple
is true
is false
to boolean
to boolean or null
not
value for unknown
bool
trilean
put into value hash set
put into value array list
put into value collection
invert set
sorted entries
to string sorted
remove keys
composed map
inverted map
entries list
sorted properties
removekeys
pre append
post append
key val separator
item separator
list values
maps
process multiple inputs
leftover args
din
dout
input array
output array
process protobuf request
get global
set global
global intern
intern all
old interner
ensure list
get or default
begin
my words
other words
array string filter
analyzed
analyzed_no_position
analyzed_not_stored
not_analyzed
not_indexed
lucene field type
lazy set
get and set
compare and set
weak compare and set
get and add
add and get
current val
next val
atomic double
get factory
set default return value
default return value
set count
increment count
decrement count
log increment count
atomic
build thread pool
get processor
poll
call
submitted item counter
returned item counter
order results
output queue
thread pool
idle processors
processor list
processor id
proc list
proc id
item id
job
destroy threadpool
item index
other queue
global mutex
delegate
interned
join with timeout
shutdown now
await termination
new task for
leftover
orphans
runnable
task
my callable
add to index
objects list
is locked
unlock
save to writer
unknown_id
default_initial_capacity
item2index
index size
index2item
simulate gc
get if defined
is garbage collected
is cache
impl or null cache
impl or null
defined element
link elements
find element
object to element
object set
get input stream
get output stream
in stream
bytes read
byte stream gobbler
identity hash map
value iterator
get first key
get second key
mf1
mf2
new mf1
new mf2
tdm
entry iterator
first key
second key
outer iterator
inner iterator
outer entry
inner entry
write int to byte arr
write long to byte arr
write float to byte arr
write double to byte arr
write boolean to byte arr
write char to byte arr
write short to byte arr
write ustring to byte arr
write astring to byte arr
byte arr to int
byte arr to short
byte arr to float
byte arr to double
byte arr to long
byte arr to boolean
byte arr to char
byte arr to ustring
byte arr to astring
string uto byte arr
string ato byte arr
int arr to byte arr
long arr to byte arr
boolean arr to byte arr
char arr to byte arr
float arr to byte arr
double arr to byte arr
short arr to byte arr
u string arr to byte arr
a string arr to byte arr
byte arr to int arr
byte arr to long arr
byte arr to boolean arr
byte arr to char arr
byte arr to short arr
byte arr to float arr
byte arr to double arr
byte arr to ustring arr
byte arr to astring arr
save double arr
save float arr
read double arr
read float arr
shortflag
intflag
longflag
str len
byte off
byte count
string len
l arr
convert byte array
backing index
spillover index
backing index size
locked
backing iterator
spillover iterator
get pad
get wrapped list
same inner list
immutable keys
hashcode
hashkey
key hashcode
value hashcode
hashable core map
hashable core map exception
new array map
resize
entry array
old entry array
new capacity
m val
internal to string
current object
other object
accept filter
reject filter
collection accept filter
collection reject filter
and filter
or filter
add filter
not filter
switched filter
judgment
conjunction
fraction
filters
process path
path str
file path processor
set left pad size
set delim pad size
set use real labels
unique labels
get contingency
sort keys
gold marginal
guess marginal
get place holder
print table
mouse moved
on mouse over
invalidate
class_prefix
left pad size
delim pad size
use real labels
new pad size
tp_
fp_
tn_
fn_
conf table
guess p
gold p
comparable
place holder
guess i
label i
row count
selected cell
mouse handler
cell width
cell height
g2d
cell
bak
x offset
y offset
max diag
max offdiag
hsb
x center
y center
percent good
percent bad
array list factory
linked list factory
hash set factory
tree set factory
new empty collection
new singleton collection
array_list_factory
linked_list_factory
hash_set_factory
tree_set_factory
default size
put spi
get spi
remove spi
remove node spi
keys spi
children names spi
child spi
sync spi
flush spi
disabled preferences
get token strs
get main token strs
get main strs
is acronym impl
is fancy acronym
is fancy acronym impl
discard pattern
stopwords
main token strs
chunk1
chunk2
token strs1
token strs2
is acro
prev_index
acronym matcher
system root
user root
install
disabled preferences factory
run shell command
get pid
get pidno exceptions
get memory in use
get stack trace string
get timestamp string
error writer
output thread
error thread
out writer thread
err writer thread
error lines
pid
system utils
process exception
writer thread
process output stream
make pair
string intern
interned string pair
intern strings
first hash
second hash
pair2
grow
priorities
legal capacity
new elements
new priorities
left child priority
right child priority
loc1
loc2
temp priority
temp element
dbl fmt
num keys printed
clone pq
remove eldest entry
backing file
cache_entries
entries since last written
frequency to write
hits
puts
num entries
access order
use file params
eldest
safe document builder factory
get text content from tags from file
get text content from tags from file saxexception
get tag elements from file
get tag elements from file saxexception
get tag element triples from file
get tag element triples from file num bounded
get tag element triples from file saxexception
get tag element triples from file num bounded saxexception
get xml parser
get validating xml parser
strip tags
is breaking
read until tag
read and parse tag
unescape string for xml
escape xml
escape element xml
escape attribute xml
escape text around xmltags
find space
get first non null attribute from list
read tag
parse tag
read document from file
make better error string
fatal error
read document from string
dbf
built up
in tag
num included siblings
schema file
schema
breaking tags
map back
mark line breaks
xml escaping pattern
nbsp
is end tag
is single tag
attributes list
exception
xmltag
saxerror handler
has property
has property prefix
as properties
as string
print properties
get sorted entries
check properties
extract prefixed properties
extract selected properties
get dir path
get int
get long
get double
get bool
get int array
get double array
get string array
over write properties
no clobber write properties
props as json string
default name
keep prefix
key str
new str
kept properties
ovp
property name
supported properties
pname
pvalue
properties copy
json properties
properties utils
property
flush parents
record verdict
internal handle
signal start track
signal end track
signal shutdown
same message
max wait time in millis
num to force print
repeat semantics
will return
repeated record count
new record
reverse stack
is repeat
should print
current time
signal
is printing
new depth
time ended
track was nonempty
printing
last record
times seen
times printed
time of last printed record
suppress record
something printed
track count pending
lines omitted
last no numbers
current no numbers
repeated record handler
repeated record info
approximate repeat semantics
exact repeat semantics
queue task
release thread control
attempt thread control
attempt thread control threadsafe
root handler
clear handlers
get handler
capture system streams
restore system streams
logf
start track
force track
end track
start threads
finish thread
end threads
hide channels everywhere
format time difference
add child tree
to string helper
sort
force
supports ansi
rev concat
warn
fatal
runtime exception
fail
end track if open
end tracks until
end tracks to
thread and run
print channels
infof
debugf
warnf
errf
err
warn
force
stdout
stderr
real sys out
real sys err
handlers
title stack
threaded log queue
current thread
threads waiting
is threaded
control
thread id
to run
thread log queue
took lock
hopeless
active thread
backlog
capture out
capture err
clean pass
long queue entry
channel names
vis handler
channel
mili
sec
is unix
start_track
shutdown
end_track
to find
children iter
child on prix
child iter
last returned
to append
to pass on
timesstamp
channels sorted
exit code
have started
meta info lock
num pending
thread finished
num still pending
bold
dim
italic
underline
blink
cross_out
black
yellow
blue
magenta
cyan
more channel names
error
tasks
f i
the i
redwood
record handler tree
console handler
redwood channels
boolean log record handler
log b
check error
set error
clear error
printf
real stream
check for throwable
from throwable
char sequence
redwood print stream
dispatchable
default_channels
array copy
component class
entry counter
pretty logger
get source string and level
color channel
style channel
set color channels
format channel
write content
update tracks
queued tracks
track stack
channel separator char
left margin
min line count for track name reminder
missing open bracket
track color
channel colors
add random colors
track style
channel styles
backup source
source string
color channels
channel str
channel to string
cand color
cand style
until depth
top trace element
to str
cursor pos
content lines printed
printable channels
chan
last chan
was any channel printed
to print
was channel printed
time of end
child info
num elements printed
output handler
track info
should log channels
from java util logging
logging method
channel mapping
default channel
matching channel
has channel
contains message
matches message
java util logging handler
old channel name
new channel name
rerouted record
reroute channel
log record handler
publish
added redwood handler
old console handler
redwood handler
java util logging adaptor
redwood handler
get logger and level
logger and level
slf4jhandler
ansi code
to color
newline log formatter
propagate record
disjunctive mode
filter handler
restore
listen on channels
channel width
hide channels
show all channels
show only channels
reroute
branch
build chain
neat exit
standard
minimal
slf4j
debug level
info level
error level
java util logging
output handler
default file
match against
java util
hide debug
show only error
channels to hide
channels to show
collapse approximate
collapse exact
destinations
handler1
handler2
handler3
handler4
handler5
prop as obj
redwood configuration
handlers
show all
hide all
also show
also hide
show_all
hide_all
default state
delta pool
something seen
visibility handler
minimal setup
stanford redwood configuration
int uni
key set not null
compact
set capacity
to shorter string
to short string
initial_capacity
other keys
new keys
map keys
to string called
called set
created called set
shorter_string_charstring_start_size
shorter_string_max_size_before_hashing
what
what set
anno idx
equals called
other v
called map
created called map
hash code called
keys code
values code
key name
array core map
as sorted list
dumped
internal add
expected max size
ihs
nlp_data_variable
nlp_data_variable_prefix
nlp_data_home
javanlp_variable
javanlp_variable_prefix
javanlp_home
data file paths
runtime class not found exception
current candidate
advance candidate
has current candidate
current candidate is acceptable
skip unacceptable candidates
has current
ascending
descending
ascending_comparator
ascending
scored comparator
int array
get left as key
get right as key
remove left as key
remove right as key
values left as key
values right as key
entry set left as key
entry set right as key
contains left as key
contains right as key
i desc
m_left as key
m_right as key
tree set
hash set
add all keys
backing map
prepare
cast
take
flat map
zip
next pair
as array list
as hash set
as collection
queued
to drop
skipped
iterables
arrays
another mutable double
contains open
expand
includes begin
includes end
is interval comparable
compare interval order
to rel flags
add interval relation flags
extract relation subflags
check multiple bit set
check flag set
check flag exclusive set
get mid point
get radius
length endpoints comparator
length scorer
interval_open_begin
interval_open_end
equal
begin_meet_end
end_meet_begin
contain
inside
overlap
rel_flags_same
rel_flags_before
rel_flags_after
rel_flags_unknown
rel_flags_ss_shift
rel_flags_se_shift
rel_flags_es_shift
rel_flags_ee_shift
rel_flags_ss_same
rel_flags_ss_before
rel_flags_ss_after
rel_flags_ss_unknown
rel_flags_se_same
rel_flags_se_before
rel_flags_se_after
rel_flags_se_unknown
rel_flags_es_same
rel_flags_es_before
rel_flags_es_after
rel_flags_es_unknown
rel_flags_ee_same
rel_flags_ee_before
rel_flags_ee_after
rel_flags_ee_unknown
rel_flags_interval_same
rel_flags_interval_before
rel_flags_interval_after
rel_flags_interval_overlap
rel_flags_interval_inside
rel_flags_interval_contain
rel_flags_interval_unknown
rel_flags_interval_almost_same
rel_flags_interval_almost_before
rel_flags_interval_almost_after
rel_flags_interval_fuzzy
check1
check2
contains other begin
contains other end
check fuzzy
is fuzzy
length_scorer
callback function
fifth
set fifth
replace ascii
utf8equivalence function
shift left
get int tuple
concat
common len
integers
int tuple
get two dimensional map
another mutable long
mutable long
poll at most every
get max memory
get max available memory
get used memory
get used memory static
get used memory string
get system free memory
get system used swap
get system swaps per sec
parse fields
poll free
poll vmstat
system is swapping
max_swaps
last poll
poll every
free mem
used swap
swaps
accurate
used k
used m
split str
line nums
curr position
free lines
free positions
bri
gigabyte
default_poll_frequency
default_log_frequency
poll frequency
log frequency
outstream
peak
pmm
memory monitor
peak memory monitor
add to index unsafe
load from reader
to string one entry per line
unmodifiable view
load from file with list
indexes
semaphore
obj lookup factory
index lookup factory
hash index
same primitive
super distance
construct
create instance
create factory
check constructor
type2class
cast without knowing type
class params
direct super
super dist
interfaces
potentials
constructor params
distances
con index
accessible
to write to
decode
types to try
to try
at least
abstract to concrete collection map
meta class
class creation exception
constructor not found exception
remove last
extract min
decrease key
verify
object to entry
num swaps
min entry
temp heap
temp list
unprocess
fix quotes
maybe append one more
subst_chars
replace_substs
subst chars
replace substs
escape chars
replace escapes
has words list
dpre
notags
get mark line breaks
set mark line breaks
blocktags
block tags
just inserted newline
tag start index
tag end index
html doc
txt doc
normalize fractions
normalize currency
minimally normalize currency
remove soft hyphens
process cp1252misc
normalize amp
ascii quotes
latex quotes
unicode quotes
non cp1252quotes
handle quotes
handle ellipsis
handle dashes
penn normalize parens
cents_pattern
pound_pattern
generic_currency_pattern
cp1252_euro_pattern
one_fourth_pattern
one_half_pattern
three_fourths_pattern
one_third_pattern
two_thirds_pattern
single_space_pattern
non_word_remove_chars
ptb3ellipsis str
unicode ellipsis str
unicode
latex
not_cp1252
ptb3
escape forward slash asterisk
amp_pattern
single quote
double quote
ascii single quote
ascii double quote
left single quote
right single quote
left double quote
right double quote
probably left
unicode left single quote
unicode right single quote
unicode left double quote
unicode right double quote
left duck
right duck
quote style
ellipses style
dashes style
left_paren_pattern
right_paren_pattern
penn_left_paren
penn_right_paren
normalize parentheses
lexer utils
is token
to core map
dependencies_basic
dependencies_collapsed
dependencies_collapsed_cc
dependencies_alternate
pos_tags
ner_tags
doc_id
sentence_index
corpus_id
doc_char_begin
doc_char_end
gloss
record source
begin char
tsvsentence iterator
set keep empty sentences
set sentence final punc words
set escaper
set sentence delimiter
set tag delimiter
set element delimiter
plain
default_sentence_delims
input reader
sentence final punc words
sentence final followers
doc path
new tokenizer factory
sent delims
delim followers
split tag
next sent
next sent carryover
split regex
seen boundary
xml itr
original doc reader
plain itr
this sentence
print sentence lengths
xml element delimiter
s delim
sentence delims
num factory flags
suppress escaping
custom tokenizer
print original text
whitespace delims
doc preprocessor
print space
plain text iterator
xmliterator
from html
from plain text
remove whitespace
handle text
handle start tag
handle end tag
full stops set
right mark set
pair_pattern
normalization table file
pair matcher
whiteplus_pattern
start_whiteplus_pattern
end_whiteplus_pattern
replace pattern
replace matcher
always add s
parse inside
sgmlbuff
last sgml
in sgml
split items
num added
process it
content string
sentence list
last ch
new char
text buffer
is title
is body
is script
is break
attr set
chinese document to sentence processor
my htmlparser
make token
word token factory
dist sim class
number equivalence
unknown word class
dist sim classifier
sentd
unescape sql
parse array
parse json tree
doubled quotes
last quote char
tree lines
governor index
json string
malt tree
malt graph
malt dependencies
tsvutils
stoplist
stoplistfile
get text codepoints
processed tokens
codepoint core label processor
tokenize nls
tokenize newlines
word segmenting tokenizer
word segmenting tokenizer factory
set eol string
is eol
eol string
next tok
tokenizer adapter
vowelinstem
doublec
cvc
setto
step1
step2
step3
step4
step5
step6
stem
i_end
inc
new_b
stemmer
americanize function
read multi word rules
text to features
token to split
make sentence tokens
multi word rules
sentinel
token components
featurized text
classification results
char and result
splitted
splitted text
to write
current character
token and class
splitted token and class
original class
token begin position
token end position
splitted list
backwards parts iterator
part token and class
part token
part length
tokens and classes
multi tokens and classes
multi token and class
backwards multi tokens and classes
span lenght
change orig text
begin class
span end
last begin char
tokens counter
sentence tokens base
current char
current class
stat tok sent
file to train set
infer multi word rules
properties arguments
class chars
clitic index
mutli word index
clitic token lenght
token counter
sentence chars
tokens chars
tok idx
rand split
end sentence addition
class and char
tok idx split
class chars text
featurized
parts len
args_to_drop
train tokenizer
class char text
training input
train file iob
file writer
classifier props
cross validation folds str
stat tok sent trainer
new core label tokenizer factory
new core label whitespace tokenizer
new word whitespace tokenizer
token to be copied
init static lexer
stem static
lemma static
lemmatize static
static lexer
word res
word has forbidden char
quoted word
morphology
build sax interface
output text and tag
end document
start element
end element
transform xml
sax parser
elements to be transformed
text to be transformed
opening tag
q name
local name
outs
sax interface
break by hyphens slashes
handle hyphenated number
remove from number
index of space
fix jflex4space after token bug
process acronym
process abbrev3
process abbrev1
yy tokenize per line
yy not tokenize per line
remove white
inquote
string to newline is sentence break
is forced end token
matches xml break element to discard
matches token patterns to discard
plausible to add
words to sentences
never
always
two_consecutive
default_boundary_regex
default_boundary_followers_regex
default_sentence_boundaries_to_discard
sentence boundary token pattern
sentence boundary multi token pattern
sentence boundary followers pattern
sentence boundary to discard
xml break elements to discard
token patterns to discard
sentence region begin pattern
sentence region end pattern
allow empty sentences
forced end value
single quote count
double quote count
last str
is sentence boundary
inside region
in wait for forced end
last token was newline
last sentence end forced
forced end
in multi token expr
discard token
forced until end value
new sent forced
debug text
isb
debug why
debug state
region element regex
process lists
lists
lexer tokenizer
lowercase and americanize function
add indices
label to be copied
core label token factory
lowercase function
load verb stem set
ynull_stem
common_noun_stem
proper_name_stem
capitalise
condub_stem
xnull_stem
cnull_stem
null_stem
semi_reg_stem
any
scan
add generic words
word set
generic words
stop list
run and exit
dependencies_stanford
dependencies_extras
dependencies_malt
dependencies_malt_alt1
dependencies_malt_alt2
default_sentence_table
sentence table spec
exceptions
lines processed
curr time
sent per sec
lookup shaper
dont use lc
word shape dan1
word shape dan2
word shape jenny1
word shape chris2
word shape chris2short
word shape chris2long
chris4equivalence class
word shape chris4
word shape chris4short
word shape chris4long
word shape dan2bio
contains greek letter
word shape chris1
word shape digits
word shape cluster1
word shape chinese
load word clusters
nowordshape
wordshapedan1
wordshapechris1
wordshapedan2
wordshapedan2uselc
wordshapedan2bio
wordshapedan2biouselc
wordshapejenny1
wordshapejenny1uselc
wordshapechris2
wordshapechris2uselc
wordshapechris3
wordshapechris3uselc
wordshapechris4
wordshapedigits
wordshapechinese
wordshapecluster1
in str
mixed
last m
non letters
boundary_size
omit if in boundary
sb len
begin chars
end chars
begin upto
end upto
seen set
i incr
sb size
chr
end sb
bound set
greek
biogreek
cardinal
seen non digit
seen lower
seen upper
all caps
init cap
let
tit
out chars
cluster1
classifier to use
word shape classifier
distributional clusters
new ptbtokenizer
get newline token
ptb2text
ptb token2text
untok
label list2text
tok reader
core label factory
new word tokenizer factory
new ptbtokenizer factory
ptb text
input file list
ptb words
parse inside pattern
filter pattern
preserve lines
one line per element
blank line after files
num files
printing
orig str
options sb
show help
input output file list
parse inside value
parsed arg str
in line
newline_token
default_tokenize_list_size
core label processor
americanize
capitalize timex
dont_capitalize_timex
minimum_length_changed
minimum_length_pattern_match
pat strings
pats
disjunctive pattern
our_exceptions
excepts
reps
converters
timex converters
timex converted
timex mapping
americanize
get tool tip text
problem_line_length
line wrap length
text left
is first line
cur line
tooltip jlist
supported fonts
has font
num_languages
unicode ranges
system fonts
system font
can display
font detector
calculate marginals
calculate marginals just singletons
calculate map
message passing
get observed assignments
marginalize message
domains overlap
asserts enabled
variable_observed_value
cache_messages
marginals
partition function
joint marginals
map marginals
cached factors
cached factor
observations
impossible observation
cached clique list
cached messages
cached backward passed messages
marginalize
include joint marginals and partition
impossible observation made
assignment value
cliques list
clique to factor
num factors cached
all observed
obs
all consistent
metadata
non zero value
uniform zero
fac
backward passed messages
force root for cached message passing
cached cliques back pointers
back pointers consistent
num visited
visited order
tree index
seen variable
to visit array
deterministic
partition includes trees
tree partition functions
converged clique
observed assignments
back pointers
joint marginal
fast pass by reference iterator
joint assignment
any null
clique marginals
all null
deterministic joint marginal
observed assignment
relevant
clique tree
marginal result
cached factor with observations
observe
get summed marginals
get maxed marginals
max out
sum out
get assignment value
set assignment value
get assignment log value
set assignment log value
get variable size
normalize log arr
neighbor indices
use_exp_approx
forward pointers
factor assignment
assn
variable
marginalized variable value
second fast pass by reference iterator
marginalized
other domain
result domain
result neighbor indices
result dimensions
msg var
msg index
other mapping
other assignment
result assignment
sum exp
starting value
curried foldr
log sum exp
dimensions
table factor
new empty clone
set dense component
set sparse component
deep clone
add vector in place
elementwise product in place
map in place
get number of components
is component sparse
get dense component
get value at
get sparse index
write to stream
read from stream
get proto builder
read from proto
value equals
increase size to
sparse
copy on write
num components
sparse info
sparse index
multiple
sparse value
my sparse index
other sparse index
my sparse value
dense buf
pointers buf
sparse buf
copy on write buf
loaded native
concat vector
cache vectors
release cache
clone table
neighbor sizes
original thunks
original thunk
concat vector table
get dimensions
combinatorial neighbor states count
get table access offset
unsafe
assignments
ndarray doubles
get meta data by reference
clone factor
get model meta data by reference
get variable meta data by reference
add factor
get variable sizes
clone model
get proto meta data builder
read meta data from proto
model meta data
variable meta data
features table
neigbor indices
meta data
variable index
neighbor dimensions
assignment featurizer
feature table
sizes
remaining
other factor
graphical model
factor
new vector
new weights vector
ensure feature
ensure sparse feature
set dense feature
set sparse feature
debug vector
debug feature value
feature to index
sparse feature index
reverse sparse feature index
reverse sparse index
concat vector namespace
clone array
get factor list
get factor or builder list
get factor count
get factor
get factor or builder
get variable meta data list
get variable meta data or builder list
get variable meta data count
get variable meta data
get variable meta data or builder
has meta data
get meta data
get meta data or builder
ensure factor is mutable
set factor
add all factor
clear factor
remove factor
get factor builder
add factor builder
get factor builder list
get factor field builder
ensure variable meta data is mutable
set variable meta data
add variable meta data
add all variable meta data
clear variable meta data
remove variable meta data
get variable meta data builder
add variable meta data builder
get variable meta data builder list
get variable meta data field builder
set meta data
merge meta data
clear meta data
get meta data builder
get meta data field builder
has features table
get features table
get features table or builder
get neighbor list
get neighbor count
get neighbor
set features table
merge features table
clear features table
get features table builder
get features table field builder
ensure neighbor is mutable
set neighbor
add neighbor
add all neighbor
clear neighbor
factor_field_number
factor_
variablemetadata_field_number
variable meta data_
metadata_field_number
meta data_
factor builder_
variable meta data builder_
meta data builder_
featurestable_field_number
features table_
neighbor_field_number
neighbor_
features table builder_
internal_static_edu_stanford_nlp_loglinear_model_proto_graphical model_descriptor
internal_static_edu_stanford_nlp_loglinear_model_proto_graphical model_field accessor table
internal_static_edu_stanford_nlp_loglinear_model_proto_factor_descriptor
internal_static_edu_stanford_nlp_loglinear_model_proto_factor_field accessor table
internal_static_edu_stanford_nlp_loglinear_model_proto_meta data_descriptor
internal_static_edu_stanford_nlp_loglinear_model_proto_meta data_field accessor table
graphical model proto
meta data
has sparse
get sparse
get data list
get data count
set sparse
clear sparse
ensure data is mutable
set data
add data
add all data
clear data
get component list
get component or builder list
get component count
get component
get component or builder
ensure component is mutable
set component
add component
add all component
clear component
remove component
get component builder
add component builder
get component builder list
get component field builder
sparse_field_number
sparse_
data_field_number
data_
component_field_number
component_
component builder_
internal_static_edu_stanford_nlp_loglinear_model_proto_concat vector_descriptor
internal_static_edu_stanford_nlp_loglinear_model_proto_concat vector_field accessor table
internal_static_edu_stanford_nlp_loglinear_model_proto_concat vector_component_descriptor
internal_static_edu_stanford_nlp_loglinear_model_proto_concat vector_component_field accessor table
concat vector proto
component
get dimension size list
get dimension size count
get dimension size
get factor table list
get factor table or builder list
get factor table count
get factor table or builder
ensure dimension size is mutable
set dimension size
add dimension size
add all dimension size
clear dimension size
ensure factor table is mutable
set factor table
add factor table
add all factor table
clear factor table
remove factor table
get factor table builder
add factor table builder
get factor table builder list
get factor table field builder
dimensionsize_field_number
dimension size_
factortable_field_number
factor table_
factor table builder_
internal_static_edu_stanford_nlp_loglinear_model_proto_concat vector table_descriptor
internal_static_edu_stanford_nlp_loglinear_model_proto_concat vector table_field accessor table
concat vector table proto
get word shape
namespace
left metadata
left token
left pos
right metadata
right token
right pos
right chunk
this tag
next tag
co nllfeaturizer
gameplay
select or create child at random
co nll
test a
test b
tags set
human feature vectors
dense
variables list
variable sizes list
variable sizes
children of root
initial factors
marginals time
local marginals time
human observation variable
added factor
cached marginal
game player benchmark
sample state
clone benchmark
make vectors
add benchmark
dot product benchmark
construction benchmark
get random sizes
proto serialization benchmark
random sized records
same sized records
to clone
clone runtime
construction runtime
dot product runtime
add runtime
proto serialize runtime
proto serialize size
component sizes
dense pieces
sparse offsets
sparse values
b arr
b arr in
concat vector benchmark
concat vector construction record
serialization report
benchmark optimizer
generate sentence model
get embeddings
load embeddings from file
correct chunk
found correct
found guessed
npchunk
cache filename
trimmed set
massive set
co nllbenchmark
co nllsentence
update weights
get fresh optimization state
optimization state
log likelihood change
squared
adagrad accumulator
last log likelihood
backtracking ada grad optimizer
ada grad optimization state
data point
get summary for instance
get deterministic assignment
variable_training_value
deterministic value
training observation
assignment prob
log likelihood differentiable function
add sparse constraint
add dense constraint
apply to weights
apply to derivative
estimate relative runtime
l2regularization
convergence derivative norm
main worker
is sparse
local log likelihood
jvm thread id
finished at time
cpu time required
use threads
natural termination barrier
queues
queue estimated total cost
datum estimated cost
min cost queue
thread waiting
workers
min finish time
max finish time
min cputime
max cputime
slowest worker
fastest worker
waiting percentage
need transfer items
to transfer
gradient computation time
derivative norm
abstract batch optimizer
constraint
optimization state
read from
write to file without factors
write to stream without factors
empty set
model batch
find available
ports
get values
str to features
add phi features
gen vals
num vals
per vals
is other active
french morpho feature specification
ftb corrector
ftbcorrector visitor
get candito tree id
preprocess mwes
make split set
cc_tagset
split set
candito name
flat file
bad trees
skip tree
candito tree id
label term
term label
label preterm
preterm label
unigram tagger
split file name
ftbdataset
update tagger
traverse and fix
resolve dummy tags
count mwestatistics
resolve_dummy_tags
n missing pos
n missing phrasal
nouns
n str
adjectives
p str
n unknown word types
pos sequence
phrasal cat
p mwe
mwepreprocessor
manual uwmodel
load ops
p bad tree
p bad tree2
fixed t
ftbcorrector
read ids
munge leaves
replace postags
output splits
tree to morfette
lemmas_as_leaves
add_morpho_to_leaves
morfette_output
escape_parens
n morph analyses
f sizes
f names
ids
canonical filename
lemmas as leaves
add morpho to leaves
escaped lemma
pre yield
f size queue
f name queue
output count
backup copy
tag yield
list len
split candito trees
mwe label to string
unique possequences
term yield
pos yield
n mwes
n all singletons
mwe label
n singletons
mwefrequency dist
fix npwith hyphen
fix mwnwith hyphen
fix prefending with hyphen
create tag and word node
word to split
acceptable mwtpost split tags
acceptable hyphen merge tags
parent tree
post merge sub trees
np nodes
left tree
merged hyphen tree
mwn child tree
mwn index
mwn nodes
new mwnnode
mwn node to update
mwn node to update original text
tag updater
full tree
match tree
mwn tree
children list
mwt word
np node
mwp node
mwp children
last mwpword
new pnode
np tree
prorel tree
french treebank udupdater
mwt string to pattern
mwt pattern counts
patterns in order
french treebank token report
tree to morfette
next list
line id
morfette file
morfette itr
analysis
token analysis
p is punct
p all upper
is upper
is all upper
is paren
munge trees with morfette analyses
morfette file iterator
process compound
process contraction
ftb factory
split_compounds_option
split_contractions_option
split compounds
split contractions
compound buffer
ftb_options
lexer properties
second offset
second length
second start
second end
split compound option
split contraction option
option list
ortho options
output token
lines per sec
ascii dash
get normalized amp next
has noun suffix
noun suffix
has adj suffix
adj suffix
has verb suffix
verb suffix
has possible plural
possible plural
has adv suffix
adv suffix
has punc
p noun suffix
p adj suffix
p has digit
p is digit
p pos plural
p verb suffix
p adv suffix
p has punc
p is punc
p all caps
french unknown word signatures
treebank for language
compatible with
afrikaans
ancient greek
armenian
basque
breton
bulgarian
buryat
catalan
croatian
czech
danish
dutch
estonian
faroese
finnish
galician
gothic
greek
hindi
hungarian
indonesian
italian
irish
kazakh
korean
kurmanji
latin
latvian
naija
north sami
norwegian
old church slavonic
old french
persian
polish
portuguese
romanian
russian
serbian
slovak
slovenian
swedish
japanese
thai
turkish
ukrainian
upper sorbian
urdu
uyghur
vietnamese
lang list
set stem
get stem
get original stem
get pronouns
setup dictionary
is strippable
remove accents
normalize stripped verb
strip suffix
separate pronouns
strip verb
default_dict
pattern_attached_pronouns
p two attached pronouns
p one attached pronoun
p strippable
p irregulars
dict path
accent fixes
svs
accented infinitives
stripped
accent fix
letter
nosse
first pron
verb key
valid
p suffix
attached
separated
spanish verb stripper
stripped verb
has masculine suffix
has feminine suffix
has conditional suffix
has imperfect er ir suffix
has imperfect suffix
has infinitive suffix
has adverb suffix
has verb first person plural suffix
has gerund suffix
conditional suffix
imperfect suffix
infinitive suffix
adverb suffix
p masculine
p feminine
p conditional suffix
p imperfect er ir suffix
p imperfect
p infinitive
p adverb
p verb first person plural
p gerund
spanish unknown word signatures
get unigram tagger
ancora_encoding
leaf label
an cora posstats
expand phrases
candidate_groups
prepositions
parenthetical expression
group parenthetical expression
multiple clauses
expand multiple clauses
prepositional phrase
leading prepositional phrase
expand prepositional phrase1
intermediate prepositional phrase
expand prepositional phrase2
prepositional vp
expand prepositional vp1
intermediate prepositional vp
expand prepositional vp2
conjunct phrase
expand conjunct phrase
intermediate substantive conjunct
expand intermediate substantive conjunct
intermediate adjective conjunct
expand intermediate adjective conjunct
intermediate noun phrase conjunct
expand intermediate noun phrase conjunct
intermediate verb conjunct
expand intermediate verb conjunct
intermediate nominal group conjunct
expand intermediate nominal group conjunct
article leading nominal group
expand article leading nominal group
article inside orphaned nominal group
expand article inside orphaned nominal group
determiner inside nominal group
expand determiner inside nominal group
contraction trailing idiom before nominal group
join article with nominal group
contraction in specifier
del todo
contraction in range phrase
expand contraction in range phrase
extend contraction
terminal prepositions
extract terminal prepositions
terminal prepositions2
extract terminal prepositions2
terminal prepositions3
extract terminal prepositions3
adverb nominal groups
replace adverb nominal group
adjective span in nominal group
clause in nominal group
label clause
clause in nominal group2
label clause2
clause in nominal group3
label clause3
lone adjective in nominal group
label adjective
group adjectives
al menos
fix al menos
todo lo contrario
fix todo lo contrario
infinitive in verb group
mark infinitive
flopped gerund
unflop flopped gerund
flopped infinitive
unflop flopped infinitive
nominal group substantives
leftover intermediates
make nominal group
redundant nominal rewrite
fix redundant nominal rewrite
redundant preposition group rewrite
fix redundant preposition group rewrite
redundant preposition group rewrite2
fix redundant preposition group rewrite2
first step expansions
intermediate expansions
final cleanup
multi word tree expander
get override tag
get containing phrase
infer pos
infer phrasal category
n fixed pos
n fixed phrasal
phrasal category map
pos map
actually names
other name pattern
other name pattern2
p pronoun determiners
containing phrase
common pattern
phrase yield
containing phrase str
override tag
unigram tagger keys
stripped verb
first is noun
second is noun
expander
multi word preprocessor
postie breaker
load trees
process tree file
get rightmost descendant
get following terminal
get right sibling or right ancestor
get leftmost descendant
find split point
fix multi word tokens
convert tree tags to ud
splitting normalizer
splitting tree factory
rightmost descendant
first to keep
leftmost descendant
idx within parent
p split point
tnf
chunked
aux tag conversion
potential auxwords
ancora tag
convert to ud
generate tags
part of speech model
spanish tagger
an cora processor
left of filter
right of exclusive filter
multi word processor
ne pattern
np pattern
grandma
grandma value
tree to tsv
answers file
confusion matrix tsv
process verb
new spanish tokenizer factory
ancora factory
split verbs
split any
ancora_options
stem end
length removed
compound core label
p dash
p space
length accum
split verb option
one per line
convert to el
is ambiguous
disambiguate personal pronoun
reflexive
ambiguous personal pronouns
always reflexive verbs
never reflexive verbs
brute force decisions
pronoun idx
brute force key
an cora pronoun disambiguator
german treebank token report
split hyphenated token
hyphenated word pattern string
hyphenated word pattern
potential hyphenated word
split up word
hyphen node
art nknode
appr acnode
german treebank udupdater
condense umlauts
ordinal predicting words
german abbreviations
updated value
updated word
empty after
ordinal merge
number to hyphen merge
hyphen to number merge
abbreviation merge
german tokenizer post processor
arg spec
next yield
file reader
tree reader
m labeled leaves
is morph tree file
morph iter
lemma iter
p paren stripper
br in
morph tags
add morpho annotations
yield iterator
activate
split morph string
morpho_mark
lemma_mark
no_analysis
tense
def
asp
mood
nnum
ngen
gen
poss
voice
other
animacy
transitivity
verbform
variant
degree
gender
morpho feature specification
has feature
num feature matches
num active features
set alt tag
get alt tag
from tag string
key_val_delim
f spec
alt tag
n matches
f pair
m feats
f name
morpho features
disable warnings
strip annotations and classing
p ent
warned entity escaping
warned proclitic enclitic
annotations and classing only
annote and class only
first stage
second stage
third stage
w len
escaped word
print to stdout
ibmarabic escaper
debug print
this instance
verb stems
b2a
toks list
uni stem
vsb
arabic verb stem bank
suppress buck digit conversion
suppress buck punct conversion
buckwalter to unicode
unicode to buckwalter
output unicode values
arabic chars
buck chars
unicode2buckwalter
u2b map
b2u map
unmappable
pass_ascii_in_unicode
suppress_digit_mapping_in_b2a
suppress_punc_mapping_in_b2a
latin punc
char u
char b
in ch
out ch
unicode to buck
process inflectional features
process inflectional features helper
def vals
case vals
poss vals
voice vals
mood vals
tense vals
p feature tuple
p dem pronoun features
p verb mood
p mood
p verb tense marker
p noun no morph
mood matcher
mood str
base part of speech
n line
arabic morpho feature specification
arabic morpho features
load universal map
universal map
short tag
universal tag
functional tag
opt toks
feat vals
map utf8
map buckwalter
utf8arabic chart
bw alef char
bw diacritics
bw tatweel
bw alef
bw quran
bw null anaphora marker
arabic punc
arabic digit
utf8diacritics
utf8tatweel
utf8alef
utf8quran
utf8pro drop
segmentation marker
morpheme boundary
use atbvocalized section mapping
strip morpheme markers in utf8
strip segmentation markers in utf8
parent tag string
parent tags to escape
utf8clitic string
bw clitics
bw string
latin punc only
arb punc only
rm diacritics
rm tatweel
norm alef
rm quran
rm pro drop
rm morpheme boundary
stripped elem
punc only
clitic marker
rm clitic marker
utf8encoding
num matcher
default lexical mapper
load mwes
get preterminal subtrees
mwe file
mwe dictionary
mwe set
mwetree visitor external
process preterminal
left clitic
right clitic
raw word
labeled atbdataset
labeling tree normalizer
atbcorrector
current infile
has arabic
ibmmtarabic dataset
arabic aover afilter
map opts
encoding map
null filter
final word
atbarabic dataset
arabic raw tree normalizer
word tag delim
tagged arabic dataset
arabic tree tagged normalizer
bies modified mapper
decoration
clean element
unvoc lexical mapper
has num
gale p4lex mapper
mwetree visitor
atb corrector
atbcorrector visitor
process short tag
start of tag map
end of tag map
num expected tokens
add dt
determiner
noun base tag
adj base tag
ldcdeterminer
tag map
tags to escape
long tag
det in long tag
some kind of noun
some kind of adj
existing short tag
inside tag map
final short tag
is end symbol
test1
test2
test3
test4
ldcpos mapper
setup output files
close output files
tagged output
trees visited
train extension
test extension
dev extension
flat extension
out filenames
out files
make flat
make tagged
cur out file name
key for file
decimated arabic dataset
arabic tree decimated normalizer
set ser input
set max eval sent len
get parser data from treebank
make parsers
convert item span
best segmentation b
ser input
max sent len
ser_input
lattice num
parseable
f parse succeeded
train treebank file
test treebank file
lattice edge
p oscore
d oscore
p iscore
d iscore
lattice hook
joint parsing model
generic lattice scorer
cmd line usage
class usage
max gold sent len
ser_input
parsing model
file stream
joint parser
charn3
default_seg_marker
rewrite delimiter
input has tags
input has domain labels
input domain
should strip rewrites
has seg markers
tok factory
has tags
has domain labels
strip rewrites
line domain
domain and data
tag delim
rew delim
word tag pair
rewrite pair
rewritten
lex list raw
lex list rewritten
atb voc options
lex list
arabic document reader and writer
rewritten arabic annotation
segment string to iob
segment string to token list
ted eval sanitize
evaluate raw text
serialize segmenter
get segmenter
opt tokenized
opt tokenizer
opt prefix
opt suffix
opt threads
opt ted eval
opt feature factory
default feature factory
local only feature factory
opt with domains
opt domain
opt no rewrites
opt local features only
prefix marker
suffix marker
is tokenized
ted eval prefix
no rewrites
next input
segmented string
labeled sequence
n segmented
segmented line
has segmentation markers
doc reader
ted eval gold tree
ted eval parse tree
ted eval gold seg
ted eval parse seg
label total
input tokens
parse tokens
safe length
ref label
n total
chars per sec
n chars
arabic segmenter
tok options
tokenized line
mapped tok
mapped toks
print lines
tokenized tok
arabic tokenizer tester
get boundary character
string to iob
fill in word statistics
token to datums
is deleted character
should not segment
strip segmentation markers
get token type
iobto string
annotate markers
annotate markers on word
get head bounds
add prefix marker
add suffix marker
label domain
token spans for iob
begin marker
end marker
both marker
no marker
begin symbol
continuation symbol
noseg symbol
rewrite symbol
rewrite tah symbol
rewrite tareef symbol
boundary symbol
boundary char
not unicode arabic
ar prefix set
ar suffix set
arabic prefix string
arabic suffix string
apply rewrite rules
iob list
str seg marker
add whitespace
word start index
boundary datum
tok type
token label
last label
first label
cross ref rewrites
char label
this char
new tok
starts with marker
ends with marker
add space
apply rewrites
labeled char
word begin
word end
head bounds
not_found
potential suffix
non suffix
potential prefix
non prefix
focus
in token
sequence length
prefix marker annotation
suffix marker annotation
new arabic tokenizer
atb factory
atb options
options str
option toks
setup normalization map
normalize token
is lengthening
get ellipsis
domain_marker
max_before
max_after
domain features
charn
charn2
seen punc
charc c
cu block
cu type
get temporal nouns
get inna sisters
get kan sisters
get dimir munfasala
get dimir mutasala
dimir munfasala
dimir mutasala
inna sisters
kan sisters
tmp nouns
arabic word lists
sg1
sg2
generate uncollapsed dependencies
generate collapsed dependencies
generate ccprocessed dependencies
generate enhanced dependencies
generate enhanced plus plus dependencies
make from tree
make from edges
get vertices from edge set
make from vertices
duplicate keep nodes
make from graphs
deep copy from graphs
include_punctuation_dependencies
collapsed_tree
ccprocessed
enhanced
enhanced_plus_plus
word filt
tag filt
deps filtered
structure
ret set
nodes to add
node a
node b
ret sg
sg list
new roots
curr sg
curr vertex
curr edge
vertex offset
new vertex
semantic graph factory
unknown vertex exception
format semantic graph
format sgnode
format sgnode oneline
format sgnode oneline helper
format sgnode multiline
format label
lparen
rparen
space
colon
default_width
default_indent
default_smart_indent
default_show_relns
default_show_tags
default_show_annos
default_show_indices
smart indent
show relns
show tags
show annos
show indices
oneline
toolong
breakable
used oneline
isnt leaf
depcy
semantic graph formatter
make graph from nodes
find matching node
get sub tree edges
get sub tree edges helper
get edges spanned by vertices
get children with reln prefix
get children with prep c
incoming edges with reln
outgoing edges with reln
edges with reln
find all relns with prefix
tabu descendants
descendants tabu relns
descendants tabu test and relns
tabu descendants helper
left most child vertice
left right most child vertices
get dependency blanket
reset vertice ordering
en repair edges
kill non rooted
anonymyize nodes
make generic vertices
make blanket vertices
make replaced edges
all edges in set
diff edges
get remaining1
get remaining2
get same edges
print edges
print vertices
semgrex from graph
semgrex from graph helper
semgrex from graph ordered nodes
sanitize for semgrex name
remove duplicates
map tree to sg
src graph
node g
node d
existing edges
tgt
vertice
excluded edge
tabu
tabu edges
reln prefix
reln prefixes
edge string
tgt reln
relns
edge relation
descendant set
tabu relns
tabu test
tabu nodes
relns to avoid
asserted nodes
asserted node
nsg
old to new vertices
new vertices
guaranteed
gov edges
dep edges
old node removed
gov edge
dep edge
wildcard_vertice_token
wildcard_vertice
verts
ret map
generic vert
generic value
shared_node_anon_prefix
blanket_node_anon_prefix
vert replacement map
use generic replacement
ret list
new edge
edges1
edges2
compare obj
remaining edges1
remaining edges2
same edges
edges2cache
edges1cache
remaining1
remaining2
show word
show index
show sent index
show pos
wrap at
match tag
match word
node name map
wildcard nodes
word transformation
pattern root
seen edges
use word as label
name edges
ordered nodes
node values transformation
vertex str
edge iter
tgt vert
apply parens
new sent index
prev roots
key val
tabu graphs
tabu map
tabu sg
tabu graph
tabu set
lex to tree node
lex to sem node
leaf proxies
proxy
depth map
node proxies
non term
best node
equiv node
curr score
intree
lword
visited nodes
semantic graph utils
edge diff result
print vertice params
tree node proxy
positioned tree
indexed word proxy
enhancedplusplus
semantic graph core annotations
collapsed dependencies annotation
basic dependencies annotation
collapsed ccprocessed dependencies annotation
enhanced dependencies annotation
enhanced plus plus dependencies annotation
alternative dependencies annotation
semantic graph printer
edge count
out degree
in degree
contains edge
vertex set
vertex list sorted
edge list sorted
outgoing edge list
incoming edge list
match pattern to vertex
has children
get incoming edges sorted
get out edges sorted
get parent list
get siblings
get path to root
get node by index safe
get node by index and copy count
get node by index and copy count safe
get node by word pattern
get all nodes by word pattern
get all nodes by part of speech pattern
descendants
descendants helper
child relns
get vertices without parents
get first root
reset roots
set roots
has child
has child with reln
has parent with reln
get child with reln
get parents with reln
get children with reln
get children with relns
is negated vertex
is negated verb
is in conditional context
attached negated verb
is auxiliary verb
get leaf vertices
get subgraph vertices
is dag helper
rec to string
to recovered sentence string
to recovered sentence string with index marking
to en uncollapsed sentence string
insert specific into list
to poslist
to compact string
to compact string helper
to dot format
get shortest undirected path nodes
get shortest undirected path edges
get shortest directed path nodes
get shortest directed path edges
read dep
make vertex
read word and index
get next free index
read left bracket
read right bracket
read reln separator
is left bracket
is right bracket
is reln separator
find all relns
yield span
add comment
get comments
add srlarcs
word map factory
v list
grandparents
v1parents
v2parents
v1grand parents
v2grand parents
v1parent
v2parent
v2grand parent
v1grand parent
node dists
dominated edge count
outer
winner
child lemma
parent list
arbitrary
trail
word format
root nodes
past first
uncompressed list
specifics
spec pair
reln tgt node
tgt list
specific node
readable
recursive
graphname
indexed word format
prev to new map
vertexes
new sg
word_and_index_pattern
indexes used
word and index
ifl
word and tag
tgt relation
tgt relation shortname
semantic graph
semantic graph parsing task
semgrex parse exception
semgrex parser token manager
compile stream
replace macros
extract macro
max_stream_size
macro_name_pattern
post processed
equal position
semgrex batch parser
set alignment
satisfy helper
get neighbor pairs
neighbor iterator
follow edge
satisfies order
is known relation
raw type
reln type
alignment
hyp to text
found once
iterator
aligned_root
start depth
end depth
used nodes
seen nodes
returned nodes
current depth
this stack
this seen
next stack
next seen
searched nodes
other end
already iterated
l1parents
graph relation
alignment
governer
limited_grandparent
grandsomething
grandparent
grandkid
limited_grandkid
sibling_relation
right_immediate_sibling
left_immediate_sibling
right_sibling
left_sibling
adjacent_node
semgrex demo
get justification
iw to string
patched alignment
make from index array
justification
hyp graph
txt graph
patched map
txt vertex set
hyp node
txt node
is node coord
has precedence
names to relations
sg_align
next node match
setup find iterator
get reln string
get relation names
sg_aligned
topological sort cache
topo sort
semgrex matcher
full expression
warn deprecated
relation disj
relation conj
mod relation
rel child
mod node
add attribute
under node negation
deprecated amp
deprecated node conj
num arg2
p c
semgrex parser
alignreln
set empty
set attribute
node attributes
node attr match
make link
is null
go to next node match
decommit named nodes
decommit named relations
desc string
is regexp
pattern content
to match
node match candidate iterator
next match reln
named first
reln named first
found reln
node pattern
node matcher
inst
init log
set log prefix
expand from patterns
exhaust from patterns
get operation from file
add resource
get resource
get resources
parse args
parse edit line
write to string
create pattern xmldoc
read from file
read from directory
ssurgeon pattern from xml
assemble pred from xml
test read
get tag text
get elt text
get first child element
get child elements
log prefix
log file path
pattern list
generated
ordered graph
gen sg
mod graph
reference list
child graph
word list resources
gov_nodename_arg
dep_nodename_arg
edge_name_arg
nodename_arg
reln_arg
node_proto_arg
weight_arg
name_arg
gov node name
edit line
tuples1
args array
args box
ret edit
dom doc
tformer
root elt
ordinal
pat elt
semgrex elt
uid elem
notes elem
semgrex graph
pat node
edit list
edit ordinal
edit elem
pattern nodes
resource nodes
resource elt
wl rsrc
uid
notes
semgrex string
semgrex pattern
ret pattern
edit nodes
edit elt
edit val
pred elt
elt name
and pred
child elt
child pred
or pred
resource id
type str
tgt dir path
rsrc
run flag
gsg
first elt
child node list
child elements
testinfo
pattern dir str
pattern dir
info path
ssurgeon
ssurgeon args
args box
from args
to edit string
crawl
label
destroy node name
seen verts
seed node
nodes to destroy
delete graph from node
get owning pattern
set owning pattern
get named node
add named node
owning pattern
ssurgeon edit
word_elt
word elt nl
test word
ssurgeon wordlist
set predicate
add edit
execute
get semgrex pattern
get edit script
get semgrex graph
get notes
set notes
get uid
set uid
uid
edit script
predicate test
pattern graph
new edit
node names
override pattern
elt_list_tag
uid_elem_tag
resource_tag
ssurgeon_elem_tag
semgrex_elem_tag
semgrex_graph_elem_tag
predicate_tag
predicate_and_tag
predicate_or_tag
pred_wordlist_test_tag
pred_id_attr
notes_elem_tag
edit_list_elem_tag
edit_elem_tag
ordinal_attr
ssurgeon pattern
ssurg and pred
get display name
current_lasttoken
lemma_and_currlast
my id
last current
wordlist test
get match name
node test
ssurg or pred
register node test
get node test
node tests
node test obj
ssurg test manager
create eng add edge
eng reln name
gov node
dep node
existing edge
add edge
get dep name
get edge name
get gov name
edge name
remove named edge
ssurgeon utils
root path
kill non rooted nodes
create add node
add node
root node name
subgraph node set
reachable set
sorted subgraph nodes
collapse subtree
create eng add dep
cheap word to string
from cheap string
null shield
new node prototype
eng relation
new node obj
pos_key
tuple_delimiter
atom_delimiter
raw arg
add dep
new root names
set roots
get relation name
wildcard_node
gov wild
dep wild
success flag
remove edge
tgt node
kill all incoming edges
set env
new pattern
tree_file
mode
default_mode
extras
conllu_file
output_format_option
mode string
output format string
use extras
conllu file
semgrex pattern
match sentence
semgrex result builder
reln builder
process semgrex request
get governor
get dependent
type equals
order by target comparator
print only relation
target val
source val
target comparator
this relation
that relation
semantic graph edge
ret flag
gov match
dep match
semantic graph edge
semantic graph edge target comparator
gamma
first keys
second keys
get map factory
total int count
total double count
average count
get count as string
get int count
get normalized count
set counts
increment counts
decrement counts
subtract all
remove zero counts
double max
keys above
keys below
keys at
natural comparator
temp minteger
old minteger
tie breaker
count threshold
get precision info
get precision description
get recall info
get recall description
get fmeasure
get f1description
tp count
fp count
fn count
neg index
labels arr
guess index
true index
set label index
clear counts
finalize counts
add guess
add guesses
get correct
get retrieved
get relevant
get accuracy info
get accuracy
get accuracy description
get conll eval string
correct guesses
tokens count
tokens correct
no label
string converter
data label index
true labels
add unknown labels
total wrong
accu
token_index
answer_index
guess_index
ignore neg label
ordered labels
correct phrases
accuracy info
get counter
size outer map
contains first key
set counter
reverse index order
to matrix string
sum inner counter
get outer map factory
get inner map factory
identity hash map counter
recompute total
outer mf
inner mf
old count
header row
row label
col label
my inner
summed
outer factory
inner factory
cc2
get reserved mass
get number of keys
get distribution from partially specified counter
get uniform distribution
get perturbed uniform distribution
get perturbed distribution
get distribution
get distribution with reserved mass
get distribution from log values
absolutely discounted distribution
laplace smoothed distribution
laplace with explicit unknown
good turing smoothed counter
good turing with explicit unknown
get count counts
simple good turing
validate counter
collect count counts
count counts2int arrays
distribution with dirichlet prior
dynamic counter with dirichlet prior
add to key set
distribution from logistic counter
reserved mass
num_entries_in_string
num keys
perturbed prob
discount
new count
zero count prob
new total
count counts
observed mass
adjusted freq
norm factor
orig freq
num unseen
sgt
probs by count
dbl count
count count
prior multiplier
remaining keys
dir2
add1
to list pair double
constant size fn
read data series
demo1
size fn
use headers
serieses
series
x data
y data
abstract data series
function data series
array data series
list data series
average data series
get double value
mutable remove
value of ignore comments
temp mdouble
old mdouble
check parameters
sample beta
get predictive probability
get predictive log probability
get posterior distribution
get posterior predictive probability
get posterior predictive log probability
unnormalized log probability of
parameters
mult parameters
parameter
new parameters
denominator
log normalize in place
subtract in place
dot product in place
as normalized counter
delete outof range
retain top
retain top key comparable
retain bottom
retain non zeros
retain above
retain below
retain matching keys
retain keys
transform with values add
to comparator
to comparator with keys
to comparator descending
to sorted list key comparable
to rank counter
to tied rank counter
to descending magnitude sorted list with counts
to sorted list with counts
to priority queue
jaccard coefficient
sum entries
optimized dot product
get dot prod
absolute difference
division
division non na n
cross entropy
skew divergence
sum squares
l2normalize
l2normalize in place
safer l2norm
safer l2normalize
linear combination
pointwise mutual information
h index
perturb counts
print counter comparison
tf log scale
print counter sorted by keys
load counter
load int counter
load into counter
save counter
load2dcounter
load into2dcounter
load inc into2dcounter
save2dcounter
save2dcounter sorted
serialize string counter
deserialize string counter
serialize counter
deserialize counter
to sorted string
to sorted by keys string
to biggest values first string
restricted arg max
to counter
as array
pow normalized
unmodifiable counter
is uniform distribution
max in place
min in place
retain top mass
pearsons correlation coefficient
spearman rank correlation
ensure keys
top keys
top keys with counts
get fcounter
transform values in place
is finite
log_e_2
logsum
value if empty
default if empty
purged items
num to purge
rem
en2
count max threshold
match patterns
match keys
remove keys collection
rank counter
i en
icount
i key
j en
avg rank
count1
count2
min count
tmp cnt
key idx
log fract
kl1
kl2
len sq
sum abs
max val
sqr sum
lsq1
lsq2
all keys
var1distribution
var2distribution
joint distribution
var1prob
var2prob
joint prob
pmi
citation counts
citation count values
citation count
occurrences
noise
perturbed count
a count
b count
scaled
scaled cnt
val str
min magnitude
item format
wrapper format
largest k
first score
restriction
max key
rand
guessed features
initial total
initial total final
def rv
original counter
copy counter
threshold count
stddev x
stddev y
mean x
mean y
xrank
yrank
top num
fscores
newcounter
retain function
hier
flat
counters
get tp
get fp
get fn
add tp
increment tp
add fp
increment fp
add fn
increment fn
add counts
positive class
guess positive
prs
precision recall stats
set bag eval
null equivalence classer
eval precision
remove item
display last
last precision
last recall
last num guessed
last num guessed correct
last num golds
last num golds correct
display helper
format number
format count
get pads
default checker
contained
eval recall
equivalence class eval
bag eval
null_equivalence_classer
checker
summary name
guessed
guessed correct
gold correct
previous guessed
previous guessed correct
previous gold correct
internal guesses
internal golds
this guessed
this correct
this guessed correct
pads
this gold
this gold correct
number format
key string
default_checker
cum precision
cum recall
cum f1
bag eval1
eq1
checker1
summary name1
evidence
lowest level counter entry set
top level key set
conditionalize helper
conditionalize
conditionalize once
increment count2d
increment count3d
add to total
increment count1d
reverse keys
wrong depth
counter view
one dimensional counter view
print key set
array print double
dump keys
zero key
use lists
final key
use list
gc1
gc2
an o
buffer increment
get chunker
get type label
in correct
prev correct
prev guess
chunker
use label
guess tag type
correct tag type
prev correct ended
prev guess ended
correct started
guess started
mstats
multi class chunk eval stats
get set of all keys
weighted average
information radius
remaining mass1
remaining mass2
new probability
num keys remaining
assigned mass1
assigned mass2
distributions
total counts
key1comparator
key2comparator
second keys size
get probability for unseen
get probabilities
find best fit
validate
integer list2int array
min_input
confid_factor
tolerance
big n
p zero
big nprime
slope
intercept
log r
log z
r star
next_n
indiff vals seen
xys
xsquares
r vals
n vals
integer
simple good turing
confidence weighted accuracy
get acc coverage
is correct
save index
use_accuracy
use_loglikelihood
correct lab
guess score
correct score
guess ind
correct ind
conf weighted accuracy
accuracy type
to string arr
opt accuracy
opt conf weighted accuracy
accrecall
optaccrecall
pos label
label d
prc
coverage
get parameters
other multinomial
num occurances
probability of new object
base measure
sampled
drawn
get pair
get xinstance
get yinstance
set sum
init hash vals
indexed values
values i
hash values
instance index
set non zeros
i p
num elems
feature
ptilde
set max y
num y
ptilde x
ptilde y
ptilde xy
v array
max y
pxy
max ys
number y
x line
index2
x st
y line
experiment
max x
y arr
x c
y c
experiments
data generic
set non binary
set binary
transform values
improved iterative
iterate
newton
update conds
pcond
fnum
gprime
zalfa
gsf
pcond falfa
gsfprime
gsfsecond
gain compute
save_lambdas
read l
read_lambdas
save_problem
log likelihood neg
log likelihood scratch
get derivatives
get derivatives neg
expected value
get derivatives expected value
loss domination
get derivatives loss domination
lambda_converged
fixed fnum xy
prob conds
zlambda
ftilde arr
assume_binary
weight ranks
convert values
nerr1
sumhighest
sumrest
alfa
const all
num nconverged
delta i
delta l
lambda0
lambda n
plambda
g prime val
g val
zlambda x
summ all exp
psff
error gain
gsf val new
alfanext
lambdas
model filename
lamb
num lambda
f lambda
drvs
localloss
hasgraph
lambda solve
ex size
problem
print optimization results
solve qn
solve owlqn2
solve cg
solve l1
likelihood
num calls
report monitoring
save_lambdas_regularly
use gaussian prior
prior sigma s
sigma squareds
default_tolerance
default_sigmasquared
neg log like
num non zero
cgm
owl
value at calls
sigma squared
lik
cgrunner
likelihood function
monitor function
f st
arr indexes
arr values
ind sp
ind values
features
choose top words
num non redundant patterns
learn new phrases
run parallel apply pats
apply pats
stats without applying patterns
learn new phrases private
get learned scores
written in justification
const vars
phrase scorer class
phrase scorer
newdt
use threshold num patterns for these words
ignore words
threshold word extract
term iter
finalwords
matched fuzzy
next ten
pati
patj
patterns for each token
patterns learned this iter
all selected patterns
tokens matched patterns
score for all words this iteration
words pat extracted
patterns and words4label
compute proc data freq
already identified words
wordsand lemma pat extracted
matched tokens by pat
already labeled words
not allowed classes
sentids
surface patterns learned this iter converted
dep patterns learned this iter converted
executor
submit
sents all
sent ids2pats
set en
sentsf
sentences for patterns
sent en
pat4sent
sents iter
phrase scores
ignore words all
gold entities4label
outputdir
reason for words
objarr
obj this iter
objinner
max pat weight terms
word max pat
maxvalue
bestw
compute raw freq if null
set ratio google ngram freq with data freq
load domain ngrams
ratio domain ngram freq with data freq
raw freq
sents files
sent id2file
in memory save file location
processed data freq
domain ngram raw freq
ratio google ngram freq with data freq
domain ngrams file
using google ngram
matched tokens for each phrase
num words compound
batch process
pattern scoring
all candidate phrases
patternsand words4label
neg patternsand words4label
un labeled patternsand words4label
current pattern weights4label
pos_i
neg_i
unlab_i
all_i
posneg_i
log fi
theta precision
set index reader searcher
query index get sentences
query index
list all documents
read proto buf annotation
get proto buf annotation
finish updating
set index writer
close index writer
load index
save tokens
index writer
index dir
analyzer
iwc
searcher
index dir str
newreader
pkey
processed key
add processed text
ptoken
sentid
ptxt
index disk dir
sentindex
stopwords
transform sentence to string
do not use
get patterns around tokens
use stop words before term
use target nerrestriction
use ner
num words compound mapped
num words compound max
use lemma context tokens
filler words
ignore word regex
pattern type
toks2
surface
dep
pattern factory
set up constructor
get pats for each token
remove over lapping labels
run posnerparse on tokens
run posneron tokens
infer parent parse tag
get thread batches
run label seed words
add to matched tokens by phrase
process sents
read saved patterns and index
get patterns
get pattern scoring class
split into num threads with sampling
calculate sufficient stats
add stats
enforce min support requirements
remove learned patterns
normalize soft max min max scores
label words
iterate extract apply
write matched tokens and sents
matched tokens by phrase json string
json array builder from map counter
iterate extract apply4label
write patterns to file
write words to file
read learned words from file
get learned patterns
get learned patterns each iter
set learned patterns
count results per entity
count results per token
write label data sents
write labeled data
write column output
write column output sents
fscore
get all files
get precision recall
get non background labels
read seed words from jsonstring
read seed words
remove labelings
get all options
run nine yards
add folder
load from saved patterns words dir
set learned patterns each iter
read classes in env
write classes in env
pats for each token
words for other class
f1seed pattern
rlog f
rlog fpos neg
rlog funlab neg
rlog fneg
ph eval in pat
ph eval in pat log p
pos neg odds
yan garber02
pos neg unlab odds
ratio all
logreg
logreglog p
sqrt all ratio
lin icml03
k nn
bpb
weightednorm
written pat in justification
learned patterns
learned patterns each iter
matched seed words
score phrases
create pats
not computed all patterns yet
seed set
label using seed sets
answer label
answer class
ans cl
generalize classes
ignore classes
seed sets
i c
g c
ansclstr
extremely small stop words list
transform core label to string
total num sents
compute data freq
otherseed
external feature weights file label
lmf
dist sim weights label
cluster num
dict odds weights label
other semantic class freq
label dict ngram
class freq
other label freq
longest matching map
longest matching string
longest matching label
propsoriginal
use target parser parent restriction
pos model path
sents cm
sent idprefix
batch process sents
num max sentences per batch file
save sentences ser dir file
num files till now
grandstr
grand
subl2
do not label these words
seen fuzzy matches
min len4fuzzy
fuzzy match
ignore case seed match
compare fuzzy
combo2
string transformation function
keyset
threaded sent ids
answerclass
seed words
overwrite existing labels
matched phrases counter
sentsi
is head
seedwords tokens
label class
min len4fuzzy for pattern
do not label dict words
string transformation
write matched tokens ids for each phrase
seedwords
labelclass
newsent
tokens core
tokenslemma
matched phrases
longest matched phrases
s en
long ph
longest matching ph
matcheds
patternsand words
current pattern weights
delete existing index
already identified patterns
p0set
ignore patterns
first call to process sents
sents pair
remove pats
score patterns
patternscoringclass
final pat
ctor
chosen pat
remove patterns
remove identified patterns
notchoose
remove chosen pats
remove chosen pat flag
chosen pat sorted
pos words
neg words
unlab words
unlab
num calls to cal stats
result all
totalitems
nitem
answer class4label
sampled sent ids
sampled sents
sent ids
token word or lemma
longest matching phrase
longest matching phrases
newpats
changedpats
snew
nertag
neg token
ignore
ig cl
label a
sindex
min max norm
one minus soft max
newscores
ph in pat scores cache
identified words
num tokens labeled
temp pats for sents
sentence changed
identified words tokens
context words recalculate pats
ph en
donotuse
ph str
matched tokens by pat all labels
terms all labels
words output
patterns output
words output file label
patterns output file label
keep running
learned words this iter
sentout
learned pat words4label
matchedtokensfilename
tokens matched pat
all matched sents
matched strs
senttokens
sen2
startend
sentfilename
arrobj
map counter
sents out file
patterns out
num iter total
pattern this iter
learned
num iter
word tp
word tn
word fp
word fn
which class to compare
last gold
last guess
eval per entity
last word labeled
list ended labels
starting labels
lastwordlabeled
answerclasses
anscl
doc en
doceval
betasq
tokfile
filef
gold words4label
learned words
numincorrect
numgoldcorrect
assumed neg
seed words file
seed words files
seed file
seed words4label
remove labeled phrases
print option class
this class
a class fields
fvalue
num iterations of saved patterns to load
patterns words dir
load model for labels
file format
preserve sentence sequence
use context nerrestriction
add eval sents to train
eval file with gold labels
save sentences ser dirstr
save sentences ser dir
systemdir
temp save sentences dir
sentsthis
outfilename
newf
evalsents
save eval sentences ser file
save eval sentences ser file file
set class for these labels
num file
eval file format
sents eval
sents cms
patterns words dir value
out properties file
seed w
answer classes
ans classes
load saved patterns words dir
num iterations loaded model
zos
folder name
base folder name
entry name
a f2
label sents using model
apply pats using model
labels for pattterns
load model for labels list
patf
toremove
wordf
global env
days
hours
learn classifier
print reason for choosing
get random boolean
logistic
get all labeled words cluster
compute sim with word vectors
compute sim with word cluster
choose unknown as negatives
choose unknown phrases
has element
num labeled tokens
get phrase1
get phrase2
get all possible negative phrases
choosedatums
get similarities
get phrase features for pattern
score using classifer
score classifier type
constvar
svm
shiftlr
linear
phrase scores raw
for learning patterns
compute raw freq
logfactory
lprior
logcl
wtd
svmcf
topfeatures
newdataset
p en
word class clusters for phrase
phrase lemma
phl
candidate phrases
other phrases
sims
sims avg max all labels
sims avg max
top sim phs
allsum
d1sq
d2sq
final sim score
num el
prev num items
prev avg
prev max
new num items
new max
positive phrases
all possible negative phrases
pos sims
neg sims
retain phrases not close to negative
candidate phrase
all max sim
avg sim
posfeat
known negative phrases
phs
threaded candidates
per select
max num
unknown samples
accept word
sampled heads
text tokens
output phrases
extracted phrases
output indices
haspositive
ignore label
close to positives first iter
close to negatives first iter
word class clusters of positive
all possible phrases
expand pos
expand neg
rneg
all positive phrases
all negative phrases
all unknown phrases
all close to positive phrases
all close to negative phrases
known positive phrases
all considered phrases
other ignore classes
numlabeled
sent inst
longest matching
ignoreclass
added as pos
simneg
cache similarities
similarities with labeled phrases
neg phrases
for learning pattern
dist sim clusters of positive
toknum
numpos
log file feat
chosen unknown
selected neg phrases
scoreslist
dscore
gscore
wordclass
patterns that extracted pat
pat that extracted word
tfscore
avg pos sim
max pos sim
sum neg
max neg
all num items
sim en
num items
max neg label
avg neg sim
create or get
get phrase lemma
get feature value
convert string phrases
convert to string
set phrase lemma
delete phrase
candidate phrase map
candidate phrase
convert2one dim
ph in pat scores
external word weights normalized
use freq phrase extracted by pat
numerator score
numerator pat wt
denominator pat wt
deno score
logpos_i
scoring function
positive patterns and words
sqrt pat score
score phrases in pat selection
dict odds word weights
google ngram norm scores
domain ngram norm scores
external feat wts normalized
edit distance from other semantic binary scores
edit distance from already extracted binary scores
external wts default
classifier scores
props2
scoreclassifier
cached scores for this iter
semantic class odds
domainscore
external feature wt
num all sentences
transform core labelto string
index class
index directory
get tokens
data instance surface
parse column file
parse file
categories allowed
sent idprefix
conllreader
dociter
sentcore
tokenindex
starting label token
end label token
tokw
starting matcher
end matcher
toksplit
sentcm
annotated text reader
check clean
setup search
add patterns
get bytes
create index if using dband not exists
get patterns for all tokens
open index writer
all patterns dir
create pat lucene index
check index
commit
baip
get relevant words
equal context
get genre
set genre
copy new token
get context token
get context str
get prev context str
get next context str
to string to write
get simpler tokens prev
get simpler tokens next
get simpler tokens
to string simple
get prev context
set prev context
get next context
set next context
same genre
subsumes array
subsumes
subsumes either way
same restrictions
get previous context len
get next context len
same length
set num words compound
relwords this pat
prev context
next context
genre
tokenj
prev context str
next context str
more previous pattern
more next pattern
this_restriction
p_restriction
simprev
simnext
prevstr
nextstr
array1
array2
numthis
numthat
surface pattern
get token str
grandparent parse tag
get compound phrases
restrictions
pattern token
word class cluster file
threshold weight
cluster ids
negative words files
negative words
per select neg
per select rand
numrand
choose this
sents file
learn important features
specificity
sensitivity
class orrestrictions as string
to string dep
to string surface
get simple
add orrestriction
set env bind restriction
set num occ
get key for class
to string class2key mapping
set class2key mapping
class2key mapping
class orrestrictions
env bind boolean restriction
alpha numeric
num min occ
num max occ
org val
class r
env bind
class comparator
create table
create upsert function
create upsert function pattern index
get prepared stmt
contains sent id
dbtable exists
delete existing
table name
patternindices table
delete dbresources on exit
stmtindex
pstmt
pats as bytes
pats token
doesnotexist
stmt2
indexquery
dbm
tables
single_batch
small_batch
medium_batch
large_batch
total number of values left to batch
in clause
contains stop word
remove stop words from selected phrases
remove phrases with stop words
all freq
matched pat
use word not labeled
addedindices
contains stop
common eng words
update patterns
get store way
get patterns instance
store way
store pats for each token
lemma exists
already labeled phrases
p sur
cand phrase
get context token str
is ascii
use pos4pattern
use coarse pos
add pat without pos
min window4pattern
max window4pattern
use previous context
use next context
num min stop words to add
use filler words in pat
prevnext
prevpatterns
nextpatterns
prevnextpatterns
fulltag
max win
previous tokens
original prev
original next
next tokens
num stop wordsprev
num stop wordsnext
num non stop words next
num non stop words prev
useprev
usenext
twithout pos
twith pos
tokenj str
is labeled o
strgeneric
str original
prev context list
prev original
pat pos
next context list
next original
checked
surface pattern factory
get all patterns
store pats for each token way
start date
num items per thread
time taken
pats for each
temp patterns for tokens
num sentences in one commit
combine key value
get file sent ids
get file sent ids from pats
add this
relevant words
inv
sent sentids
phrase scores normalized
tfidf scores
edit distance other binary scores
edit distance same binary scores
norm tfidfscores
dict oddds scores
googlescore
edit d
edit dsame
w en
avg score
get connection
db location
dbusername
dbpassword
sqlconnection
set max phrase length
check if satisfied max depth
process sentence for type
get sem grex pattern nodes
print sub graph
check if satisfies rel constrains
descendants with reln
print matched graphs for pattern
cutoff relations
ignore tags
ignore common tags
cutoff tags
max phrase length
matched graphs for pattern
found in max depth
type patterns
type phrases
type indices
type trigger words
find sub trees
trigger words
output nodes
found words parents
if satisfied max depth
matched graphs
cutoffrelations
additional cut off rels
list of output
list of output indices
do not add these
and nodes
all cut off rels
feat per token
extracted ph
rel name
rel specific name
rel full name
dontuse
cut off tag regex
max graphs per pattern
g en
extract phrase from pattern
dep pattern
get matched tokens index
matched restriction
matching word restriction
tokens c
indexed word semantic graph pair
get indices
article id
extracted phrase
get patterns for all phrases
pattern to dep pattern
if ignore rel
ignore rels
up depth
allowed tags for trigger
allowed tag pattern for trigger
ignore rels set
pats4sent
all nodes
patterndep
dep pattern factory
data instance dep
edit distance with new buffers
edit distance with buffers
iterate over stripe
init memoise tables
thread local buffer size
cost local
back1local
back2local
back1
back2
tlen
temp cost
edit distance damerau levenshtein like
get new surface instance
get new instance
data instance
portnum
newphrases
removephrases
newannotations
processfile
removeannotations
suggest
matchedtokensbyall
matchedtokensbyphrase
allannotations
annotationsbysent
summary
close
whatitdoes
client number
nextline action
text annotation patterns interface
perform action update model
get pat tfidfscore
get google ngram score
get domain ngram score
get dist sim wt score
get word shape score
get dict odds score
get phrase weight from words
oovexternal feat wt
oovdict odds
oovdomain ngram score
oovgoogle ngram score
use pattern weights
word freq norm
use avg insteadof min phrase scoring
sqrt
log
numitems
avgsim
maxsim
learned scores
pats that extracted this
gnew
totalscore
numw
thislabel
alllabels
default wt
write error
test properties file
model nameto dir name
quoted string
json object
testmode
suggestions
test props
model dir
model properties file
stop words file
write output file
spiedservlet
has seed word or other sem
get learned words each iter
set learned words each iter
list file including itself
read gold entities
get word shapes for labels
get generalize classes
get stop words
add word shapes
get seed label dictionary
get learned words
get learned words as json
get learned words as json last iteration
get set words as json
get english words
get common eng words
get other semantic classes words
set other semantic classes words
get word class clusters
get edit dist
get edit distance from this class
get edit distance from other classes
get edit distance from english words
get edit distance from english words matches
get edit distance scores other class
get edit distance scores other class threshold
get edit distance scores this class threshold
get edit distance scores this class
is fuzzy match
contains fuzzy
get general word class clusters
set general word class clusters
get word shape cache
get answer class
get ignore wordswith classes during selection
add seed words
num iterations for patterns
num patterns
compute all patterns
threshold select pattern
restrict to matched
use pattern result as label
use matching phrase
tune threshold keep running
max extract num words
use other labels wordsas negative
marked output text file
column output file
match lower case context
target allowed tags initials str
allowed tags initials
target allowed ners
allowed nersfor labels
num words to add
threshold num patterns applied
word scoring
lrsigma
english words files
english words
common words pattern files
other semantic classes files
other semantic classes words
seed label dictionary
ignore wordswith classes during selection
word ignore regex
stop words pattern files
already set up
word class clusters
general word class cluster file
general word class clusters
external feature weights dir
do not apply patterns
min unlab phrase support for pat
min pos phrase support for pat
add indv words from phrases except last as neg
edit distance from english words
edit distance from english words matches
edit distance from other semantic classes
edit distance from other semantic classes matches
edit distance from this class
edit distance from this class matches
word shapes for labels
channel name logger
dist sim weights
dict odds weights
inverted index class
inverted index directory
club neighboring labeled words
subsample unk as neg using sim
expand positives when sampling
expand negatives when sampling
similarity threshold high precision
positive similarity threshold low precision
use word vectors to compute sim
log file vector similarity
gold entities eval files
expand phrases num top similar
save patterns words dir
seeds
num obj
created objects
distsim
googlengram
patwtbyfreq
editdistsame
editdistother
domainngram
semanticodds
wordshape
wordvecpossimavg
wordvecpossimmax
wordvecnegsimavg
wordvecnegsimmax
isfirstcapital
wordshapestr
bow
remove over lapping labels from seed
use phrase eval word class
use phrase eval word vector
use phrase eval google ngram
use phrase eval domain ngram
use phrase eval pat wt by freq
use phrase eval semantic odds
use phrase eval edit dist same
use phrase eval edit dist other
use phrase eval word shape
use phrase eval word shape str
use phrase eval first capital
use phrase eval bow
use pattern eval word class
use pattern eval word shape
use pattern eval word shape str
use pattern eval first capital
use pattern eval google ngram
use pattern eval domain ngram
use pattern eval semantic odds
use pattern eval edit dist same
use pattern eval edit dist other
use pattern eval bow
do not extract phrase any word labeled other class
save inverted index
load inverted index
sample sentences for sufficient stats
word shape cache
inverted index
extremedebug
minimaldebug
memory
lucene
openhft
function words
stopwfile
english words file
stop str
labelstr
gfile
goldfile
read in memory
sentfiles iter
learned words each iter
min ph
edit dist max
write matched tokens files
min dtotal
min dfinal
edit match
edit dist
edit dist ph
edit dist ratio
constants and variables
score phrase measures
data sents iterator
get relevant words base
pattern class
rel words
pattern
claz
patterns annotations
processed text annotation
matched pattern
matched patterns
matched phrases
longest matched phrase for each label
pattern label1
pattern label2
pattern label3
pattern label4
pattern label5
pattern label6
pattern label7
pattern label8
pattern label9
pattern label10
seed labeled or not
other semantic label
pattern human label1
pattern human label2
pattern human label3
pattern human label4
pattern human label5
pattern human label6
pattern human label7
pattern human label8
pattern human label9
pattern human label10
get all annotations
suggest phrases
suggest phrases test
reset pattern labels in sents
get matched tokens by all phrases
get matched tokens by phrase
set up properties
do remove phrases
do remove annotations
do new annotations
change annotation
current summary
do new phrases
human label classes
machine answer classes
sent has label
objsent
tokenid
haslabel
label arr
run props
remove properties
already learned iters
all extractions
write output to file
additional seed words files
additional seed words
mc cl
humanansclstr
tokens num
obj4label
token arry
seedw
text annotation patterns
add starting classes
transitive closure
prepend package
canonical identifier
ingoing dependencies
outgoing dependencies
is class
dep queue
closure
starting classes
starting patterns
starting class
starting class names
outgoing dependency
pkg line
class line
member line
in dep line
out dep line
both dep line
sorted closure
already output
pkgname
cur package
cur class
in dep
out dep
class id
base index
base id
ident
dependency analyzer
identifier
set next object
next object
reader iterator factory
reader iterator
set next
get line iterator
set next object helper
rif
files strings and readers
reader iterator
curr reader
parse string
tag name pattern
keep internal tags
keep delimiting tags
count depth
tag name regexp
resettable reader iterator factory
default delimit reg ex iterator
default delimit reg ex iterator factory
english args
stanford core nlpenglish test app
chinese args
stanford core nlpspanish test app
stanford core nlpchinese test app
test multithreaded combine segmented sentence
create test tokens
create test flags
segment_attempts_per_thread
threads
chinese string utils test
test iob1iob2
test iob1iob1
test iob2iob1
test iob2iobes
test iobesiob1
test iob1io
test iob1no prefix
test no prefix io
test bilouiobes
test iob2bilou
load core label list
check answers
run iobresults test
make list core label
test iob2results
test iobresults
test ioeresults
test ioresults
test iobesresults
iob1
iob2
iobes
noprefix
bilou
test input
labels iob2
labels iob
labels ioe
labels io
labels iobes
iobutils test
correct answers
best sequence score
run sequence finder
run possible values checker
test exact best sequence finder
test beam best sequence finder
test sequence sampler
mid tags
null tags
tags at pos
best labels
possible
bsf
tsm2
tsm2nr
tsm3
best sequence finder test
test sequence model1
test sequence model2
test sequence model2nr
test sequence model3
test per state best sequence finder
run sequences finder
k2nr
test2nr answers
test2nr scores
best labels counter
top values
str sequence
kbest sequence finder test
test using iterator
test using enhanced for
test using to array
out wss
out idx
object bank wrapper test
resolve and check range
test resolve dow to day
test next
test this
parse date time standard instant format
parse date time standard local date time format
anchor time
test pairs
sutime test
test duration contains duration
test duration contains time
range1
range2
range3
range4
duration test
joda time tests
test no errors
test tag errors
test mislabeled spans
test extra span
test missing span
tree span scoring test
build fake parse result
build fake request
request bytes
test build request
verify results
test single multi request
test multi request
test gold trees
test get results
test score dataset
requests
single bout
single bytes
response bytes
evaluate external parser test
test binary side
shift reduce utils test
test size
test max abs
test score
test condense
test add scaled
test random add
test na n
test read write
scores2
weight test
build state
test left transition
test right transition
check heads
shifts
binary transition test
test unary transitions
test compound unary transitions
test separators
test initial state from tagged
comma tree string
tree strings
tree text
expected transitions
expected separators
shift reduce parser test
test transition
shift transition test
build transition list
test reorder incorrect binary transition
test reorder incorrect shift resulting tree
test reorder incorrect shift
right np
temp right np
left np
temp left np
right vp
temp right vp
left vp
temp left vp
right s
temp right s
left s
temp left s
unary advp
tags
incorrect shift trees
testcase
tnum
reordered
reordering oracle test
test get signature
spanish unknown word model test
test flatten tall trees
flattened
new trees
parser utils test
check word lemma tag
new label word
new label lemma
new label tag
new label from string word lemma tag
new label from string word tag
new label from string word
w tf
w lt
word lemma tag factory test
internal validation
validate has tag
test string label
test tagged word
test word tag
lab3
labels test
test word lemma constructor label word
test word lemma constructor label word label tag
test word lemma constructor word tag
test set from string word and lemma
test set from string word and lemma and tag
test set from string word
w lt f
label word
label tag
word lemma tag test
test indexed word comparisons
iw3
iw4
iw5
iw6
indexed word test
test trie basic
test trie find all
test trie find non overlapping
test trie segment
test trie find closest
trie map
trie map test
build request
test simple request
test two result request
test two requests
pattern match
process tokens regex request test
test simple trigger
test optional trigger
test optional trigger2
test optional trigger3
test optional trigger4
test optional trigger5
sequence pattern trigger test
test exct ws matching
test lnrm matching
entity matcher
entity name
multi word string matcher test
test phrase table
test iterator
test find matches
orig phrases
iterated phrases
in orig not in iterated
in iterated not in orig
phrase table test
test copy
category word tag factory test
test constructor
category word tag test
test core label list to string
test tagged word list to string
test tokenized sentence size
expected value only
expected tagged
cl words
cl values
cl word tags
cl value tags
sentence array
text array
sentence test
test not null
test previous word
test next word
test original sentence
test character offset begin
test character offset end
test white space
test indices
test begin position
test end position
token test
prepare documents
test create from text
test docid
one sentence document
two sentence document
document test
test length of multi word sentence
test length of special character only sentence
test length of one word sentence
test length of one word sentence with dot
test document linking
test basic tokenization
test weird tokens
test original text
test character offsets
test sentence index
test sentence token offsets
tokenize and split annotation
test from core map crash check
test from core map correctness check
test tokenize whitespace simple
test tokenize whitespace with spaces
test string representation
test substring
test sentence from document
test serialize to stream
get write count
got closed
initial sentence
sut
initial document
write count
mocked out stream
was written to
was not closed
mock output stream
mk extraction
mk tree
blue cats play with yarn no indices
blue cats play with yarn
yarn blue cats play with
test to sentence no indices
test to sentence in order
test to sentence out of order
test same semantics for different word order
test glosses
test blue cats play with yarn
test blue cats play quietly with yarn
test cats have tails
testrabbits eat vegetables
test fish like to swim
test fish like to swim alternate parse
test my cats play with yarn
test cats are cute
test iam in florida
test wh
test propagate csubj
test he was inaugurated
test ppattachment
test ppattachment two
test xcomp
test passive nsubj
test possessive
test possessive no ner
test possessive with object
test appos in object
test appos as subj
test reflexive
test passive reflexive
test possessive in entity
test of which
test obj in relation
test vbg
test vbgcollapsed
test there are in
test there are with
test there are vbing
test dogs inheaven
test adv object
test adv object passive
test obama born in regression
test obama president of regression
test obama president of regression full
test george boyd regression
test uspresident obama1
test uspresident obama2
test usally britain
test uspresident obama
test uss ally britain
test president obama
test american actor chris pratt
test chris manning of stanford
test chris manning of stanford long
test chris is of stanford
test ppextraction
test comma doesnt overgenerate
test compound possessive
test all nominals
test acl
test acl with adverb
test acl no pp
test acl with pp
test nmod tmod
test vponly replaced with
test throw away
test mass of iron
test state of the union
list index
relation triple segmenter test
spot test join table
entailment state
some insertion relations
conj or peculiarities
some deletion relations
natural logic relation test
mk word
test no clauses
test xcomp obj
test xcomp subj
test ccomp
open ietest
test values ordered desc
curr length
operator test
equals string
none project
additive_antimultiplicative project
multiplicative_antimultiplicative project
additive project
antimultiplicative project
multiplicative truth
upward downward
additive
multiplicative
antimultiplicative
additive anti multiplicative
multiplicative anti multiplicative
polarity test
mk label
mock labels
guess nerspan
extract nerdiffering types
extract nerno ner
util test
test short
test int
test long
test_length
byte array utils test
tear down
test read write stream from string
test read lines
check line iterable
test line iterable with eol
test line iterable without eol
test iter files recursive
test cp source file target not exists
test cp source file target exists
test cp source file target is dir
test cp source dir target not exists
test cp source dir target is dir
test cp recursive
test tail
dir path
exp line
source dir
source sub dir
ioutils test
test is acronym
test mention matches speaker annotation
ibm
ibm2
ibmm
mibm
rules test
test find tree with smallest span
rule based coref mention finder test
test round with boundaries
test round2
test is dangerous
test is very dangerous
test log add
test int pow
test arccos
test python mod
test parse double
test parse int
test parse int with boundaries
lsum
my lsum
parsed
sloppy math test
test inner product
test num rows
test exp log
test exp log inplace
test add in place
test multiply in place
test pow in place
test add
test multiply
test pow
test pairwise add
test pairwise subtract
test pairwise multiply
test has na n
test has infinite
test count na n
test fliter na n
test count infinite
test fliter infinite
test fliter na nand infinite
test sum
test norm_inf
test argmax
test argmin
test log sum
test normalize
test kldivergence
test sum and mean
help test safe sum and mean
test safe sum and mean
test jensen shannon
test2d add
n rows
d1prime
f_d3
my sum
ninf
kld
dprime
array math test
test compare values
test mult
test mult const
test divide
test divide const
test exp
test log
test plus
test plus const
test minus
test minus const
correct result
admath test
test combining datasets
test svmlight integer format
new rvfdatum
datum1
datum2
data1
data2
rvfdataset test
test create folds
dev train test
dev train test2
dev train test3
dev train test4
dev train test5
general dataset test
test size three identity matrix
test flatten array
test dot product
test convert collection to array
expected matrix
actual matrix
expected array
actual array
indices to multiply
expected product
actual product
input collection
logistic utils test
test weighting works
test backwards compatibility
test mixed compatibility
datum3
weighted rvfdataset test
test dataset
dataset test
create file
create test file
create broken file
test read normal
test read backwards
test error
tsvtagged file reader test
test pairs holder
pairs holder
pairs holder test
test get xml words
xml sent
maxent tagger test
test uniqueness
test sameness
test preserves string
test preserves index
test can count
test holds lots of stuff
test closed
test serialization
ttags test
test all numeric
exx
extractor frames rare test
test get parenthesized arg
extractor test
check invert
check context
test remove xml
test extract specific tag
test sentence splitting
test nested tags
test missing close tags
test early end
test invertible
test context
test offsets
test attributes
test via core nlp
test kbp section matching
ptb invertible
ptb not invertible
clean xml all tags
clean xml some tags
clean xml end sentences
clean xml with flaws
wts splitter
xml remover
gold annotations
annotation labels
annotation label
expected context
xml context
test no tags
test tags
test many tags
discussion forum post
sentence quoted
sentence author
potential quote text
clean xml annotator test
test escape
test no escape
test sanitize jsonstring
test simple json
test collection json
test nested json
test complex json
test simple document
writer1
jsonoutputter test
test custom simple sentence
output keys
co nlloutputter test
test include text
expected simple
expected include text
xmloutputter test
test new version
test bad language
test default no nls pipeline
test hyphens
test numeric hyphens
test before after offsets
test final gonna
t words
old words
new words3
new words4
props3
ann3
pipeline3
toks3
out3
props4
ann4
pipeline4
toks4
out4
props5
ann5
pipeline5
toks5
out5
tokenizer annotator test
test prereq annotators basic
test prereq annotators order preserving
test prereq annotators regex nerafter ner
test prereq annotators coref before open ie
test prereq annotators coref
test prereq annotators coref with parse
stanford core nlptest
test annotator
test tokenize nls doesnt change ssplit results
test default newline is sentence break settings
test two newline is sentence break settings
test always newline is sentence break settings
test dateline separation
test spanish dateline separation
test kbp works
test kbp spanish works
num_sentences
sentence two tokens
date line texts
date line tokens
sentence one tokens
date line spanish texts
date line spanish tokens
kbp document
kbp sentences
kbp spanish document
kbp spanish sentences
words to sentences annotator test
test from list
annotation test
test merge chunks
chunk annotation utils test
test verbose
test model name
relation extractor annotator test
test signature
annotator pool test
sample annotator factory
test union
span test
test cosine
test is zero
neural utils test
run testing
test mod collins head finder
hf heads
head cat
mod collins head finder test
penn tree reader test
test tree iterator
test deeper copy
test remove
test dominates
test penn print
check binary
test is binary
tree test
test cases
do test
test basic relation
test basic relation with copula as head
test non collapsed relation
test non collapsed separator
test collapsed relation
test ccprocessed relation
test answer
copula_head
non_collapsed
non_collapsed_separator
cc_processed
universal english grammatical structure test
test constituents
constituent test
test simple filter
duplicate tree string filter test
useless tree filter test
test regular semantic head finder
test copula head semantic head finder
shfc
shf heads
shfc heads
semantic head finder test
test basic category
treebank language pack test
tree from string
trees from string
test jo o silva
test no results
test one result
test two results
test reuse
test word disjunction
test immediately dominates
test sister
test precedes follows
test immediate precedes follows
test left right most descendant
test first last child
test ith child
test only child
test dominate unary chain
test preceding following sister
test category functions
test category disjunction
test precedes described chain
test dominate described chain
test segmented and equals expressions
test two children
test doc examples
test month day year
test complex
test complex2
test named
test link
test nonsense
test head of phrase
test only match root
test repeated variables
test moe curly larry
test immediate sister
test variable groups
test parenthesized expressions
test parent equals
test root disjunction
test subtree pattern
test disjunction variable assignments
test optional
tregex1
tregex2
tregex3
matcher1
matcher3
dominates pattern
dominated pattern
preceding
impreceding
following
imfollowing
foo category
foo compiler
foo tregex
bar category
bar compiler
bar tregex
ab category
ab compiler
aaa tregex
bbb tregex
both tregex
test pattern
tests
tregex test
tree test example
test regex pattern
test node pattern
test variable pattern
run pattern test
good labels
bad labels
good matches
bad matches
bad
relabel node test
test back reference
test foreign
test adjoin
test adjoin h
test adjoin f
test adjoin with named node
test auxiliary tree errors
test create subtrees
test create subtrees extended
test delete
test prune
test insert
test insert with named node
test relabel
test replace node
test replace tree
test chinese replace tree
test insert delete
test replace with repeats
test coindex
test keyword
test if exists
test move
test excise
updated
tsurgeon test
test name pattern
run name pattern false
run name pattern true
test unescape
auxiliary tree test
test money or more
test compound modifiers
input tree
qptree transformer test
test height
trees test
test multi words
test comment
test extra dependencies
test single read and write
test reading and writing
multiword_test_input
comment_test_input
extra_deps_test_input
extra_deps_test_empty_nodeinput
string reader
co nlludocument reader writer test
test basic relations
test more basic relations
test to be relations
test basic relations with copula as head
test non collapsed relations
test collapsed relations
test ccprocessed relations
test copy nodes
test answers
basic answers
noncollapsed answers
basic answer
noncollapsed answer
english grammatical structure test
test conll2007
test penn
tree print test
token set
test english dependencies by tree
token string
tp matcher
test answers collapsed
test answers ccprocessed
test answer collapsed
test answer ccprocessed
test answer tokens
test answer collapsed tokens
test answer ccprocessed tokens
grammatical structure test
output lll
output aan
output fff
chinese utils test
test normal delete
test fix split element
test another split
test nothing left tree
ctberror correcting tree normalizer test
ignore relations
tested relations
universal chinese grammatical structure test
chinese grammatical structure test
lp1
lp2
trf01
trf02
trf11
trf12
trf21
trf22
ans21
ans22
t01
t02
t11
t12
t21
t22
negra penn language pack test
test move rb
sym_dont_move_rb
coordination transformer test
test date normalization
test is after
test is compatible
test relative date creation
test contains
static compatible strings1
static compatible strings2
static compatible answers
static after strings2
static after strings1
static after answers
original dates
relative arguments
relative date answers
isodate instance test
test percent normalization
test money normalization
test number normalization
test ordinal normalization
test time normalization
percent strings
percent answers
quantifiable entity normalizer test
test combination
ans2
ans3
ans5
ans6
ans7
ans8
ans9
ans10
ans11
ans12
ans13
ans14
ans15
ans16
out1
out6
out7
out8
out9
out10
first input
second input
input1
classifier combiner test
parse co nll
ietest utils
compare answers
test uncased
check sentences
test cased
test neroverlaps
expected uncased
expected cased
ner patterns
nersentences
snum
word pieces
tag pieces
ner pieces
nersentence
wnum
nertoken
temp filename
uncased
regex nersequence classifier test
test accuracy simple
test accuracy no relation
test accuracy true negatives
kbprelation extractor test
test rosenbrock
test qnminimizer rosenbrock
minimizer test
rosenbrock function
test easy
golden section line search test
estimate gradient
test xsquared plus one
low answer
deg
num dim
test grad
f grad
diff function test
check graph consistency
test num vertices
test num edges
test del zero degree nodes
test shortest path direction sensitive nodes
test shorted path direction sensitive edges
test shortest path direction insensitive nodes
test shortest path direction insensitive edges
test connected components
test edges nodes
test small add remove
test small remove vertex
test small contains
test add remove
test add remove2
test add remove3
test get all vertices
test neighbors
test is neighbor
test degree
check iterator
test iterables
test copy constructor
test iterator remove
test loops
found set
original size
directed multi graph test
test fill static field
test fill static field from properties
fill nonstatic field
fill nonstatic field from properties
fill mixed fields instance given
fill mixed fields no instance given
check options override properties
static option
nonstatic option
argument parser test
static class
nonstatic class
mixed class
test one arg
test no args
reflection loading test
test strip tags
test xmltag
expected breaking result
expected no breaking result
xmlutils test
test maps
view
core maps test
test basic operations
test remove mapping
test merging operations
test random add remove and delta
cvm from map
cvm from cvm
cvm to merge
expected merge
foo map
expected map
r int1
r int2
original copy map
delta copy map
delta2map
collection valued map test
display i
display a
display s
constructor invoked
test basic
test inheritance
make ref
test consistency with java
test primitives
test cast simple
test cast array
test cast string array
test cast enum
test cast collection
test cast map
test cast regression
test cast from string
test cast stream
class
isomething
asomething
ssomething
something
test spliterator in sequence
test spliterator in parallel
iterit
iterable iterator test
test content
object1
object0
object2
object3
beam test
test compose
plus one
doubler
composed
functions test
test equals
tss
tss1
tss2
tss3
tss4
tree shaped stack test
test cross
test diff
test intersection
test powerset
sets test
test array map equals hash map
test hash map equals array map
test clear
test put all
test entry set
test values
test put duplicate values
hmap
newmap
hmap values
map values
array map test
test create
test get and set
test simple equals
test key set
test no hanging
test to short string
test equals reversed insert order
test object loops
test object loop equals
test core label set word behavior
paragraphs
paragraphs2
foo paragraph
bar paragraph
baz
foobar paragraph
biff
barfoo paragraph
lemmaless hash code
nulled copy
boff
array core map test
concatenation iterator test
test basic iterator
test map factory
test tree map iterator
test add all
map iterator
two dimensional map test
test real labels
test bulk add
test value sort
echo
confusion matrix test
backwards integer
test tr
test get base name no suffix
test get base name empty suffix
test get base name dot txt suffix
test get base name pdf suffix
test args to properties
test value split
test longest common substring
test edit distance
test split on char
test string is null or empty
test csv
test get character ngrams
test character ngram
make set
test expand environment variables
test decode array
test regex groups
test escape json string
test index of regex
test split regex
test split keep delimiter
test split lines keep newlines
arg nums
vals1
vals3
escape inputs
csv inputs
csv outputs
temp file1
temp file2
decoded array
test10
test11
hyphens_dashes
string utils test
test load collection
test sorted
test to list
test to set
test get ngrams
split one
test get index
test contains any
test is sub list
test max index
test iterator concat empty
test iterator concat single iter
test iterator concat multi iter
test iterator concat empty iter
test iterator concaat remove
collection file
actual set
actual list
expected list
input ints
expected ints
expected strings
word lists string
collection utils test
test double
test null safe comparator
test list comparator
test array comparator
three
comparators test
test global
synchronized interner test
test get
test index of
test to array
test objects
index3
concurrent hash index test
test synchronization
test unsynchronized
next sleep time
n items
n returned
max_sleep_time
sleep time
multicore wrapper test
delayed identity function
